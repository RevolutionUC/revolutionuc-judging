Opt-in prize,Submission Title,Submission Url,Submission Tagline,Submission Created At,Plain Description,Video,Website,File Url,Built With,What Is Your Table Number?,Mlh Points,Mlh Hardware Lab,Mlh Software Lab,Submitter Screen Name,Submitter First Name,Submitter Last Name,Submitter Email,College/Universities Of Team Members,Additional Team Member Count,Team Member 1 Screen Name,Team Member 1 First Name,Team Member 1 Last Name,Team Member 1 Email,...,,,,,,,,,,,
Best Use of Twilio,Denial Dial,https://revuc-viii.devpost.com/submissions/114270-denial-dial,The most clever rejection hotline ever made!,3/2/2019 21:33,"Inspiration

Ever been asked for your phone number by a stranger but you didn't want to give it to them? Denial Dial is here to save the day!

What it does

Just text (614) 782-8989 and we will handle the rejection for you. When the stranger texts our number, our server will wait about 30 minutes and send them a text. But we didn't stop there - if multiple people have texted the hotline in the last 30 minutes they will be paired up at random and start texting each other. After a few messages we send them both a carefully worded rejection text and send them on their way!

How we built it

We used Twilio's API with Node.js and MongoDB to build a server that responds to texts to the phone number and responds the way we want it to.

Challenges we ran into

Deployment on Google Cloud Platform was very difficult, especially getting MongoDB to work

Accomplishments that we're proud of

We built something that is useful in the real world and successfully used Twilio APIs which we have never used before!

What's next for Denial Dial

We will keep the server running for the foreseeable future so everyone can use it! 
",,https://github.com/nathan815/denial-dial,,"twilio, node.js, express.js, mongodb",801A-5,"Eastern Michigan University, University of Michigan",,,markfonte,Mark,Fonte,mark@fonte.com,"University of Michigan - Ann Arbor, Eastern Michigan University",1,nathan815,Nathan,Johnson,nathancj224@gmail.com,,,,,,,,,,,,
Most Innovative Hack(TCS),Circuit Builder AR,https://revuc-viii.devpost.com/submissions/114367-circuit-builder-ar,See how to wire a circuit using your phone camera and AR,3/3/2019 0:05,"Inspiration

When I was in high school, and even the first few years of college, I found it extremely hard to learn about electronics outside of classes. I thought, ""I can make something with my skills to improve this.""

What it does

If you have all of the needed parts, simply point your phone camera at them, and watch AR fill in the wiring so that you no longer have to dig for datasheets, or get confused with wiring diagrams.

How I built it

Using Vuforia, which allows for object tracking and other AR functionalities. Unity, which allows for the 3D world space editing which was used to make the live AR wire diagrams. 

Challenges I ran into

Unity is extremely daunting to get started with. Just the beginner tutorials are 8 hours long each, so it was a lot of trial and error to get the program to work.

Accomplishments that I'm proud of

I'm really happy with how the app turned out, it looks really good for a demo made in under 24 hours.

What I learned

I learned a bit more about how to use Unity and the 3d space kind of programming.

What's next for Circuit Builder AR

The demo program was only made for one simple circuit because of time constraints. However, it would be cool to build out a full app for all of the Electronics classes at UC.

In addition, Unity allows for me to port this application to IOS, Linux, Windows, and more. However, this will require a much greater effort to carry out.

How is this different from other apps?

If you look at Google AR Core, Apple ARKit, and other major AR apps, the major thing that they do well is object recognition and ground plane tracking. Meaning, you can point your camera at almost any object and either know what you're looking at, or project something onto that object. Those kinds of capabilities have been publically available since around 2011. What is really innovative, unique, and new, is AR with an experience in mind. For example, manuals, instructions, and hands on activities that are completely custom are able to provide an experience that Google or Apple is not going to be able to reproduce in the standard AR Core or ARKit apps because it is a custom program catered to a specific need. This type of program is what I have created a demo for with this project.

Where can I see the project?

Unfortunately, Vuforia requires some private keys in order to make the app work. I cannot share the project source at the moment because I do not want my keys to be abused.
",https://youtu.be/LE57ltMmDEQ,,,"unity, c#, vuforia",860D-6,University of Cincinnati,,,bcohen116,Benjamin,Cohen,bcohen116@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Hardware Hack,Circuit Builder AR,https://revuc-viii.devpost.com/submissions/114367-circuit-builder-ar,See how to wire a circuit using your phone camera and AR,3/3/2019 0:05,"Inspiration

When I was in high school, and even the first few years of college, I found it extremely hard to learn about electronics outside of classes. I thought, ""I can make something with my skills to improve this.""

What it does

If you have all of the needed parts, simply point your phone camera at them, and watch AR fill in the wiring so that you no longer have to dig for datasheets, or get confused with wiring diagrams.

How I built it

Using Vuforia, which allows for object tracking and other AR functionalities. Unity, which allows for the 3D world space editing which was used to make the live AR wire diagrams. 

Challenges I ran into

Unity is extremely daunting to get started with. Just the beginner tutorials are 8 hours long each, so it was a lot of trial and error to get the program to work.

Accomplishments that I'm proud of

I'm really happy with how the app turned out, it looks really good for a demo made in under 24 hours.

What I learned

I learned a bit more about how to use Unity and the 3d space kind of programming.

What's next for Circuit Builder AR

The demo program was only made for one simple circuit because of time constraints. However, it would be cool to build out a full app for all of the Electronics classes at UC.

In addition, Unity allows for me to port this application to IOS, Linux, Windows, and more. However, this will require a much greater effort to carry out.

How is this different from other apps?

If you look at Google AR Core, Apple ARKit, and other major AR apps, the major thing that they do well is object recognition and ground plane tracking. Meaning, you can point your camera at almost any object and either know what you're looking at, or project something onto that object. Those kinds of capabilities have been publically available since around 2011. What is really innovative, unique, and new, is AR with an experience in mind. For example, manuals, instructions, and hands on activities that are completely custom are able to provide an experience that Google or Apple is not going to be able to reproduce in the standard AR Core or ARKit apps because it is a custom program catered to a specific need. This type of program is what I have created a demo for with this project.

Where can I see the project?

Unfortunately, Vuforia requires some private keys in order to make the app work. I cannot share the project source at the moment because I do not want my keys to be abused.
",https://youtu.be/LE57ltMmDEQ,,,"unity, c#, vuforia",860D-6,University of Cincinnati,,,bcohen116,Benjamin,Cohen,bcohen116@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Design,Circuit Builder AR,https://revuc-viii.devpost.com/submissions/114367-circuit-builder-ar,See how to wire a circuit using your phone camera and AR,3/3/2019 0:05,"Inspiration

When I was in high school, and even the first few years of college, I found it extremely hard to learn about electronics outside of classes. I thought, ""I can make something with my skills to improve this.""

What it does

If you have all of the needed parts, simply point your phone camera at them, and watch AR fill in the wiring so that you no longer have to dig for datasheets, or get confused with wiring diagrams.

How I built it

Using Vuforia, which allows for object tracking and other AR functionalities. Unity, which allows for the 3D world space editing which was used to make the live AR wire diagrams. 

Challenges I ran into

Unity is extremely daunting to get started with. Just the beginner tutorials are 8 hours long each, so it was a lot of trial and error to get the program to work.

Accomplishments that I'm proud of

I'm really happy with how the app turned out, it looks really good for a demo made in under 24 hours.

What I learned

I learned a bit more about how to use Unity and the 3d space kind of programming.

What's next for Circuit Builder AR

The demo program was only made for one simple circuit because of time constraints. However, it would be cool to build out a full app for all of the Electronics classes at UC.

In addition, Unity allows for me to port this application to IOS, Linux, Windows, and more. However, this will require a much greater effort to carry out.

How is this different from other apps?

If you look at Google AR Core, Apple ARKit, and other major AR apps, the major thing that they do well is object recognition and ground plane tracking. Meaning, you can point your camera at almost any object and either know what you're looking at, or project something onto that object. Those kinds of capabilities have been publically available since around 2011. What is really innovative, unique, and new, is AR with an experience in mind. For example, manuals, instructions, and hands on activities that are completely custom are able to provide an experience that Google or Apple is not going to be able to reproduce in the standard AR Core or ARKit apps because it is a custom program catered to a specific need. This type of program is what I have created a demo for with this project.

Where can I see the project?

Unfortunately, Vuforia requires some private keys in order to make the app work. I cannot share the project source at the moment because I do not want my keys to be abused.
",https://youtu.be/LE57ltMmDEQ,,,"unity, c#, vuforia",860D-6,University of Cincinnati,,,bcohen116,Benjamin,Cohen,bcohen116@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),Circuit Builder AR,https://revuc-viii.devpost.com/submissions/114367-circuit-builder-ar,See how to wire a circuit using your phone camera and AR,3/3/2019 0:05,"Inspiration

When I was in high school, and even the first few years of college, I found it extremely hard to learn about electronics outside of classes. I thought, ""I can make something with my skills to improve this.""

What it does

If you have all of the needed parts, simply point your phone camera at them, and watch AR fill in the wiring so that you no longer have to dig for datasheets, or get confused with wiring diagrams.

How I built it

Using Vuforia, which allows for object tracking and other AR functionalities. Unity, which allows for the 3D world space editing which was used to make the live AR wire diagrams. 

Challenges I ran into

Unity is extremely daunting to get started with. Just the beginner tutorials are 8 hours long each, so it was a lot of trial and error to get the program to work.

Accomplishments that I'm proud of

I'm really happy with how the app turned out, it looks really good for a demo made in under 24 hours.

What I learned

I learned a bit more about how to use Unity and the 3d space kind of programming.

What's next for Circuit Builder AR

The demo program was only made for one simple circuit because of time constraints. However, it would be cool to build out a full app for all of the Electronics classes at UC.

In addition, Unity allows for me to port this application to IOS, Linux, Windows, and more. However, this will require a much greater effort to carry out.

How is this different from other apps?

If you look at Google AR Core, Apple ARKit, and other major AR apps, the major thing that they do well is object recognition and ground plane tracking. Meaning, you can point your camera at almost any object and either know what you're looking at, or project something onto that object. Those kinds of capabilities have been publically available since around 2011. What is really innovative, unique, and new, is AR with an experience in mind. For example, manuals, instructions, and hands on activities that are completely custom are able to provide an experience that Google or Apple is not going to be able to reproduce in the standard AR Core or ARKit apps because it is a custom program catered to a specific need. This type of program is what I have created a demo for with this project.

Where can I see the project?

Unfortunately, Vuforia requires some private keys in order to make the app work. I cannot share the project source at the moment because I do not want my keys to be abused.
",https://youtu.be/LE57ltMmDEQ,,,"unity, c#, vuforia",860D-6,University of Cincinnati,,,bcohen116,Benjamin,Cohen,bcohen116@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Useless Hack,The Fizzle Fairies Menagerie of Funky Retro Carnivores,https://revuc-viii.devpost.com/submissions/114406-the-fizzle-fairies-menagerie-of-funky-retro-carnivores,"Play with and create gif based animal babies, feed them, help them survive!",3/3/2019 2:30,"Instructions

Click an animal to use it!

to create your own animal, follow these steps!


Click ""Draw New Animals Here""
Use Piskel to draw and animate your animal
Once you're done, click the EXPORT option on the side of pixlr (it looks like mountains and a sun)
Click ""Upload"" then copy the yellow link
Paste the yellow link into the text box in our app, and click ""Add an Animal""
Scroll the the bottom, and click your animal to select it!
You successfully created an abomination! 


Inspiration

We were inspired by memes, virtual pets, and retro video game sprites.

What it does

You create and play with little animals, feed them, and raise that score!

How we built it

We used glitch as our online collaborative IDE, and using flask we set up a website that used p5.js to draw our pixel babies to the screen. You can even add your own using the sprite editor we used online!

Challenges we ran into

Starting out with a lot of ideas, we had to narrow down our focus. We started with much more central and practical ideas, but in the end, we just wanted to have fun!

Accomplishments that we're proud of

We are proud of our sprite art, many of them actually drawn by us during our Hackathon time!

What we learned

We learned how to set up flask online, maneuver glitch, and write JavaScript to manipulate the dom. Not to mention our new experience with pixel art animations! 

What's next for The Fizzle Fairies Menagerie of Funky Retro Carnivores

We're contemplating a server-side storage of the animals people create, that way you can play with anyone's animals and share them online! We would also like to let people play with their animals together using client to client network communication through our flask server.

To use the chrome extension


Unzip the fizzleExtension
go to chrome://extensions
enable developer mode
Import the fizzleExtension unzipped folder
Enjoy your pet sitting on your stuff (you can't click it when he does that!) as he follows you around the internet!
(Your score is now printed into the console)

",,https://royal-sunshine.glitch.me/cody,https://s3.amazonaws.com/challengepost/zip_files/production/41741/zip_files/fizzleExtension.zip,"flask, p5, javascript",860D-1,Berea College,,,CodyWMitchell,Cody,Mitchell,bigbrocode@yahoo.com,Berea College,2,joshua_ames,Joshua,Ames,joshua_ames@berea.edu,Jupiter_Juice,,,captainfroggybrains28@berea.edu,,,,,,,,
Best Hardware Hack,PowerSetter,https://revuc-viii.devpost.com/submissions/114483-powersetter,A web-app that finds all possible subsets,3/3/2019 6:44,"Inspiration

Combinatorial abstraction. Using binary strings from 0-2^(n-1) to represent the subsets of a set of size n.

What it does

finds the subsets of a set

How I built it

html5, css3, and javascript.

Challenges I ran into

Javascript proved to be a difficult language for me as someone who comes from working with mainly high level programming languages such as python or Ruby.

Accomplishments that I'm proud of

Firstly, the app works. Overall, I would say that I am most proud that I was able to build a basic web app with the little I know.

What I learned

The language of Javascript, encorporating it efficiently in html5

What's next for PowerSetter

improvements to the overall UI, styling, and fixing some serious bugs such passing in sets as elements.
",,https://github.com/Davidg384/PowerSetter,,"love, javascript, html5, css3, vim, pixie-dust",860D-3,Berea College,DragonBoard 410C,,davidg384,David,Gonzalez,davidg384@gmail.com,Berea College,0,,,,,,,,,,,,,,,,
Best Design,PowerSetter,https://revuc-viii.devpost.com/submissions/114483-powersetter,A web-app that finds all possible subsets,3/3/2019 6:44,"Inspiration

Combinatorial abstraction. Using binary strings from 0-2^(n-1) to represent the subsets of a set of size n.

What it does

finds the subsets of a set

How I built it

html5, css3, and javascript.

Challenges I ran into

Javascript proved to be a difficult language for me as someone who comes from working with mainly high level programming languages such as python or Ruby.

Accomplishments that I'm proud of

Firstly, the app works. Overall, I would say that I am most proud that I was able to build a basic web app with the little I know.

What I learned

The language of Javascript, encorporating it efficiently in html5

What's next for PowerSetter

improvements to the overall UI, styling, and fixing some serious bugs such passing in sets as elements.
",,https://github.com/Davidg384/PowerSetter,,"love, javascript, html5, css3, vim, pixie-dust",860D-3,Berea College,DragonBoard 410C,,davidg384,David,Gonzalez,davidg384@gmail.com,Berea College,0,,,,,,,,,,,,,,,,
Best Useless Hack,PowerSetter,https://revuc-viii.devpost.com/submissions/114483-powersetter,A web-app that finds all possible subsets,3/3/2019 6:44,"Inspiration

Combinatorial abstraction. Using binary strings from 0-2^(n-1) to represent the subsets of a set of size n.

What it does

finds the subsets of a set

How I built it

html5, css3, and javascript.

Challenges I ran into

Javascript proved to be a difficult language for me as someone who comes from working with mainly high level programming languages such as python or Ruby.

Accomplishments that I'm proud of

Firstly, the app works. Overall, I would say that I am most proud that I was able to build a basic web app with the little I know.

What I learned

The language of Javascript, encorporating it efficiently in html5

What's next for PowerSetter

improvements to the overall UI, styling, and fixing some serious bugs such passing in sets as elements.
",,https://github.com/Davidg384/PowerSetter,,"love, javascript, html5, css3, vim, pixie-dust",860D-3,Berea College,DragonBoard 410C,,davidg384,David,Gonzalez,davidg384@gmail.com,Berea College,0,,,,,,,,,,,,,,,,
Best Use of Azure (Microsoft),DIALEXT - SMS Communication without Language Barriers,https://revuc-viii.devpost.com/submissions/114507-dialext-sms-communication-without-language-barriers,An SMS-based group chat which seamlessly translates all incoming messages to each users' preferred language!,3/3/2019 7:15,"Inspiration

We went into this hackathon without a solid idea for a project and were hoping for inspiration somewhere along the way. The live demo of Twilio's SMS messaging services at the opening ceremony seemed so seamless and so powerful, that we knew we wanted to use their API. 3 hours into the hackathon we came up with Dialext!

What it does

Dialext is a group texting interface which is meant to take down language barriers and to allow people to communicate with each other by translating all incoming texts to each user's preferred language! 

One of the many reasons Dialext is a great product is its consideration of its users' needs! While many people have unlimited texting these days, unlimited data is still nowhere near as common. There are also many places which have too poor of a signal for good data connections but a good enough signal for SMS. Since Dialext is completely SMS-based (from the user's perspective), it eliminates the need for data, which is required for many other web-based or app-based translation and chatting applications! Another bonus is the convenience - not only does Dialext provide a chatting space for you and your friends, but it automatically does all the translations behind the scenes without the user having to copy/paste the texts from their friends into 3rd party translators!

How we built it

The program was built in Visual Studio 2017 using C# .NET. We used Twilio's REST API for sending and receiving SMS messages, Microsoft's Azure Cognitive Services - Translator Text API for translating the individual texts between languages, and ngrok to allow our receiver program to be called by Twilio over the internet. 

Challenges we ran into

Twilio Timeout:

To make this project run, I have two C# .NET applications running simultaneously, but that was not always the case. Initially there was only one C# .NET project, and it was in charge of receiving the incoming SMS messages, decoding the textmessages/phone numbers/ other useful info, checking whether the user was a new or returning user, storing and retrieving user information to/from databases, translating the texts, and sending out the relevant messages to each user based on sender/sendee status, user/admin level, and preferred language. What I didn't know at first was that the Twilio API had a wait time of 15 seconds for a reply before timing out and assuming something was wrong with my server/application and abandoning the SMS request in favor of an error message. 

I couldn't find a way to increase the timeout time, so I had to find ways to make a swifter response. Most of the time seemed to come from opening, searching through, and closing the Access databases which stored the currently-active users' phone numbers and preferred languages. I decided to split the project into two. 

The first project would get the SMS message, send the phone number and SMS body (message) into a quick .txt file, and respond with null to Twilio, avoiding the timeout problem. This is the receive program.

The second project would read each .txt file placed in its reserved directory by the first receive program. This second program would take note of the sender's phone number and message, check for exit codes (if the user is trying to leave the chat) and respond accordingly, report any major changes/errors to the admin, and, of course, translate and send out the messages to each individual user.

Access Databases

Initially we were using Access Databases (.accdb) to store the information from each user, but we had trouble with the ""Microsoft.ACE.OLEDB.12.0"" provider which seemed to be on my PC but not recognized by my Visual Studio project - after trying to resolve this problem for about an hour, I prioritized finishing the rest of the project, and simply used .txt files instead.

Accomplishments that we're proud of

This is our first hackathon and we made a functional project!!!! While I've worked with C# before and am familiar with Visual Studio, I've never used Twilio SMS or Azure Translator APIs before, so there was definitely a lot that I learned from this project!

What we learned

The obvious answers are that we learned the Twilio SMS and Azure Translator APIs, but we also learned how to trouble-shoot, make decisions, and adapt quickly to changing conditions/project specifications. Finally, we learned that if we come upon an error/ problem/ question on the software we're building, odds are that somebody before us has thought the exact same thing - Google and StackOverflow are your best friends in these scenarios.

What's next for Dialext

A static web page for hosting the Twilio response instructions, for explaining Dialext's purpose, and for letting people sign up their phone numbers online? Support for more languages than the current 6 (English, French, German, Portuguese, Russian, Spanish)? Support for multiple group chats and for private group chats? Less hard coding/repetition and more security? There are lots of ways to improve this project!
",,https://github.uc.edu/chapkoaa/DIALEXT_RevolutionUC_2019,,".net, azure, azure-cognitive-services-translator, twilio, love-<3, caffeine",860D-7,1,,,chapkoaa,Anastasiya,Chapko,chapkoaa@mail.uc.edu,University of Cincinnati,1,eblenms,Matthew,Eblen,eblenms@mail.uc.edu,,,,,,,,,,,,
Most Innovative Hack(TCS),DIALEXT - SMS Communication without Language Barriers,https://revuc-viii.devpost.com/submissions/114507-dialext-sms-communication-without-language-barriers,An SMS-based group chat which seamlessly translates all incoming messages to each users' preferred language!,3/3/2019 7:15,"Inspiration

We went into this hackathon without a solid idea for a project and were hoping for inspiration somewhere along the way. The live demo of Twilio's SMS messaging services at the opening ceremony seemed so seamless and so powerful, that we knew we wanted to use their API. 3 hours into the hackathon we came up with Dialext!

What it does

Dialext is a group texting interface which is meant to take down language barriers and to allow people to communicate with each other by translating all incoming texts to each user's preferred language! 

One of the many reasons Dialext is a great product is its consideration of its users' needs! While many people have unlimited texting these days, unlimited data is still nowhere near as common. There are also many places which have too poor of a signal for good data connections but a good enough signal for SMS. Since Dialext is completely SMS-based (from the user's perspective), it eliminates the need for data, which is required for many other web-based or app-based translation and chatting applications! Another bonus is the convenience - not only does Dialext provide a chatting space for you and your friends, but it automatically does all the translations behind the scenes without the user having to copy/paste the texts from their friends into 3rd party translators!

How we built it

The program was built in Visual Studio 2017 using C# .NET. We used Twilio's REST API for sending and receiving SMS messages, Microsoft's Azure Cognitive Services - Translator Text API for translating the individual texts between languages, and ngrok to allow our receiver program to be called by Twilio over the internet. 

Challenges we ran into

Twilio Timeout:

To make this project run, I have two C# .NET applications running simultaneously, but that was not always the case. Initially there was only one C# .NET project, and it was in charge of receiving the incoming SMS messages, decoding the textmessages/phone numbers/ other useful info, checking whether the user was a new or returning user, storing and retrieving user information to/from databases, translating the texts, and sending out the relevant messages to each user based on sender/sendee status, user/admin level, and preferred language. What I didn't know at first was that the Twilio API had a wait time of 15 seconds for a reply before timing out and assuming something was wrong with my server/application and abandoning the SMS request in favor of an error message. 

I couldn't find a way to increase the timeout time, so I had to find ways to make a swifter response. Most of the time seemed to come from opening, searching through, and closing the Access databases which stored the currently-active users' phone numbers and preferred languages. I decided to split the project into two. 

The first project would get the SMS message, send the phone number and SMS body (message) into a quick .txt file, and respond with null to Twilio, avoiding the timeout problem. This is the receive program.

The second project would read each .txt file placed in its reserved directory by the first receive program. This second program would take note of the sender's phone number and message, check for exit codes (if the user is trying to leave the chat) and respond accordingly, report any major changes/errors to the admin, and, of course, translate and send out the messages to each individual user.

Access Databases

Initially we were using Access Databases (.accdb) to store the information from each user, but we had trouble with the ""Microsoft.ACE.OLEDB.12.0"" provider which seemed to be on my PC but not recognized by my Visual Studio project - after trying to resolve this problem for about an hour, I prioritized finishing the rest of the project, and simply used .txt files instead.

Accomplishments that we're proud of

This is our first hackathon and we made a functional project!!!! While I've worked with C# before and am familiar with Visual Studio, I've never used Twilio SMS or Azure Translator APIs before, so there was definitely a lot that I learned from this project!

What we learned

The obvious answers are that we learned the Twilio SMS and Azure Translator APIs, but we also learned how to trouble-shoot, make decisions, and adapt quickly to changing conditions/project specifications. Finally, we learned that if we come upon an error/ problem/ question on the software we're building, odds are that somebody before us has thought the exact same thing - Google and StackOverflow are your best friends in these scenarios.

What's next for Dialext

A static web page for hosting the Twilio response instructions, for explaining Dialext's purpose, and for letting people sign up their phone numbers online? Support for more languages than the current 6 (English, French, German, Portuguese, Russian, Spanish)? Support for multiple group chats and for private group chats? Less hard coding/repetition and more security? There are lots of ways to improve this project!
",,https://github.uc.edu/chapkoaa/DIALEXT_RevolutionUC_2019,,".net, azure, azure-cognitive-services-translator, twilio, love-<3, caffeine",860D-7,1,,,chapkoaa,Anastasiya,Chapko,chapkoaa@mail.uc.edu,University of Cincinnati,1,eblenms,Matthew,Eblen,eblenms@mail.uc.edu,,,,,,,,,,,,
Best Use of Twilio,DIALEXT - SMS Communication without Language Barriers,https://revuc-viii.devpost.com/submissions/114507-dialext-sms-communication-without-language-barriers,An SMS-based group chat which seamlessly translates all incoming messages to each users' preferred language!,3/3/2019 7:15,"Inspiration

We went into this hackathon without a solid idea for a project and were hoping for inspiration somewhere along the way. The live demo of Twilio's SMS messaging services at the opening ceremony seemed so seamless and so powerful, that we knew we wanted to use their API. 3 hours into the hackathon we came up with Dialext!

What it does

Dialext is a group texting interface which is meant to take down language barriers and to allow people to communicate with each other by translating all incoming texts to each user's preferred language! 

One of the many reasons Dialext is a great product is its consideration of its users' needs! While many people have unlimited texting these days, unlimited data is still nowhere near as common. There are also many places which have too poor of a signal for good data connections but a good enough signal for SMS. Since Dialext is completely SMS-based (from the user's perspective), it eliminates the need for data, which is required for many other web-based or app-based translation and chatting applications! Another bonus is the convenience - not only does Dialext provide a chatting space for you and your friends, but it automatically does all the translations behind the scenes without the user having to copy/paste the texts from their friends into 3rd party translators!

How we built it

The program was built in Visual Studio 2017 using C# .NET. We used Twilio's REST API for sending and receiving SMS messages, Microsoft's Azure Cognitive Services - Translator Text API for translating the individual texts between languages, and ngrok to allow our receiver program to be called by Twilio over the internet. 

Challenges we ran into

Twilio Timeout:

To make this project run, I have two C# .NET applications running simultaneously, but that was not always the case. Initially there was only one C# .NET project, and it was in charge of receiving the incoming SMS messages, decoding the textmessages/phone numbers/ other useful info, checking whether the user was a new or returning user, storing and retrieving user information to/from databases, translating the texts, and sending out the relevant messages to each user based on sender/sendee status, user/admin level, and preferred language. What I didn't know at first was that the Twilio API had a wait time of 15 seconds for a reply before timing out and assuming something was wrong with my server/application and abandoning the SMS request in favor of an error message. 

I couldn't find a way to increase the timeout time, so I had to find ways to make a swifter response. Most of the time seemed to come from opening, searching through, and closing the Access databases which stored the currently-active users' phone numbers and preferred languages. I decided to split the project into two. 

The first project would get the SMS message, send the phone number and SMS body (message) into a quick .txt file, and respond with null to Twilio, avoiding the timeout problem. This is the receive program.

The second project would read each .txt file placed in its reserved directory by the first receive program. This second program would take note of the sender's phone number and message, check for exit codes (if the user is trying to leave the chat) and respond accordingly, report any major changes/errors to the admin, and, of course, translate and send out the messages to each individual user.

Access Databases

Initially we were using Access Databases (.accdb) to store the information from each user, but we had trouble with the ""Microsoft.ACE.OLEDB.12.0"" provider which seemed to be on my PC but not recognized by my Visual Studio project - after trying to resolve this problem for about an hour, I prioritized finishing the rest of the project, and simply used .txt files instead.

Accomplishments that we're proud of

This is our first hackathon and we made a functional project!!!! While I've worked with C# before and am familiar with Visual Studio, I've never used Twilio SMS or Azure Translator APIs before, so there was definitely a lot that I learned from this project!

What we learned

The obvious answers are that we learned the Twilio SMS and Azure Translator APIs, but we also learned how to trouble-shoot, make decisions, and adapt quickly to changing conditions/project specifications. Finally, we learned that if we come upon an error/ problem/ question on the software we're building, odds are that somebody before us has thought the exact same thing - Google and StackOverflow are your best friends in these scenarios.

What's next for Dialext

A static web page for hosting the Twilio response instructions, for explaining Dialext's purpose, and for letting people sign up their phone numbers online? Support for more languages than the current 6 (English, French, German, Portuguese, Russian, Spanish)? Support for multiple group chats and for private group chats? Less hard coding/repetition and more security? There are lots of ways to improve this project!
",,https://github.uc.edu/chapkoaa/DIALEXT_RevolutionUC_2019,,".net, azure, azure-cognitive-services-translator, twilio, love-<3, caffeine",860D-7,1,,,chapkoaa,Anastasiya,Chapko,chapkoaa@mail.uc.edu,University of Cincinnati,1,eblenms,Matthew,Eblen,eblenms@mail.uc.edu,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),DIALEXT - SMS Communication without Language Barriers,https://revuc-viii.devpost.com/submissions/114507-dialext-sms-communication-without-language-barriers,An SMS-based group chat which seamlessly translates all incoming messages to each users' preferred language!,3/3/2019 7:15,"Inspiration

We went into this hackathon without a solid idea for a project and were hoping for inspiration somewhere along the way. The live demo of Twilio's SMS messaging services at the opening ceremony seemed so seamless and so powerful, that we knew we wanted to use their API. 3 hours into the hackathon we came up with Dialext!

What it does

Dialext is a group texting interface which is meant to take down language barriers and to allow people to communicate with each other by translating all incoming texts to each user's preferred language! 

One of the many reasons Dialext is a great product is its consideration of its users' needs! While many people have unlimited texting these days, unlimited data is still nowhere near as common. There are also many places which have too poor of a signal for good data connections but a good enough signal for SMS. Since Dialext is completely SMS-based (from the user's perspective), it eliminates the need for data, which is required for many other web-based or app-based translation and chatting applications! Another bonus is the convenience - not only does Dialext provide a chatting space for you and your friends, but it automatically does all the translations behind the scenes without the user having to copy/paste the texts from their friends into 3rd party translators!

How we built it

The program was built in Visual Studio 2017 using C# .NET. We used Twilio's REST API for sending and receiving SMS messages, Microsoft's Azure Cognitive Services - Translator Text API for translating the individual texts between languages, and ngrok to allow our receiver program to be called by Twilio over the internet. 

Challenges we ran into

Twilio Timeout:

To make this project run, I have two C# .NET applications running simultaneously, but that was not always the case. Initially there was only one C# .NET project, and it was in charge of receiving the incoming SMS messages, decoding the textmessages/phone numbers/ other useful info, checking whether the user was a new or returning user, storing and retrieving user information to/from databases, translating the texts, and sending out the relevant messages to each user based on sender/sendee status, user/admin level, and preferred language. What I didn't know at first was that the Twilio API had a wait time of 15 seconds for a reply before timing out and assuming something was wrong with my server/application and abandoning the SMS request in favor of an error message. 

I couldn't find a way to increase the timeout time, so I had to find ways to make a swifter response. Most of the time seemed to come from opening, searching through, and closing the Access databases which stored the currently-active users' phone numbers and preferred languages. I decided to split the project into two. 

The first project would get the SMS message, send the phone number and SMS body (message) into a quick .txt file, and respond with null to Twilio, avoiding the timeout problem. This is the receive program.

The second project would read each .txt file placed in its reserved directory by the first receive program. This second program would take note of the sender's phone number and message, check for exit codes (if the user is trying to leave the chat) and respond accordingly, report any major changes/errors to the admin, and, of course, translate and send out the messages to each individual user.

Access Databases

Initially we were using Access Databases (.accdb) to store the information from each user, but we had trouble with the ""Microsoft.ACE.OLEDB.12.0"" provider which seemed to be on my PC but not recognized by my Visual Studio project - after trying to resolve this problem for about an hour, I prioritized finishing the rest of the project, and simply used .txt files instead.

Accomplishments that we're proud of

This is our first hackathon and we made a functional project!!!! While I've worked with C# before and am familiar with Visual Studio, I've never used Twilio SMS or Azure Translator APIs before, so there was definitely a lot that I learned from this project!

What we learned

The obvious answers are that we learned the Twilio SMS and Azure Translator APIs, but we also learned how to trouble-shoot, make decisions, and adapt quickly to changing conditions/project specifications. Finally, we learned that if we come upon an error/ problem/ question on the software we're building, odds are that somebody before us has thought the exact same thing - Google and StackOverflow are your best friends in these scenarios.

What's next for Dialext

A static web page for hosting the Twilio response instructions, for explaining Dialext's purpose, and for letting people sign up their phone numbers online? Support for more languages than the current 6 (English, French, German, Portuguese, Russian, Spanish)? Support for multiple group chats and for private group chats? Less hard coding/repetition and more security? There are lots of ways to improve this project!
",,https://github.uc.edu/chapkoaa/DIALEXT_RevolutionUC_2019,,".net, azure, azure-cognitive-services-translator, twilio, love-<3, caffeine",860D-7,1,,,chapkoaa,Anastasiya,Chapko,chapkoaa@mail.uc.edu,University of Cincinnati,1,eblenms,Matthew,Eblen,eblenms@mail.uc.edu,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),DIALEXT - SMS Communication without Language Barriers,https://revuc-viii.devpost.com/submissions/114507-dialext-sms-communication-without-language-barriers,An SMS-based group chat which seamlessly translates all incoming messages to each users' preferred language!,3/3/2019 7:15,"Inspiration

We went into this hackathon without a solid idea for a project and were hoping for inspiration somewhere along the way. The live demo of Twilio's SMS messaging services at the opening ceremony seemed so seamless and so powerful, that we knew we wanted to use their API. 3 hours into the hackathon we came up with Dialext!

What it does

Dialext is a group texting interface which is meant to take down language barriers and to allow people to communicate with each other by translating all incoming texts to each user's preferred language! 

One of the many reasons Dialext is a great product is its consideration of its users' needs! While many people have unlimited texting these days, unlimited data is still nowhere near as common. There are also many places which have too poor of a signal for good data connections but a good enough signal for SMS. Since Dialext is completely SMS-based (from the user's perspective), it eliminates the need for data, which is required for many other web-based or app-based translation and chatting applications! Another bonus is the convenience - not only does Dialext provide a chatting space for you and your friends, but it automatically does all the translations behind the scenes without the user having to copy/paste the texts from their friends into 3rd party translators!

How we built it

The program was built in Visual Studio 2017 using C# .NET. We used Twilio's REST API for sending and receiving SMS messages, Microsoft's Azure Cognitive Services - Translator Text API for translating the individual texts between languages, and ngrok to allow our receiver program to be called by Twilio over the internet. 

Challenges we ran into

Twilio Timeout:

To make this project run, I have two C# .NET applications running simultaneously, but that was not always the case. Initially there was only one C# .NET project, and it was in charge of receiving the incoming SMS messages, decoding the textmessages/phone numbers/ other useful info, checking whether the user was a new or returning user, storing and retrieving user information to/from databases, translating the texts, and sending out the relevant messages to each user based on sender/sendee status, user/admin level, and preferred language. What I didn't know at first was that the Twilio API had a wait time of 15 seconds for a reply before timing out and assuming something was wrong with my server/application and abandoning the SMS request in favor of an error message. 

I couldn't find a way to increase the timeout time, so I had to find ways to make a swifter response. Most of the time seemed to come from opening, searching through, and closing the Access databases which stored the currently-active users' phone numbers and preferred languages. I decided to split the project into two. 

The first project would get the SMS message, send the phone number and SMS body (message) into a quick .txt file, and respond with null to Twilio, avoiding the timeout problem. This is the receive program.

The second project would read each .txt file placed in its reserved directory by the first receive program. This second program would take note of the sender's phone number and message, check for exit codes (if the user is trying to leave the chat) and respond accordingly, report any major changes/errors to the admin, and, of course, translate and send out the messages to each individual user.

Access Databases

Initially we were using Access Databases (.accdb) to store the information from each user, but we had trouble with the ""Microsoft.ACE.OLEDB.12.0"" provider which seemed to be on my PC but not recognized by my Visual Studio project - after trying to resolve this problem for about an hour, I prioritized finishing the rest of the project, and simply used .txt files instead.

Accomplishments that we're proud of

This is our first hackathon and we made a functional project!!!! While I've worked with C# before and am familiar with Visual Studio, I've never used Twilio SMS or Azure Translator APIs before, so there was definitely a lot that I learned from this project!

What we learned

The obvious answers are that we learned the Twilio SMS and Azure Translator APIs, but we also learned how to trouble-shoot, make decisions, and adapt quickly to changing conditions/project specifications. Finally, we learned that if we come upon an error/ problem/ question on the software we're building, odds are that somebody before us has thought the exact same thing - Google and StackOverflow are your best friends in these scenarios.

What's next for Dialext

A static web page for hosting the Twilio response instructions, for explaining Dialext's purpose, and for letting people sign up their phone numbers online? Support for more languages than the current 6 (English, French, German, Portuguese, Russian, Spanish)? Support for multiple group chats and for private group chats? Less hard coding/repetition and more security? There are lots of ways to improve this project!
",,https://github.uc.edu/chapkoaa/DIALEXT_RevolutionUC_2019,,".net, azure, azure-cognitive-services-translator, twilio, love-<3, caffeine",860D-7,1,,,chapkoaa,Anastasiya,Chapko,chapkoaa@mail.uc.edu,University of Cincinnati,1,eblenms,Matthew,Eblen,eblenms@mail.uc.edu,,,,,,,,,,,,
Most Innovative Hack(TCS),Deep_Learner,https://revuc-viii.devpost.com/submissions/114666-deep_learner,"Deep Learner is an app where users can import data, visualize it and run neural networks, without writing any code.",3/3/2019 9:32,"RevolutionUC

Project: Deep Learner

Authors: 

• Giorgi Lomia
• Dostonbek Toirov
• Hila Manalai
• Emely Alfaro

Categories:
• Education
• Demystify Data

Purpose: 
To make neural networks/deep learning more accessible to general public and those who might not have programming skills.

Description:
Deep Learner is an interactive GUI that allows users to import data, visualize it, decide which variable to predict and run neural networks on it. Users are able to construct and train complex neural networks without writing any code. Based on the obtained results, users can try more optimizers, change predictors or save and export the model results to make decisions. 
In general, this program enables users to create their own neural network models without any prior knowledge of coding.

What we learned:
• Creating a fully viable product
• Better understanding of Deep Learning and the underlying structure of neural networks
• Designing user interface
• Optimizing user experience 
• Understanding user needs

To Run the App


Clone or download the repo as .zip file
You need to have Python 3 to be able to run the app. Install requirements and dependencies by running:

$ pip3 install -r requirements.txt

Start the app by running:

$ python3 GUI.py


",,https://github.com/Dostonbek1/RevolutionUC,,"python, r",860D-6,Berea College,,,alfarozavalae,Emely,Alfaro Zavala,alfarozavalae@berea.edu,Berea College,3,Dostonbek1,Dostonbek,Toirov,toirovd@berea.edu,hmanalai,hmanalai,Manalai,hila_manalai@berea.edu,GioLomia,GioLomia,,lomiag@berea.edu,,,,
Best Design,Deep_Learner,https://revuc-viii.devpost.com/submissions/114666-deep_learner,"Deep Learner is an app where users can import data, visualize it and run neural networks, without writing any code.",3/3/2019 9:32,"RevolutionUC

Project: Deep Learner

Authors: 

• Giorgi Lomia
• Dostonbek Toirov
• Hila Manalai
• Emely Alfaro

Categories:
• Education
• Demystify Data

Purpose: 
To make neural networks/deep learning more accessible to general public and those who might not have programming skills.

Description:
Deep Learner is an interactive GUI that allows users to import data, visualize it, decide which variable to predict and run neural networks on it. Users are able to construct and train complex neural networks without writing any code. Based on the obtained results, users can try more optimizers, change predictors or save and export the model results to make decisions. 
In general, this program enables users to create their own neural network models without any prior knowledge of coding.

What we learned:
• Creating a fully viable product
• Better understanding of Deep Learning and the underlying structure of neural networks
• Designing user interface
• Optimizing user experience 
• Understanding user needs

To Run the App


Clone or download the repo as .zip file
You need to have Python 3 to be able to run the app. Install requirements and dependencies by running:

$ pip3 install -r requirements.txt

Start the app by running:

$ python3 GUI.py


",,https://github.com/Dostonbek1/RevolutionUC,,"python, r",860D-6,Berea College,,,alfarozavalae,Emely,Alfaro Zavala,alfarozavalae@berea.edu,Berea College,3,Dostonbek1,Dostonbek,Toirov,toirovd@berea.edu,hmanalai,hmanalai,Manalai,hila_manalai@berea.edu,GioLomia,GioLomia,,lomiag@berea.edu,,,,
Best Undergrad Hack (Undergrad Research),Deep_Learner,https://revuc-viii.devpost.com/submissions/114666-deep_learner,"Deep Learner is an app where users can import data, visualize it and run neural networks, without writing any code.",3/3/2019 9:32,"RevolutionUC

Project: Deep Learner

Authors: 

• Giorgi Lomia
• Dostonbek Toirov
• Hila Manalai
• Emely Alfaro

Categories:
• Education
• Demystify Data

Purpose: 
To make neural networks/deep learning more accessible to general public and those who might not have programming skills.

Description:
Deep Learner is an interactive GUI that allows users to import data, visualize it, decide which variable to predict and run neural networks on it. Users are able to construct and train complex neural networks without writing any code. Based on the obtained results, users can try more optimizers, change predictors or save and export the model results to make decisions. 
In general, this program enables users to create their own neural network models without any prior knowledge of coding.

What we learned:
• Creating a fully viable product
• Better understanding of Deep Learning and the underlying structure of neural networks
• Designing user interface
• Optimizing user experience 
• Understanding user needs

To Run the App


Clone or download the repo as .zip file
You need to have Python 3 to be able to run the app. Install requirements and dependencies by running:

$ pip3 install -r requirements.txt

Start the app by running:

$ python3 GUI.py


",,https://github.com/Dostonbek1/RevolutionUC,,"python, r",860D-6,Berea College,,,alfarozavalae,Emely,Alfaro Zavala,alfarozavalae@berea.edu,Berea College,3,Dostonbek1,Dostonbek,Toirov,toirovd@berea.edu,hmanalai,hmanalai,Manalai,hila_manalai@berea.edu,GioLomia,GioLomia,,lomiag@berea.edu,,,,
Make the Customer's Life Easier (84.51),Deep_Learner,https://revuc-viii.devpost.com/submissions/114666-deep_learner,"Deep Learner is an app where users can import data, visualize it and run neural networks, without writing any code.",3/3/2019 9:32,"RevolutionUC

Project: Deep Learner

Authors: 

• Giorgi Lomia
• Dostonbek Toirov
• Hila Manalai
• Emely Alfaro

Categories:
• Education
• Demystify Data

Purpose: 
To make neural networks/deep learning more accessible to general public and those who might not have programming skills.

Description:
Deep Learner is an interactive GUI that allows users to import data, visualize it, decide which variable to predict and run neural networks on it. Users are able to construct and train complex neural networks without writing any code. Based on the obtained results, users can try more optimizers, change predictors or save and export the model results to make decisions. 
In general, this program enables users to create their own neural network models without any prior knowledge of coding.

What we learned:
• Creating a fully viable product
• Better understanding of Deep Learning and the underlying structure of neural networks
• Designing user interface
• Optimizing user experience 
• Understanding user needs

To Run the App


Clone or download the repo as .zip file
You need to have Python 3 to be able to run the app. Install requirements and dependencies by running:

$ pip3 install -r requirements.txt

Start the app by running:

$ python3 GUI.py


",,https://github.com/Dostonbek1/RevolutionUC,,"python, r",860D-6,Berea College,,,alfarozavalae,Emely,Alfaro Zavala,alfarozavalae@berea.edu,Berea College,3,Dostonbek1,Dostonbek,Toirov,toirovd@berea.edu,hmanalai,hmanalai,Manalai,hila_manalai@berea.edu,GioLomia,GioLomia,,lomiag@berea.edu,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,Deep_Learner,https://revuc-viii.devpost.com/submissions/114666-deep_learner,"Deep Learner is an app where users can import data, visualize it and run neural networks, without writing any code.",3/3/2019 9:32,"RevolutionUC

Project: Deep Learner

Authors: 

• Giorgi Lomia
• Dostonbek Toirov
• Hila Manalai
• Emely Alfaro

Categories:
• Education
• Demystify Data

Purpose: 
To make neural networks/deep learning more accessible to general public and those who might not have programming skills.

Description:
Deep Learner is an interactive GUI that allows users to import data, visualize it, decide which variable to predict and run neural networks on it. Users are able to construct and train complex neural networks without writing any code. Based on the obtained results, users can try more optimizers, change predictors or save and export the model results to make decisions. 
In general, this program enables users to create their own neural network models without any prior knowledge of coding.

What we learned:
• Creating a fully viable product
• Better understanding of Deep Learning and the underlying structure of neural networks
• Designing user interface
• Optimizing user experience 
• Understanding user needs

To Run the App


Clone or download the repo as .zip file
You need to have Python 3 to be able to run the app. Install requirements and dependencies by running:

$ pip3 install -r requirements.txt

Start the app by running:

$ python3 GUI.py


",,https://github.com/Dostonbek1/RevolutionUC,,"python, r",860D-6,Berea College,,,alfarozavalae,Emely,Alfaro Zavala,alfarozavalae@berea.edu,Berea College,3,Dostonbek1,Dostonbek,Toirov,toirovd@berea.edu,hmanalai,hmanalai,Manalai,hila_manalai@berea.edu,GioLomia,GioLomia,,lomiag@berea.edu,,,,
Best Hack for Social Good (JP Morgan Chase & Co),Deep_Learner,https://revuc-viii.devpost.com/submissions/114666-deep_learner,"Deep Learner is an app where users can import data, visualize it and run neural networks, without writing any code.",3/3/2019 9:32,"RevolutionUC

Project: Deep Learner

Authors: 

• Giorgi Lomia
• Dostonbek Toirov
• Hila Manalai
• Emely Alfaro

Categories:
• Education
• Demystify Data

Purpose: 
To make neural networks/deep learning more accessible to general public and those who might not have programming skills.

Description:
Deep Learner is an interactive GUI that allows users to import data, visualize it, decide which variable to predict and run neural networks on it. Users are able to construct and train complex neural networks without writing any code. Based on the obtained results, users can try more optimizers, change predictors or save and export the model results to make decisions. 
In general, this program enables users to create their own neural network models without any prior knowledge of coding.

What we learned:
• Creating a fully viable product
• Better understanding of Deep Learning and the underlying structure of neural networks
• Designing user interface
• Optimizing user experience 
• Understanding user needs

To Run the App


Clone or download the repo as .zip file
You need to have Python 3 to be able to run the app. Install requirements and dependencies by running:

$ pip3 install -r requirements.txt

Start the app by running:

$ python3 GUI.py


",,https://github.com/Dostonbek1/RevolutionUC,,"python, r",860D-6,Berea College,,,alfarozavalae,Emely,Alfaro Zavala,alfarozavalae@berea.edu,Berea College,3,Dostonbek1,Dostonbek,Toirov,toirovd@berea.edu,hmanalai,hmanalai,Manalai,hila_manalai@berea.edu,GioLomia,GioLomia,,lomiag@berea.edu,,,,
Most Innovative Hack(TCS),Portable Remote-Controlled Forklift Prototype,https://revuc-viii.devpost.com/submissions/114668-portable-remote-controlled-forklift-prototype,"To ensure safety and efficiency of forklift operation, we made a portable and remote-controlled forklift prototype. ",3/3/2019 9:33,"Inspiration

The basis of our design is to have an emphasis on safety. We wanted to take the human element out of the forklift operation, but still give them the control and ease of use remotely. Operator related accidents happen on a regular basis and this will keep the operator out of harms way as well as allowing the forklift to be compact enough to transport with ease due to its folding platform. 

What it does

To account for this we redesigned the forklift, complete with remote controls to avoid operator injury. The remote control allows the operator to be able to control it from a distance and avoid blind spots that traditional forklifts have a serious problem with.This is not only safe for the operator, but anyone else that may be within its area of use.

It's design also considered the condition of portability. With it's folding mechanical arm concept it is able to fit in the underside of a trailer or in a small container that is easily transported.This allows for it to be used anywhere, and with the use of it's zero turn capabilities it can move in very tight spaces with ease. 

How we built it

Keeping the build as simple as possible without sacrificing functionality we decided to use LEGO as the base building material. We all had an abundance of material and knowledge to be able to construct the forklift without the worry of using unfamiliar materials. With a combination of LEGO Technic and Arduino electronics (motors, Xbox controller adapter, Arduino Shield, and motor controllers) we were able to utilize the functionality of LEGO and the advanced programming options of Arduino.  

Challenges we ran into

The original plan to implement zero turn was to have free standing wheels on the back and simply drive the front wheels similar to how a shopping cart's wheels work. The weight of the car prevented the wheels from spinning properly so we implemented power steering in the back, trying several designs before arriving at the final design.

The code we wrote implemented example code taken from Kristian Lauszus and an Xbox controller library developed by felis on GitHub. Learning how this library worked and implementing it properly took some occasional tweaking of the code. 

Finally, lining up all the Legos in different planes and their accompanying gears took several attempts for every motor. Matching the necessary torque with the desired speed also took lots of trial and error.

The attempt to make the forklift arm fold back onto the machine with a motor did not work, as the motors either lacked the proper strength or Legos did not have the desired stability. Because of this we left the arm folding back on the machine as a concept, needed to be done with our hands.

Accomplishments that we're proud of

The power-steering zero turn design was something we did not plan on implementing. We planned on being pressed for time, so developing this over the course of two hours and its accompanying code, left us very satisfied. 

Gear reductions were also very difficult to build, as they take several planes on mounting that all have to be rigidly locked to the chassis. The payout in torque allows our robot to move as quickly and as powerfully as it does.

What we learned

While each of us came into the Hackathon planning to utilize our different strengths (coding, building, and electronics), we were each able to learn from each other as single-handedly trying to handle any of these tasks was daunting. 

What's next for our Portable Remote-Controlled Forklift Prototype

Being a prototype, the potential for actual development is very appealing. While materials like plastic limited our rigidity, real world steel construction would allow our design to be increasingly functional. Coupled with the obvious body-to-processor ratio difference between a prototype and a real model, an actual design should be even more feasible than a prototype. 

Lastly, since our prototype is already driver less, there is strong potential for autonomous driving. While safety was our focus, and autonomy would have to be implemented flawlessly to preserve this, the massive payouts in production speed, safety and portability make it an ideal project for the future. 
",,,,"arduino, stepper-motors, lego-technic, xbox-controller, gear-reductions",801B-1,University of Cincinnati,,,hockereh,Ethan,Hocker,hockereh@mail.uc.edu,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Hardware Hack,Portable Remote-Controlled Forklift Prototype,https://revuc-viii.devpost.com/submissions/114668-portable-remote-controlled-forklift-prototype,"To ensure safety and efficiency of forklift operation, we made a portable and remote-controlled forklift prototype. ",3/3/2019 9:33,"Inspiration

The basis of our design is to have an emphasis on safety. We wanted to take the human element out of the forklift operation, but still give them the control and ease of use remotely. Operator related accidents happen on a regular basis and this will keep the operator out of harms way as well as allowing the forklift to be compact enough to transport with ease due to its folding platform. 

What it does

To account for this we redesigned the forklift, complete with remote controls to avoid operator injury. The remote control allows the operator to be able to control it from a distance and avoid blind spots that traditional forklifts have a serious problem with.This is not only safe for the operator, but anyone else that may be within its area of use.

It's design also considered the condition of portability. With it's folding mechanical arm concept it is able to fit in the underside of a trailer or in a small container that is easily transported.This allows for it to be used anywhere, and with the use of it's zero turn capabilities it can move in very tight spaces with ease. 

How we built it

Keeping the build as simple as possible without sacrificing functionality we decided to use LEGO as the base building material. We all had an abundance of material and knowledge to be able to construct the forklift without the worry of using unfamiliar materials. With a combination of LEGO Technic and Arduino electronics (motors, Xbox controller adapter, Arduino Shield, and motor controllers) we were able to utilize the functionality of LEGO and the advanced programming options of Arduino.  

Challenges we ran into

The original plan to implement zero turn was to have free standing wheels on the back and simply drive the front wheels similar to how a shopping cart's wheels work. The weight of the car prevented the wheels from spinning properly so we implemented power steering in the back, trying several designs before arriving at the final design.

The code we wrote implemented example code taken from Kristian Lauszus and an Xbox controller library developed by felis on GitHub. Learning how this library worked and implementing it properly took some occasional tweaking of the code. 

Finally, lining up all the Legos in different planes and their accompanying gears took several attempts for every motor. Matching the necessary torque with the desired speed also took lots of trial and error.

The attempt to make the forklift arm fold back onto the machine with a motor did not work, as the motors either lacked the proper strength or Legos did not have the desired stability. Because of this we left the arm folding back on the machine as a concept, needed to be done with our hands.

Accomplishments that we're proud of

The power-steering zero turn design was something we did not plan on implementing. We planned on being pressed for time, so developing this over the course of two hours and its accompanying code, left us very satisfied. 

Gear reductions were also very difficult to build, as they take several planes on mounting that all have to be rigidly locked to the chassis. The payout in torque allows our robot to move as quickly and as powerfully as it does.

What we learned

While each of us came into the Hackathon planning to utilize our different strengths (coding, building, and electronics), we were each able to learn from each other as single-handedly trying to handle any of these tasks was daunting. 

What's next for our Portable Remote-Controlled Forklift Prototype

Being a prototype, the potential for actual development is very appealing. While materials like plastic limited our rigidity, real world steel construction would allow our design to be increasingly functional. Coupled with the obvious body-to-processor ratio difference between a prototype and a real model, an actual design should be even more feasible than a prototype. 

Lastly, since our prototype is already driver less, there is strong potential for autonomous driving. While safety was our focus, and autonomy would have to be implemented flawlessly to preserve this, the massive payouts in production speed, safety and portability make it an ideal project for the future. 
",,,,"arduino, stepper-motors, lego-technic, xbox-controller, gear-reductions",801B-1,University of Cincinnati,,,hockereh,Ethan,Hocker,hockereh@mail.uc.edu,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),Portable Remote-Controlled Forklift Prototype,https://revuc-viii.devpost.com/submissions/114668-portable-remote-controlled-forklift-prototype,"To ensure safety and efficiency of forklift operation, we made a portable and remote-controlled forklift prototype. ",3/3/2019 9:33,"Inspiration

The basis of our design is to have an emphasis on safety. We wanted to take the human element out of the forklift operation, but still give them the control and ease of use remotely. Operator related accidents happen on a regular basis and this will keep the operator out of harms way as well as allowing the forklift to be compact enough to transport with ease due to its folding platform. 

What it does

To account for this we redesigned the forklift, complete with remote controls to avoid operator injury. The remote control allows the operator to be able to control it from a distance and avoid blind spots that traditional forklifts have a serious problem with.This is not only safe for the operator, but anyone else that may be within its area of use.

It's design also considered the condition of portability. With it's folding mechanical arm concept it is able to fit in the underside of a trailer or in a small container that is easily transported.This allows for it to be used anywhere, and with the use of it's zero turn capabilities it can move in very tight spaces with ease. 

How we built it

Keeping the build as simple as possible without sacrificing functionality we decided to use LEGO as the base building material. We all had an abundance of material and knowledge to be able to construct the forklift without the worry of using unfamiliar materials. With a combination of LEGO Technic and Arduino electronics (motors, Xbox controller adapter, Arduino Shield, and motor controllers) we were able to utilize the functionality of LEGO and the advanced programming options of Arduino.  

Challenges we ran into

The original plan to implement zero turn was to have free standing wheels on the back and simply drive the front wheels similar to how a shopping cart's wheels work. The weight of the car prevented the wheels from spinning properly so we implemented power steering in the back, trying several designs before arriving at the final design.

The code we wrote implemented example code taken from Kristian Lauszus and an Xbox controller library developed by felis on GitHub. Learning how this library worked and implementing it properly took some occasional tweaking of the code. 

Finally, lining up all the Legos in different planes and their accompanying gears took several attempts for every motor. Matching the necessary torque with the desired speed also took lots of trial and error.

The attempt to make the forklift arm fold back onto the machine with a motor did not work, as the motors either lacked the proper strength or Legos did not have the desired stability. Because of this we left the arm folding back on the machine as a concept, needed to be done with our hands.

Accomplishments that we're proud of

The power-steering zero turn design was something we did not plan on implementing. We planned on being pressed for time, so developing this over the course of two hours and its accompanying code, left us very satisfied. 

Gear reductions were also very difficult to build, as they take several planes on mounting that all have to be rigidly locked to the chassis. The payout in torque allows our robot to move as quickly and as powerfully as it does.

What we learned

While each of us came into the Hackathon planning to utilize our different strengths (coding, building, and electronics), we were each able to learn from each other as single-handedly trying to handle any of these tasks was daunting. 

What's next for our Portable Remote-Controlled Forklift Prototype

Being a prototype, the potential for actual development is very appealing. While materials like plastic limited our rigidity, real world steel construction would allow our design to be increasingly functional. Coupled with the obvious body-to-processor ratio difference between a prototype and a real model, an actual design should be even more feasible than a prototype. 

Lastly, since our prototype is already driver less, there is strong potential for autonomous driving. While safety was our focus, and autonomy would have to be implemented flawlessly to preserve this, the massive payouts in production speed, safety and portability make it an ideal project for the future. 
",,,,"arduino, stepper-motors, lego-technic, xbox-controller, gear-reductions",801B-1,University of Cincinnati,,,hockereh,Ethan,Hocker,hockereh@mail.uc.edu,University of Cincinnati,0,,,,,,,,,,,,,,,,
Make the Customer's Life Easier (84.51),Portable Remote-Controlled Forklift Prototype,https://revuc-viii.devpost.com/submissions/114668-portable-remote-controlled-forklift-prototype,"To ensure safety and efficiency of forklift operation, we made a portable and remote-controlled forklift prototype. ",3/3/2019 9:33,"Inspiration

The basis of our design is to have an emphasis on safety. We wanted to take the human element out of the forklift operation, but still give them the control and ease of use remotely. Operator related accidents happen on a regular basis and this will keep the operator out of harms way as well as allowing the forklift to be compact enough to transport with ease due to its folding platform. 

What it does

To account for this we redesigned the forklift, complete with remote controls to avoid operator injury. The remote control allows the operator to be able to control it from a distance and avoid blind spots that traditional forklifts have a serious problem with.This is not only safe for the operator, but anyone else that may be within its area of use.

It's design also considered the condition of portability. With it's folding mechanical arm concept it is able to fit in the underside of a trailer or in a small container that is easily transported.This allows for it to be used anywhere, and with the use of it's zero turn capabilities it can move in very tight spaces with ease. 

How we built it

Keeping the build as simple as possible without sacrificing functionality we decided to use LEGO as the base building material. We all had an abundance of material and knowledge to be able to construct the forklift without the worry of using unfamiliar materials. With a combination of LEGO Technic and Arduino electronics (motors, Xbox controller adapter, Arduino Shield, and motor controllers) we were able to utilize the functionality of LEGO and the advanced programming options of Arduino.  

Challenges we ran into

The original plan to implement zero turn was to have free standing wheels on the back and simply drive the front wheels similar to how a shopping cart's wheels work. The weight of the car prevented the wheels from spinning properly so we implemented power steering in the back, trying several designs before arriving at the final design.

The code we wrote implemented example code taken from Kristian Lauszus and an Xbox controller library developed by felis on GitHub. Learning how this library worked and implementing it properly took some occasional tweaking of the code. 

Finally, lining up all the Legos in different planes and their accompanying gears took several attempts for every motor. Matching the necessary torque with the desired speed also took lots of trial and error.

The attempt to make the forklift arm fold back onto the machine with a motor did not work, as the motors either lacked the proper strength or Legos did not have the desired stability. Because of this we left the arm folding back on the machine as a concept, needed to be done with our hands.

Accomplishments that we're proud of

The power-steering zero turn design was something we did not plan on implementing. We planned on being pressed for time, so developing this over the course of two hours and its accompanying code, left us very satisfied. 

Gear reductions were also very difficult to build, as they take several planes on mounting that all have to be rigidly locked to the chassis. The payout in torque allows our robot to move as quickly and as powerfully as it does.

What we learned

While each of us came into the Hackathon planning to utilize our different strengths (coding, building, and electronics), we were each able to learn from each other as single-handedly trying to handle any of these tasks was daunting. 

What's next for our Portable Remote-Controlled Forklift Prototype

Being a prototype, the potential for actual development is very appealing. While materials like plastic limited our rigidity, real world steel construction would allow our design to be increasingly functional. Coupled with the obvious body-to-processor ratio difference between a prototype and a real model, an actual design should be even more feasible than a prototype. 

Lastly, since our prototype is already driver less, there is strong potential for autonomous driving. While safety was our focus, and autonomy would have to be implemented flawlessly to preserve this, the massive payouts in production speed, safety and portability make it an ideal project for the future. 
",,,,"arduino, stepper-motors, lego-technic, xbox-controller, gear-reductions",801B-1,University of Cincinnati,,,hockereh,Ethan,Hocker,hockereh@mail.uc.edu,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Design,WhackaStack,https://revuc-viii.devpost.com/submissions/114673-whackastack,Whacking & Stacking to Better Credit: An Entertaining Way to Learn More about Credit through an Interactive Game,3/3/2019 9:41,"Inspiration

Adulting is challenging, but credit shouldn't have to be. I have learned from my personal experience of being lost, and not knowing how to navigate credit, as a young adult. After watching many podcasts, taking online courses and talking to individuals with good credit, I was able to understand credit more thoroughly. I want to share that knowledge with others, in a more relatable way, so that their learning process is more entertaining and easy to access in a central location with WhackaStack.

What it does

There aren't many fun ways to learn about how to maintain good credit, and WhackaStack is a great way to meet this gap in the market, by providing key facts about credit through an entertaining game, modeled after Whack a Mole. Top mistakes to avoid with credit are shown on the WhackaStack monsters that the player learns through completing the game. These helpful tips are also reinforced through additional resources including Bizkids, Credit Karam and Credit Sesame to further the discussion.

How I built it

I researched jquery frameworks online and considered how I could integrate key credit information in entertaining ways, and that lead me to use Whack a Mole as a model.

Challenges I ran into

The hover reaction that makes the picture change in the animation was challenging. It took me a while to figure it out. This is my first time making a game.

Accomplishments that I'm proud of

I am more familiar with jQuery, and I feel more confident to take on more challenges and make responsive web apps.

What I learned

I learned how to make a web, game apps with jQuery and also how to make static pictures into animated sequences.

What's next for WhackaStack

I'm going to consider adding more reactions for clicks, and additional resources.
",,https://github.com/TAdeniyi/WhackaStack,,"jquery, html5, css, paint3d, canva, github, atom",801-5,Georgia Tech,,,temiloluwaadeniyi,Temiloluwa,Adeniyi,temiloluwa.adeniyi@gmail.com,Georgia Institute of Technology - Main Campus,0,,,,,,,,,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,WhackaStack,https://revuc-viii.devpost.com/submissions/114673-whackastack,Whacking & Stacking to Better Credit: An Entertaining Way to Learn More about Credit through an Interactive Game,3/3/2019 9:41,"Inspiration

Adulting is challenging, but credit shouldn't have to be. I have learned from my personal experience of being lost, and not knowing how to navigate credit, as a young adult. After watching many podcasts, taking online courses and talking to individuals with good credit, I was able to understand credit more thoroughly. I want to share that knowledge with others, in a more relatable way, so that their learning process is more entertaining and easy to access in a central location with WhackaStack.

What it does

There aren't many fun ways to learn about how to maintain good credit, and WhackaStack is a great way to meet this gap in the market, by providing key facts about credit through an entertaining game, modeled after Whack a Mole. Top mistakes to avoid with credit are shown on the WhackaStack monsters that the player learns through completing the game. These helpful tips are also reinforced through additional resources including Bizkids, Credit Karam and Credit Sesame to further the discussion.

How I built it

I researched jquery frameworks online and considered how I could integrate key credit information in entertaining ways, and that lead me to use Whack a Mole as a model.

Challenges I ran into

The hover reaction that makes the picture change in the animation was challenging. It took me a while to figure it out. This is my first time making a game.

Accomplishments that I'm proud of

I am more familiar with jQuery, and I feel more confident to take on more challenges and make responsive web apps.

What I learned

I learned how to make a web, game apps with jQuery and also how to make static pictures into animated sequences.

What's next for WhackaStack

I'm going to consider adding more reactions for clicks, and additional resources.
",,https://github.com/TAdeniyi/WhackaStack,,"jquery, html5, css, paint3d, canva, github, atom",801-5,Georgia Tech,,,temiloluwaadeniyi,Temiloluwa,Adeniyi,temiloluwa.adeniyi@gmail.com,Georgia Institute of Technology - Main Campus,0,,,,,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),WhackaStack,https://revuc-viii.devpost.com/submissions/114673-whackastack,Whacking & Stacking to Better Credit: An Entertaining Way to Learn More about Credit through an Interactive Game,3/3/2019 9:41,"Inspiration

Adulting is challenging, but credit shouldn't have to be. I have learned from my personal experience of being lost, and not knowing how to navigate credit, as a young adult. After watching many podcasts, taking online courses and talking to individuals with good credit, I was able to understand credit more thoroughly. I want to share that knowledge with others, in a more relatable way, so that their learning process is more entertaining and easy to access in a central location with WhackaStack.

What it does

There aren't many fun ways to learn about how to maintain good credit, and WhackaStack is a great way to meet this gap in the market, by providing key facts about credit through an entertaining game, modeled after Whack a Mole. Top mistakes to avoid with credit are shown on the WhackaStack monsters that the player learns through completing the game. These helpful tips are also reinforced through additional resources including Bizkids, Credit Karam and Credit Sesame to further the discussion.

How I built it

I researched jquery frameworks online and considered how I could integrate key credit information in entertaining ways, and that lead me to use Whack a Mole as a model.

Challenges I ran into

The hover reaction that makes the picture change in the animation was challenging. It took me a while to figure it out. This is my first time making a game.

Accomplishments that I'm proud of

I am more familiar with jQuery, and I feel more confident to take on more challenges and make responsive web apps.

What I learned

I learned how to make a web, game apps with jQuery and also how to make static pictures into animated sequences.

What's next for WhackaStack

I'm going to consider adding more reactions for clicks, and additional resources.
",,https://github.com/TAdeniyi/WhackaStack,,"jquery, html5, css, paint3d, canva, github, atom",801-5,Georgia Tech,,,temiloluwaadeniyi,Temiloluwa,Adeniyi,temiloluwa.adeniyi@gmail.com,Georgia Institute of Technology - Main Campus,0,,,,,,,,,,,,,,,,
 Best IoT Hack using a Qualcomm Device (MLH),QUICK-INV,https://revuc-viii.devpost.com/submissions/114681-quick-inv,An IOT project that uses the Google Vision API to detect multiple objects and compare them against a baseline image,3/3/2019 9:46,"Inspiration

We were inspired 

What it does

Our project uses a camera and Google Cloud's Vision API to first take a baseline image of say a shelf or a refrigerator to compare against the current state of the items in the image(whether they are present or not). In addition, we integrated our project with Twillio so that a user could send text requests such as ""What's missing in my fridge?"" to get a list of items to buy when they're at the grocery store. Twillio can also send the user what's currently in their fridge/cupboard or  provides a help function that shows a list of all the commands to use. 

How we built it

How we built it:
We built this application using a combination of Google Cloud hosting, Google Vision API, and Twillio. We hosted a  LAMP server on the google cloud instances that would hold not only a web user interface, but would act as a file server where the remote camera can upload images for processing. This way we were able to process the images as well as store them for later use if we wanted. 

The remote camera runs a python script that takes a picture after a set amount of time, that is configurable by the user, and then the device forms an SFTP connection with the server to transfer the files. The server will then check the folder that contains images and send all available images to be processed by the Google vision API. The results of this contain confidence values of what objects are in the image, this data is then submitted to the database in order to maintain a record over time.

We then implemented the Twillio api so that a user can request more in-depth data about what the camera contains, and is missing (from the base line), this is useful for many purposes and is scalable . As a final touch we have data over time displayed on the PHP website.

Challenges we ran into

While working on our project, we ran into several unexpected challenges that took many hours to recover from. We accidentally posted our api key to our GCP services on github where it was picked up by a web crawler. Shortly after, our project on GCP was hacked and multiple delete-protected VMs were spun up to perfrom crypto mining which led google to suspend our project until our appeal was accepted( after 2 days!). We recovered from this set

Accomplishments that we're proud of

We are proud to have a functioning product that does what we initially wanted to do. Further more we ran into several challenges as mentioned above that we are proud to have put behind us.

What we learned

We learned a great deal about Google Cloud platform and the services that were available to us through there. We also learned how to use the Vision API and store & display the various data we collected using a data visualization tool called high charts. 

What's next for QUICK-INV

In the future we can add google home implementation where users can use voice commands to check their various inventories. 
",,http://quick-inv.com,,"google-cloud, google-vision-api, php, python, mysql, camera, highcharts",801B-4,Northern Kentucky University,,Domain.com|-|Google Cloud Platform,Tobel158,Tobel,Atnafu,tobelwubshet@gmail.com,Northern Kentucky University,3,OGod,Noah,Fields,fieldsn4w@gmail.com,GaneshBudhathoki,Ganesh,Budhathoki,ganesh.budhathoki88@gmail.com,Kenchava,Kenchava,,tkchauvin@gmail.com,,,,
Best Use of Google Cloud Platform (MLH),QUICK-INV,https://revuc-viii.devpost.com/submissions/114681-quick-inv,An IOT project that uses the Google Vision API to detect multiple objects and compare them against a baseline image,3/3/2019 9:46,"Inspiration

We were inspired 

What it does

Our project uses a camera and Google Cloud's Vision API to first take a baseline image of say a shelf or a refrigerator to compare against the current state of the items in the image(whether they are present or not). In addition, we integrated our project with Twillio so that a user could send text requests such as ""What's missing in my fridge?"" to get a list of items to buy when they're at the grocery store. Twillio can also send the user what's currently in their fridge/cupboard or  provides a help function that shows a list of all the commands to use. 

How we built it

How we built it:
We built this application using a combination of Google Cloud hosting, Google Vision API, and Twillio. We hosted a  LAMP server on the google cloud instances that would hold not only a web user interface, but would act as a file server where the remote camera can upload images for processing. This way we were able to process the images as well as store them for later use if we wanted. 

The remote camera runs a python script that takes a picture after a set amount of time, that is configurable by the user, and then the device forms an SFTP connection with the server to transfer the files. The server will then check the folder that contains images and send all available images to be processed by the Google vision API. The results of this contain confidence values of what objects are in the image, this data is then submitted to the database in order to maintain a record over time.

We then implemented the Twillio api so that a user can request more in-depth data about what the camera contains, and is missing (from the base line), this is useful for many purposes and is scalable . As a final touch we have data over time displayed on the PHP website.

Challenges we ran into

While working on our project, we ran into several unexpected challenges that took many hours to recover from. We accidentally posted our api key to our GCP services on github where it was picked up by a web crawler. Shortly after, our project on GCP was hacked and multiple delete-protected VMs were spun up to perfrom crypto mining which led google to suspend our project until our appeal was accepted( after 2 days!). We recovered from this set

Accomplishments that we're proud of

We are proud to have a functioning product that does what we initially wanted to do. Further more we ran into several challenges as mentioned above that we are proud to have put behind us.

What we learned

We learned a great deal about Google Cloud platform and the services that were available to us through there. We also learned how to use the Vision API and store & display the various data we collected using a data visualization tool called high charts. 

What's next for QUICK-INV

In the future we can add google home implementation where users can use voice commands to check their various inventories. 
",,http://quick-inv.com,,"google-cloud, google-vision-api, php, python, mysql, camera, highcharts",801B-4,Northern Kentucky University,,Domain.com|-|Google Cloud Platform,Tobel158,Tobel,Atnafu,tobelwubshet@gmail.com,Northern Kentucky University,3,OGod,Noah,Fields,fieldsn4w@gmail.com,GaneshBudhathoki,Ganesh,Budhathoki,ganesh.budhathoki88@gmail.com,Kenchava,Kenchava,,tkchauvin@gmail.com,,,,
Most Innovative Hack(TCS),QUICK-INV,https://revuc-viii.devpost.com/submissions/114681-quick-inv,An IOT project that uses the Google Vision API to detect multiple objects and compare them against a baseline image,3/3/2019 9:46,"Inspiration

We were inspired 

What it does

Our project uses a camera and Google Cloud's Vision API to first take a baseline image of say a shelf or a refrigerator to compare against the current state of the items in the image(whether they are present or not). In addition, we integrated our project with Twillio so that a user could send text requests such as ""What's missing in my fridge?"" to get a list of items to buy when they're at the grocery store. Twillio can also send the user what's currently in their fridge/cupboard or  provides a help function that shows a list of all the commands to use. 

How we built it

How we built it:
We built this application using a combination of Google Cloud hosting, Google Vision API, and Twillio. We hosted a  LAMP server on the google cloud instances that would hold not only a web user interface, but would act as a file server where the remote camera can upload images for processing. This way we were able to process the images as well as store them for later use if we wanted. 

The remote camera runs a python script that takes a picture after a set amount of time, that is configurable by the user, and then the device forms an SFTP connection with the server to transfer the files. The server will then check the folder that contains images and send all available images to be processed by the Google vision API. The results of this contain confidence values of what objects are in the image, this data is then submitted to the database in order to maintain a record over time.

We then implemented the Twillio api so that a user can request more in-depth data about what the camera contains, and is missing (from the base line), this is useful for many purposes and is scalable . As a final touch we have data over time displayed on the PHP website.

Challenges we ran into

While working on our project, we ran into several unexpected challenges that took many hours to recover from. We accidentally posted our api key to our GCP services on github where it was picked up by a web crawler. Shortly after, our project on GCP was hacked and multiple delete-protected VMs were spun up to perfrom crypto mining which led google to suspend our project until our appeal was accepted( after 2 days!). We recovered from this set

Accomplishments that we're proud of

We are proud to have a functioning product that does what we initially wanted to do. Further more we ran into several challenges as mentioned above that we are proud to have put behind us.

What we learned

We learned a great deal about Google Cloud platform and the services that were available to us through there. We also learned how to use the Vision API and store & display the various data we collected using a data visualization tool called high charts. 

What's next for QUICK-INV

In the future we can add google home implementation where users can use voice commands to check their various inventories. 
",,http://quick-inv.com,,"google-cloud, google-vision-api, php, python, mysql, camera, highcharts",801B-4,Northern Kentucky University,,Domain.com|-|Google Cloud Platform,Tobel158,Tobel,Atnafu,tobelwubshet@gmail.com,Northern Kentucky University,3,OGod,Noah,Fields,fieldsn4w@gmail.com,GaneshBudhathoki,Ganesh,Budhathoki,ganesh.budhathoki88@gmail.com,Kenchava,Kenchava,,tkchauvin@gmail.com,,,,
Best Hardware Hack,QUICK-INV,https://revuc-viii.devpost.com/submissions/114681-quick-inv,An IOT project that uses the Google Vision API to detect multiple objects and compare them against a baseline image,3/3/2019 9:46,"Inspiration

We were inspired 

What it does

Our project uses a camera and Google Cloud's Vision API to first take a baseline image of say a shelf or a refrigerator to compare against the current state of the items in the image(whether they are present or not). In addition, we integrated our project with Twillio so that a user could send text requests such as ""What's missing in my fridge?"" to get a list of items to buy when they're at the grocery store. Twillio can also send the user what's currently in their fridge/cupboard or  provides a help function that shows a list of all the commands to use. 

How we built it

How we built it:
We built this application using a combination of Google Cloud hosting, Google Vision API, and Twillio. We hosted a  LAMP server on the google cloud instances that would hold not only a web user interface, but would act as a file server where the remote camera can upload images for processing. This way we were able to process the images as well as store them for later use if we wanted. 

The remote camera runs a python script that takes a picture after a set amount of time, that is configurable by the user, and then the device forms an SFTP connection with the server to transfer the files. The server will then check the folder that contains images and send all available images to be processed by the Google vision API. The results of this contain confidence values of what objects are in the image, this data is then submitted to the database in order to maintain a record over time.

We then implemented the Twillio api so that a user can request more in-depth data about what the camera contains, and is missing (from the base line), this is useful for many purposes and is scalable . As a final touch we have data over time displayed on the PHP website.

Challenges we ran into

While working on our project, we ran into several unexpected challenges that took many hours to recover from. We accidentally posted our api key to our GCP services on github where it was picked up by a web crawler. Shortly after, our project on GCP was hacked and multiple delete-protected VMs were spun up to perfrom crypto mining which led google to suspend our project until our appeal was accepted( after 2 days!). We recovered from this set

Accomplishments that we're proud of

We are proud to have a functioning product that does what we initially wanted to do. Further more we ran into several challenges as mentioned above that we are proud to have put behind us.

What we learned

We learned a great deal about Google Cloud platform and the services that were available to us through there. We also learned how to use the Vision API and store & display the various data we collected using a data visualization tool called high charts. 

What's next for QUICK-INV

In the future we can add google home implementation where users can use voice commands to check their various inventories. 
",,http://quick-inv.com,,"google-cloud, google-vision-api, php, python, mysql, camera, highcharts",801B-4,Northern Kentucky University,,Domain.com|-|Google Cloud Platform,Tobel158,Tobel,Atnafu,tobelwubshet@gmail.com,Northern Kentucky University,3,OGod,Noah,Fields,fieldsn4w@gmail.com,GaneshBudhathoki,Ganesh,Budhathoki,ganesh.budhathoki88@gmail.com,Kenchava,Kenchava,,tkchauvin@gmail.com,,,,
Best Use of Twilio,QUICK-INV,https://revuc-viii.devpost.com/submissions/114681-quick-inv,An IOT project that uses the Google Vision API to detect multiple objects and compare them against a baseline image,3/3/2019 9:46,"Inspiration

We were inspired 

What it does

Our project uses a camera and Google Cloud's Vision API to first take a baseline image of say a shelf or a refrigerator to compare against the current state of the items in the image(whether they are present or not). In addition, we integrated our project with Twillio so that a user could send text requests such as ""What's missing in my fridge?"" to get a list of items to buy when they're at the grocery store. Twillio can also send the user what's currently in their fridge/cupboard or  provides a help function that shows a list of all the commands to use. 

How we built it

How we built it:
We built this application using a combination of Google Cloud hosting, Google Vision API, and Twillio. We hosted a  LAMP server on the google cloud instances that would hold not only a web user interface, but would act as a file server where the remote camera can upload images for processing. This way we were able to process the images as well as store them for later use if we wanted. 

The remote camera runs a python script that takes a picture after a set amount of time, that is configurable by the user, and then the device forms an SFTP connection with the server to transfer the files. The server will then check the folder that contains images and send all available images to be processed by the Google vision API. The results of this contain confidence values of what objects are in the image, this data is then submitted to the database in order to maintain a record over time.

We then implemented the Twillio api so that a user can request more in-depth data about what the camera contains, and is missing (from the base line), this is useful for many purposes and is scalable . As a final touch we have data over time displayed on the PHP website.

Challenges we ran into

While working on our project, we ran into several unexpected challenges that took many hours to recover from. We accidentally posted our api key to our GCP services on github where it was picked up by a web crawler. Shortly after, our project on GCP was hacked and multiple delete-protected VMs were spun up to perfrom crypto mining which led google to suspend our project until our appeal was accepted( after 2 days!). We recovered from this set

Accomplishments that we're proud of

We are proud to have a functioning product that does what we initially wanted to do. Further more we ran into several challenges as mentioned above that we are proud to have put behind us.

What we learned

We learned a great deal about Google Cloud platform and the services that were available to us through there. We also learned how to use the Vision API and store & display the various data we collected using a data visualization tool called high charts. 

What's next for QUICK-INV

In the future we can add google home implementation where users can use voice commands to check their various inventories. 
",,http://quick-inv.com,,"google-cloud, google-vision-api, php, python, mysql, camera, highcharts",801B-4,Northern Kentucky University,,Domain.com|-|Google Cloud Platform,Tobel158,Tobel,Atnafu,tobelwubshet@gmail.com,Northern Kentucky University,3,OGod,Noah,Fields,fieldsn4w@gmail.com,GaneshBudhathoki,Ganesh,Budhathoki,ganesh.budhathoki88@gmail.com,Kenchava,Kenchava,,tkchauvin@gmail.com,,,,
 Best Domain Registered with Domain.com (MLH),QUICK-INV,https://revuc-viii.devpost.com/submissions/114681-quick-inv,An IOT project that uses the Google Vision API to detect multiple objects and compare them against a baseline image,3/3/2019 9:46,"Inspiration

We were inspired 

What it does

Our project uses a camera and Google Cloud's Vision API to first take a baseline image of say a shelf or a refrigerator to compare against the current state of the items in the image(whether they are present or not). In addition, we integrated our project with Twillio so that a user could send text requests such as ""What's missing in my fridge?"" to get a list of items to buy when they're at the grocery store. Twillio can also send the user what's currently in their fridge/cupboard or  provides a help function that shows a list of all the commands to use. 

How we built it

How we built it:
We built this application using a combination of Google Cloud hosting, Google Vision API, and Twillio. We hosted a  LAMP server on the google cloud instances that would hold not only a web user interface, but would act as a file server where the remote camera can upload images for processing. This way we were able to process the images as well as store them for later use if we wanted. 

The remote camera runs a python script that takes a picture after a set amount of time, that is configurable by the user, and then the device forms an SFTP connection with the server to transfer the files. The server will then check the folder that contains images and send all available images to be processed by the Google vision API. The results of this contain confidence values of what objects are in the image, this data is then submitted to the database in order to maintain a record over time.

We then implemented the Twillio api so that a user can request more in-depth data about what the camera contains, and is missing (from the base line), this is useful for many purposes and is scalable . As a final touch we have data over time displayed on the PHP website.

Challenges we ran into

While working on our project, we ran into several unexpected challenges that took many hours to recover from. We accidentally posted our api key to our GCP services on github where it was picked up by a web crawler. Shortly after, our project on GCP was hacked and multiple delete-protected VMs were spun up to perfrom crypto mining which led google to suspend our project until our appeal was accepted( after 2 days!). We recovered from this set

Accomplishments that we're proud of

We are proud to have a functioning product that does what we initially wanted to do. Further more we ran into several challenges as mentioned above that we are proud to have put behind us.

What we learned

We learned a great deal about Google Cloud platform and the services that were available to us through there. We also learned how to use the Vision API and store & display the various data we collected using a data visualization tool called high charts. 

What's next for QUICK-INV

In the future we can add google home implementation where users can use voice commands to check their various inventories. 
",,http://quick-inv.com,,"google-cloud, google-vision-api, php, python, mysql, camera, highcharts",801B-4,Northern Kentucky University,,Domain.com|-|Google Cloud Platform,Tobel158,Tobel,Atnafu,tobelwubshet@gmail.com,Northern Kentucky University,3,OGod,Noah,Fields,fieldsn4w@gmail.com,GaneshBudhathoki,Ganesh,Budhathoki,ganesh.budhathoki88@gmail.com,Kenchava,Kenchava,,tkchauvin@gmail.com,,,,
Make the Customer's Life Easier (84.51),QUICK-INV,https://revuc-viii.devpost.com/submissions/114681-quick-inv,An IOT project that uses the Google Vision API to detect multiple objects and compare them against a baseline image,3/3/2019 9:46,"Inspiration

We were inspired 

What it does

Our project uses a camera and Google Cloud's Vision API to first take a baseline image of say a shelf or a refrigerator to compare against the current state of the items in the image(whether they are present or not). In addition, we integrated our project with Twillio so that a user could send text requests such as ""What's missing in my fridge?"" to get a list of items to buy when they're at the grocery store. Twillio can also send the user what's currently in their fridge/cupboard or  provides a help function that shows a list of all the commands to use. 

How we built it

How we built it:
We built this application using a combination of Google Cloud hosting, Google Vision API, and Twillio. We hosted a  LAMP server on the google cloud instances that would hold not only a web user interface, but would act as a file server where the remote camera can upload images for processing. This way we were able to process the images as well as store them for later use if we wanted. 

The remote camera runs a python script that takes a picture after a set amount of time, that is configurable by the user, and then the device forms an SFTP connection with the server to transfer the files. The server will then check the folder that contains images and send all available images to be processed by the Google vision API. The results of this contain confidence values of what objects are in the image, this data is then submitted to the database in order to maintain a record over time.

We then implemented the Twillio api so that a user can request more in-depth data about what the camera contains, and is missing (from the base line), this is useful for many purposes and is scalable . As a final touch we have data over time displayed on the PHP website.

Challenges we ran into

While working on our project, we ran into several unexpected challenges that took many hours to recover from. We accidentally posted our api key to our GCP services on github where it was picked up by a web crawler. Shortly after, our project on GCP was hacked and multiple delete-protected VMs were spun up to perfrom crypto mining which led google to suspend our project until our appeal was accepted( after 2 days!). We recovered from this set

Accomplishments that we're proud of

We are proud to have a functioning product that does what we initially wanted to do. Further more we ran into several challenges as mentioned above that we are proud to have put behind us.

What we learned

We learned a great deal about Google Cloud platform and the services that were available to us through there. We also learned how to use the Vision API and store & display the various data we collected using a data visualization tool called high charts. 

What's next for QUICK-INV

In the future we can add google home implementation where users can use voice commands to check their various inventories. 
",,http://quick-inv.com,,"google-cloud, google-vision-api, php, python, mysql, camera, highcharts",801B-4,Northern Kentucky University,,Domain.com|-|Google Cloud Platform,Tobel158,Tobel,Atnafu,tobelwubshet@gmail.com,Northern Kentucky University,3,OGod,Noah,Fields,fieldsn4w@gmail.com,GaneshBudhathoki,Ganesh,Budhathoki,ganesh.budhathoki88@gmail.com,Kenchava,Kenchava,,tkchauvin@gmail.com,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,QUICK-INV,https://revuc-viii.devpost.com/submissions/114681-quick-inv,An IOT project that uses the Google Vision API to detect multiple objects and compare them against a baseline image,3/3/2019 9:46,"Inspiration

We were inspired 

What it does

Our project uses a camera and Google Cloud's Vision API to first take a baseline image of say a shelf or a refrigerator to compare against the current state of the items in the image(whether they are present or not). In addition, we integrated our project with Twillio so that a user could send text requests such as ""What's missing in my fridge?"" to get a list of items to buy when they're at the grocery store. Twillio can also send the user what's currently in their fridge/cupboard or  provides a help function that shows a list of all the commands to use. 

How we built it

How we built it:
We built this application using a combination of Google Cloud hosting, Google Vision API, and Twillio. We hosted a  LAMP server on the google cloud instances that would hold not only a web user interface, but would act as a file server where the remote camera can upload images for processing. This way we were able to process the images as well as store them for later use if we wanted. 

The remote camera runs a python script that takes a picture after a set amount of time, that is configurable by the user, and then the device forms an SFTP connection with the server to transfer the files. The server will then check the folder that contains images and send all available images to be processed by the Google vision API. The results of this contain confidence values of what objects are in the image, this data is then submitted to the database in order to maintain a record over time.

We then implemented the Twillio api so that a user can request more in-depth data about what the camera contains, and is missing (from the base line), this is useful for many purposes and is scalable . As a final touch we have data over time displayed on the PHP website.

Challenges we ran into

While working on our project, we ran into several unexpected challenges that took many hours to recover from. We accidentally posted our api key to our GCP services on github where it was picked up by a web crawler. Shortly after, our project on GCP was hacked and multiple delete-protected VMs were spun up to perfrom crypto mining which led google to suspend our project until our appeal was accepted( after 2 days!). We recovered from this set

Accomplishments that we're proud of

We are proud to have a functioning product that does what we initially wanted to do. Further more we ran into several challenges as mentioned above that we are proud to have put behind us.

What we learned

We learned a great deal about Google Cloud platform and the services that were available to us through there. We also learned how to use the Vision API and store & display the various data we collected using a data visualization tool called high charts. 

What's next for QUICK-INV

In the future we can add google home implementation where users can use voice commands to check their various inventories. 
",,http://quick-inv.com,,"google-cloud, google-vision-api, php, python, mysql, camera, highcharts",801B-4,Northern Kentucky University,,Domain.com|-|Google Cloud Platform,Tobel158,Tobel,Atnafu,tobelwubshet@gmail.com,Northern Kentucky University,3,OGod,Noah,Fields,fieldsn4w@gmail.com,GaneshBudhathoki,Ganesh,Budhathoki,ganesh.budhathoki88@gmail.com,Kenchava,Kenchava,,tkchauvin@gmail.com,,,,
Best Design,ELLo Mate,https://revuc-viii.devpost.com/submissions/114683-ello-mate,Helping educators understand reading comprehension levels of ELL students. Inspired by tutoring ELL students at NKU. ,3/3/2019 9:47,"Inspiration
 At Northern Kentucky University, there are a good number of ELL (English Language Learning) students attending. The main source that is used by these students is the Writing Center. One of our team members, Isabel, happens to be a writing consultant at NKU. After working with so many ELL students, she wanted to make a change in the way things are happening in a tutoring session. Upon first meeting and ELL student, there is never a good way to asses his or her reading comprehension level. It is only after roughly the second session that a tutor will have an idea as to what level his or her tutee is. If there was something to help the tutors (even teachers) understand and assess, there would be a significant increase in the efficiency of a learning session. 

What it does
 Ello Mate is a web application that allows for ELL students (and anyone, really) to test into and improve reading comprehension levels. Students will see their progress and continue to be challenged to better their skills. Teachers and tutors, as a result, will be able to access the statistics and information necessary to better aid the students in their learning. By helping the students and helping the teachers, there is an excellent win-win scenario present. 

How we built it
 We built this application by banding our brains together, failing a bit (a lot, actually) at first, and finishing stronger than we thought.  The applications we used were HTML, CSS, Laravel, JavaScript, and PHP. 

Challenges we ran into
 A challenge that we ran into was exploring Laravel from scratch by creating local databases. Another challenge we faced was trying to incorporate some form of artificial intelligence to help compute various statistical measurements. 

Accomplishments that we're proud of
We are proud of learning new languages and frameworks. We are also rather proud of how we executed our plan and created something that we think and sincerely hope will benefit many. 

What we learned
 Unfamiliar templates are difficult to customize to your needs. Database management can be challenging when using multiple tables and many entities. 

What's next for ELLo Mate
 The dream is rather huge for this team at ELLo Mate. Of course, we want to make this application the best platform for learning as possible. If this ever piqued the interest of schools and universities, we believe that this would be an excellent tool in the various communication barriers found between educators and students. And, while this was originally inspired by the large influx of ELL students coming to a university's writing center, this is an application that can be used by anyone who wants to improve his or her reading comprehension. Younger readers could especially benefit from this application. We want to help the literary world one paragraph at a time. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/41764/zip_files/Ellomate.docx,"html, css, php, laravel, javascript",801B-2,Northern Kentucky University,,,winkleskit1,Taylor Isabel,Winkleski,winkleskit1@nku.edu,Northern Kentucky University,1,BrentSchleper,Brent,Schleper,brentschleper@gmail.com,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),ELLo Mate,https://revuc-viii.devpost.com/submissions/114683-ello-mate,Helping educators understand reading comprehension levels of ELL students. Inspired by tutoring ELL students at NKU. ,3/3/2019 9:47,"Inspiration
 At Northern Kentucky University, there are a good number of ELL (English Language Learning) students attending. The main source that is used by these students is the Writing Center. One of our team members, Isabel, happens to be a writing consultant at NKU. After working with so many ELL students, she wanted to make a change in the way things are happening in a tutoring session. Upon first meeting and ELL student, there is never a good way to asses his or her reading comprehension level. It is only after roughly the second session that a tutor will have an idea as to what level his or her tutee is. If there was something to help the tutors (even teachers) understand and assess, there would be a significant increase in the efficiency of a learning session. 

What it does
 Ello Mate is a web application that allows for ELL students (and anyone, really) to test into and improve reading comprehension levels. Students will see their progress and continue to be challenged to better their skills. Teachers and tutors, as a result, will be able to access the statistics and information necessary to better aid the students in their learning. By helping the students and helping the teachers, there is an excellent win-win scenario present. 

How we built it
 We built this application by banding our brains together, failing a bit (a lot, actually) at first, and finishing stronger than we thought.  The applications we used were HTML, CSS, Laravel, JavaScript, and PHP. 

Challenges we ran into
 A challenge that we ran into was exploring Laravel from scratch by creating local databases. Another challenge we faced was trying to incorporate some form of artificial intelligence to help compute various statistical measurements. 

Accomplishments that we're proud of
We are proud of learning new languages and frameworks. We are also rather proud of how we executed our plan and created something that we think and sincerely hope will benefit many. 

What we learned
 Unfamiliar templates are difficult to customize to your needs. Database management can be challenging when using multiple tables and many entities. 

What's next for ELLo Mate
 The dream is rather huge for this team at ELLo Mate. Of course, we want to make this application the best platform for learning as possible. If this ever piqued the interest of schools and universities, we believe that this would be an excellent tool in the various communication barriers found between educators and students. And, while this was originally inspired by the large influx of ELL students coming to a university's writing center, this is an application that can be used by anyone who wants to improve his or her reading comprehension. Younger readers could especially benefit from this application. We want to help the literary world one paragraph at a time. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/41764/zip_files/Ellomate.docx,"html, css, php, laravel, javascript",801B-2,Northern Kentucky University,,,winkleskit1,Taylor Isabel,Winkleski,winkleskit1@nku.edu,Northern Kentucky University,1,BrentSchleper,Brent,Schleper,brentschleper@gmail.com,,,,,,,,,,,,
Make the Customer's Life Easier (84.51),ELLo Mate,https://revuc-viii.devpost.com/submissions/114683-ello-mate,Helping educators understand reading comprehension levels of ELL students. Inspired by tutoring ELL students at NKU. ,3/3/2019 9:47,"Inspiration
 At Northern Kentucky University, there are a good number of ELL (English Language Learning) students attending. The main source that is used by these students is the Writing Center. One of our team members, Isabel, happens to be a writing consultant at NKU. After working with so many ELL students, she wanted to make a change in the way things are happening in a tutoring session. Upon first meeting and ELL student, there is never a good way to asses his or her reading comprehension level. It is only after roughly the second session that a tutor will have an idea as to what level his or her tutee is. If there was something to help the tutors (even teachers) understand and assess, there would be a significant increase in the efficiency of a learning session. 

What it does
 Ello Mate is a web application that allows for ELL students (and anyone, really) to test into and improve reading comprehension levels. Students will see their progress and continue to be challenged to better their skills. Teachers and tutors, as a result, will be able to access the statistics and information necessary to better aid the students in their learning. By helping the students and helping the teachers, there is an excellent win-win scenario present. 

How we built it
 We built this application by banding our brains together, failing a bit (a lot, actually) at first, and finishing stronger than we thought.  The applications we used were HTML, CSS, Laravel, JavaScript, and PHP. 

Challenges we ran into
 A challenge that we ran into was exploring Laravel from scratch by creating local databases. Another challenge we faced was trying to incorporate some form of artificial intelligence to help compute various statistical measurements. 

Accomplishments that we're proud of
We are proud of learning new languages and frameworks. We are also rather proud of how we executed our plan and created something that we think and sincerely hope will benefit many. 

What we learned
 Unfamiliar templates are difficult to customize to your needs. Database management can be challenging when using multiple tables and many entities. 

What's next for ELLo Mate
 The dream is rather huge for this team at ELLo Mate. Of course, we want to make this application the best platform for learning as possible. If this ever piqued the interest of schools and universities, we believe that this would be an excellent tool in the various communication barriers found between educators and students. And, while this was originally inspired by the large influx of ELL students coming to a university's writing center, this is an application that can be used by anyone who wants to improve his or her reading comprehension. Younger readers could especially benefit from this application. We want to help the literary world one paragraph at a time. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/41764/zip_files/Ellomate.docx,"html, css, php, laravel, javascript",801B-2,Northern Kentucky University,,,winkleskit1,Taylor Isabel,Winkleski,winkleskit1@nku.edu,Northern Kentucky University,1,BrentSchleper,Brent,Schleper,brentschleper@gmail.com,,,,,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,ELLo Mate,https://revuc-viii.devpost.com/submissions/114683-ello-mate,Helping educators understand reading comprehension levels of ELL students. Inspired by tutoring ELL students at NKU. ,3/3/2019 9:47,"Inspiration
 At Northern Kentucky University, there are a good number of ELL (English Language Learning) students attending. The main source that is used by these students is the Writing Center. One of our team members, Isabel, happens to be a writing consultant at NKU. After working with so many ELL students, she wanted to make a change in the way things are happening in a tutoring session. Upon first meeting and ELL student, there is never a good way to asses his or her reading comprehension level. It is only after roughly the second session that a tutor will have an idea as to what level his or her tutee is. If there was something to help the tutors (even teachers) understand and assess, there would be a significant increase in the efficiency of a learning session. 

What it does
 Ello Mate is a web application that allows for ELL students (and anyone, really) to test into and improve reading comprehension levels. Students will see their progress and continue to be challenged to better their skills. Teachers and tutors, as a result, will be able to access the statistics and information necessary to better aid the students in their learning. By helping the students and helping the teachers, there is an excellent win-win scenario present. 

How we built it
 We built this application by banding our brains together, failing a bit (a lot, actually) at first, and finishing stronger than we thought.  The applications we used were HTML, CSS, Laravel, JavaScript, and PHP. 

Challenges we ran into
 A challenge that we ran into was exploring Laravel from scratch by creating local databases. Another challenge we faced was trying to incorporate some form of artificial intelligence to help compute various statistical measurements. 

Accomplishments that we're proud of
We are proud of learning new languages and frameworks. We are also rather proud of how we executed our plan and created something that we think and sincerely hope will benefit many. 

What we learned
 Unfamiliar templates are difficult to customize to your needs. Database management can be challenging when using multiple tables and many entities. 

What's next for ELLo Mate
 The dream is rather huge for this team at ELLo Mate. Of course, we want to make this application the best platform for learning as possible. If this ever piqued the interest of schools and universities, we believe that this would be an excellent tool in the various communication barriers found between educators and students. And, while this was originally inspired by the large influx of ELL students coming to a university's writing center, this is an application that can be used by anyone who wants to improve his or her reading comprehension. Younger readers could especially benefit from this application. We want to help the literary world one paragraph at a time. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/41764/zip_files/Ellomate.docx,"html, css, php, laravel, javascript",801B-2,Northern Kentucky University,,,winkleskit1,Taylor Isabel,Winkleski,winkleskit1@nku.edu,Northern Kentucky University,1,BrentSchleper,Brent,Schleper,brentschleper@gmail.com,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),ELLo Mate,https://revuc-viii.devpost.com/submissions/114683-ello-mate,Helping educators understand reading comprehension levels of ELL students. Inspired by tutoring ELL students at NKU. ,3/3/2019 9:47,"Inspiration
 At Northern Kentucky University, there are a good number of ELL (English Language Learning) students attending. The main source that is used by these students is the Writing Center. One of our team members, Isabel, happens to be a writing consultant at NKU. After working with so many ELL students, she wanted to make a change in the way things are happening in a tutoring session. Upon first meeting and ELL student, there is never a good way to asses his or her reading comprehension level. It is only after roughly the second session that a tutor will have an idea as to what level his or her tutee is. If there was something to help the tutors (even teachers) understand and assess, there would be a significant increase in the efficiency of a learning session. 

What it does
 Ello Mate is a web application that allows for ELL students (and anyone, really) to test into and improve reading comprehension levels. Students will see their progress and continue to be challenged to better their skills. Teachers and tutors, as a result, will be able to access the statistics and information necessary to better aid the students in their learning. By helping the students and helping the teachers, there is an excellent win-win scenario present. 

How we built it
 We built this application by banding our brains together, failing a bit (a lot, actually) at first, and finishing stronger than we thought.  The applications we used were HTML, CSS, Laravel, JavaScript, and PHP. 

Challenges we ran into
 A challenge that we ran into was exploring Laravel from scratch by creating local databases. Another challenge we faced was trying to incorporate some form of artificial intelligence to help compute various statistical measurements. 

Accomplishments that we're proud of
We are proud of learning new languages and frameworks. We are also rather proud of how we executed our plan and created something that we think and sincerely hope will benefit many. 

What we learned
 Unfamiliar templates are difficult to customize to your needs. Database management can be challenging when using multiple tables and many entities. 

What's next for ELLo Mate
 The dream is rather huge for this team at ELLo Mate. Of course, we want to make this application the best platform for learning as possible. If this ever piqued the interest of schools and universities, we believe that this would be an excellent tool in the various communication barriers found between educators and students. And, while this was originally inspired by the large influx of ELL students coming to a university's writing center, this is an application that can be used by anyone who wants to improve his or her reading comprehension. Younger readers could especially benefit from this application. We want to help the literary world one paragraph at a time. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/41764/zip_files/Ellomate.docx,"html, css, php, laravel, javascript",801B-2,Northern Kentucky University,,,winkleskit1,Taylor Isabel,Winkleski,winkleskit1@nku.edu,Northern Kentucky University,1,BrentSchleper,Brent,Schleper,brentschleper@gmail.com,,,,,,,,,,,,
,GUI-game-Nim,https://revuc-viii.devpost.com/submissions/114698-gui-game-nim,Creating Gui game,3/3/2019 9:51,"GUI-game

Creating Gui game
 RevolutionUC: Game of Nim 

 Authors 
• May Jue
• Eleni Lazaridou

See also the list of contributors who participated in this project.
Description of Nim
The game of Nim is a two player strategical game. The game has a pile of a specific object. Each player take turns and remover a number of objects. The purpose of the game is for one player to get the last one. 
Getting Started
The user plays against the computer in a Tkinter environment. The computer uses mathematical logic in order to win. The players should make wise decisions, as they have the benefit of always start first. 
",,https://github.com/MayJue/GUI-game,,python,860D-1,Berea College,,,lazaridoue,Eleni,Lazaridou,lazaridoue@berea.edu,Berea College,1,MayJue,May,Jue,juem@berea.edu,,,,,,,,,,,,
Best Useless Hack,Useless Unity,https://revuc-viii.devpost.com/submissions/114735-useless-unity,A one-level test site of VR with a lot of trees,3/3/2019 9:59,"Inspiration

I've wanted to learn a game engine for a while, and when I saw the hardware table I wanted to try to play around with some sort of VR

What it does

Displays trees in an enclosed space through a VR headset where you can (hopefully) move around in it

How I built it

Unity Game Engine

Challenges I ran into

Getting the VR headset to work the way I wanted it to and starting the entire learning process from scratch

Accomplishments that I'm proud of

Making trees and doing something outside my comfort zone

What I learned

A little C#, how to use Unity, and a little on how to use the Oculus Gear

What's next for Useless Unity

Getting everything to work properly and maybe adding something other than trees
",,,https://s3.amazonaws.com/challengepost/zip_files/production/41748/zip_files/Useless_Unity_0.2.zip,"unity, c#, oculus-gear-vr",860D-7,Miami University,Oculus Rift,,knborror,Kaylynn,Borror,knborror@yahoo.com,Miami University,0,,,,,,,,,,,,,,,,
 Best IoT Hack using a Qualcomm Device (MLH),BLE Kindergarten Kop,https://revuc-viii.devpost.com/submissions/114753-ble-kindergarten-kop,"Bluetooth Invisible Fence, but for Children",3/3/2019 10:08,"Inspiration



What it does



How we built it



Challenges we ran into



Accomplishments that we're proud of



What we learned



What's next for BLE Kindergarten Kop


",,http://aibigdataminingarquantumiotbiometricmachinelearning3dblockchainsynergyalgorithm.com,,"bluetooth, python, linux, qualcomm-dragonboard-410c, arduino, raspberry-pi",860D-5,"University of Louisville, University of Cincinnati",Arduino 101|-|DragonBoard 410C,,HatFreshman,Jacob,Butler,jrbutl02@louisville.edu,"University of Louisville, University of Cincinnati",4,cmklenda,Caleb,Klenda,cmklenda@gmail.com,cmklenda,Caleb,Klenda,cmklenda@gmail.com,WodeDaToad,WodeDaToad,,kennedwj@mail.uc.edu,singh2s7,Simranjit,Singh,singh2s7@mail.uc.edu
Best Hardware Hack,BLE Kindergarten Kop,https://revuc-viii.devpost.com/submissions/114753-ble-kindergarten-kop,"Bluetooth Invisible Fence, but for Children",3/3/2019 10:08,"Inspiration



What it does



How we built it



Challenges we ran into



Accomplishments that we're proud of



What we learned



What's next for BLE Kindergarten Kop


",,http://aibigdataminingarquantumiotbiometricmachinelearning3dblockchainsynergyalgorithm.com,,"bluetooth, python, linux, qualcomm-dragonboard-410c, arduino, raspberry-pi",860D-5,"University of Louisville, University of Cincinnati",Arduino 101|-|DragonBoard 410C,,HatFreshman,Jacob,Butler,jrbutl02@louisville.edu,"University of Louisville, University of Cincinnati",4,cmklenda,Caleb,Klenda,cmklenda@gmail.com,cmklenda,Caleb,Klenda,cmklenda@gmail.com,WodeDaToad,WodeDaToad,,kennedwj@mail.uc.edu,singh2s7,Simranjit,Singh,singh2s7@mail.uc.edu
Best Use of Twilio,BLE Kindergarten Kop,https://revuc-viii.devpost.com/submissions/114753-ble-kindergarten-kop,"Bluetooth Invisible Fence, but for Children",3/3/2019 10:08,"Inspiration



What it does



How we built it



Challenges we ran into



Accomplishments that we're proud of



What we learned



What's next for BLE Kindergarten Kop


",,http://aibigdataminingarquantumiotbiometricmachinelearning3dblockchainsynergyalgorithm.com,,"bluetooth, python, linux, qualcomm-dragonboard-410c, arduino, raspberry-pi",860D-5,"University of Louisville, University of Cincinnati",Arduino 101|-|DragonBoard 410C,,HatFreshman,Jacob,Butler,jrbutl02@louisville.edu,"University of Louisville, University of Cincinnati",4,cmklenda,Caleb,Klenda,cmklenda@gmail.com,cmklenda,Caleb,Klenda,cmklenda@gmail.com,WodeDaToad,WodeDaToad,,kennedwj@mail.uc.edu,singh2s7,Simranjit,Singh,singh2s7@mail.uc.edu
 Best Domain Registered with Domain.com (MLH),BLE Kindergarten Kop,https://revuc-viii.devpost.com/submissions/114753-ble-kindergarten-kop,"Bluetooth Invisible Fence, but for Children",3/3/2019 10:08,"Inspiration



What it does



How we built it



Challenges we ran into



Accomplishments that we're proud of



What we learned



What's next for BLE Kindergarten Kop


",,http://aibigdataminingarquantumiotbiometricmachinelearning3dblockchainsynergyalgorithm.com,,"bluetooth, python, linux, qualcomm-dragonboard-410c, arduino, raspberry-pi",860D-5,"University of Louisville, University of Cincinnati",Arduino 101|-|DragonBoard 410C,,HatFreshman,Jacob,Butler,jrbutl02@louisville.edu,"University of Louisville, University of Cincinnati",4,cmklenda,Caleb,Klenda,cmklenda@gmail.com,cmklenda,Caleb,Klenda,cmklenda@gmail.com,WodeDaToad,WodeDaToad,,kennedwj@mail.uc.edu,singh2s7,Simranjit,Singh,singh2s7@mail.uc.edu
Best Design,BLE Kindergarten Kop,https://revuc-viii.devpost.com/submissions/114753-ble-kindergarten-kop,"Bluetooth Invisible Fence, but for Children",3/3/2019 10:08,"Inspiration



What it does



How we built it



Challenges we ran into



Accomplishments that we're proud of



What we learned



What's next for BLE Kindergarten Kop


",,http://aibigdataminingarquantumiotbiometricmachinelearning3dblockchainsynergyalgorithm.com,,"bluetooth, python, linux, qualcomm-dragonboard-410c, arduino, raspberry-pi",860D-5,"University of Louisville, University of Cincinnati",Arduino 101|-|DragonBoard 410C,,HatFreshman,Jacob,Butler,jrbutl02@louisville.edu,"University of Louisville, University of Cincinnati",4,cmklenda,Caleb,Klenda,cmklenda@gmail.com,cmklenda,Caleb,Klenda,cmklenda@gmail.com,WodeDaToad,WodeDaToad,,kennedwj@mail.uc.edu,singh2s7,Simranjit,Singh,singh2s7@mail.uc.edu
Best Undergrad Hack (Undergrad Research),BLE Kindergarten Kop,https://revuc-viii.devpost.com/submissions/114753-ble-kindergarten-kop,"Bluetooth Invisible Fence, but for Children",3/3/2019 10:08,"Inspiration



What it does



How we built it



Challenges we ran into



Accomplishments that we're proud of



What we learned



What's next for BLE Kindergarten Kop


",,http://aibigdataminingarquantumiotbiometricmachinelearning3dblockchainsynergyalgorithm.com,,"bluetooth, python, linux, qualcomm-dragonboard-410c, arduino, raspberry-pi",860D-5,"University of Louisville, University of Cincinnati",Arduino 101|-|DragonBoard 410C,,HatFreshman,Jacob,Butler,jrbutl02@louisville.edu,"University of Louisville, University of Cincinnati",4,cmklenda,Caleb,Klenda,cmklenda@gmail.com,cmklenda,Caleb,Klenda,cmklenda@gmail.com,WodeDaToad,WodeDaToad,,kennedwj@mail.uc.edu,singh2s7,Simranjit,Singh,singh2s7@mail.uc.edu
Best Hack for Social Good (JP Morgan Chase & Co),BLE Kindergarten Kop,https://revuc-viii.devpost.com/submissions/114753-ble-kindergarten-kop,"Bluetooth Invisible Fence, but for Children",3/3/2019 10:08,"Inspiration



What it does



How we built it



Challenges we ran into



Accomplishments that we're proud of



What we learned



What's next for BLE Kindergarten Kop


",,http://aibigdataminingarquantumiotbiometricmachinelearning3dblockchainsynergyalgorithm.com,,"bluetooth, python, linux, qualcomm-dragonboard-410c, arduino, raspberry-pi",860D-5,"University of Louisville, University of Cincinnati",Arduino 101|-|DragonBoard 410C,,HatFreshman,Jacob,Butler,jrbutl02@louisville.edu,"University of Louisville, University of Cincinnati",4,cmklenda,Caleb,Klenda,cmklenda@gmail.com,cmklenda,Caleb,Klenda,cmklenda@gmail.com,WodeDaToad,WodeDaToad,,kennedwj@mail.uc.edu,singh2s7,Simranjit,Singh,singh2s7@mail.uc.edu
Make the Customer's Life Easier (84.51),Revolutionizing Image Recognition,https://revuc-viii.devpost.com/submissions/114754-revolutionizing-image-recognition,Using data to make customers and sales managers' live easier. ,3/3/2019 10:09,"Inspiration

Hololens, AI, Image learning

What it does

Uses data, and adds stock data which will be combined with other databases such as recipes, aisle locations, pinging store clerks for help. Improves customer experience, produces ads based on items sold and ordered in different store locations and areas 

How we built it

Using unity, android studio, visual studio code

Challenges we ran into

Combining the UI to the backend code, trying to combine our works

Accomplishments that we're proud of

Image recognition and QR code connected to a database made by referencing 84.51 database

What we learned

Unity, C#, Python, Java, Android Studio, Visual Studio, Dart and Flutter

What's next for Revolutionizing Image Recognition

Store scanners/cameras, drones, efficient stocking and use of data applied to customers' experience
",,https://github.com/JuntaoDong/RevolutionUC_2019,,"ishan, puran",801-9,University of Cincinnati,,,JuntaoDong,JT,,juntaodong@gmail.com,University of Cincinnati,2,ishqwn,ishqwn,,ishangupta2k@gmail.com,PuranKansakar,PuranKansakar,,phkansakar@gmail.com,,,,,,,,
 Best IoT Hack using a Qualcomm Device (MLH),Store Alerting System,https://revuc-viii.devpost.com/submissions/114756-store-alerting-system,Uses Dragon Boardand and sensor to detect emptiness and alert,3/3/2019 10:12,"Inspiration

Making customer service better. 
Detects objects and alerts the workers by beeping  buzzer and flashing an LED light signal when the inventory is out of stock. 

How I built it

We used Dragon Board 410 by Qualcom. We installed arduino through linux on the board. Then we started writing our code. Made connections of the sensors and other peripherals and just uploaded the code on the board.

Challenges I ran into

We had no clue how to operate Qualcom Dragon board, it also kept dying on us. Libraries were not working, we had to write code on a small keyboard.  Moreover, we had to try many trial and error based approaches to figure out the correct position for sensor to work desirably.

Accomplishments that I'm proud of

We are so proud that we all met as a team, most of us even had no clue of any hardware technology, let alone be a challenge of figuring out Dragon board to serve the purpose. We are really proud despite many obstacles we are able to finish our product and learnt so much from this experience.

What I learned

We learnt how to operate Dragon Board, use linux, and arduino IDE .

What's next for Alerting System

We are thinking of adding more functionality to it to send text alerts on phone or another peripheral device rather than than using buzzer or LED light. We are thinking of using Twilio's API for that purpose.
",,,,dragon-board,801-12,"The University of Toledo, University of Cincinatti",DragonBoard 410C,Qualcomm,ChandBabuHaryani,Chand Babu,Haryani,chandharyani@yahoo.com,"The University of Toledo, University of Cincinnati",2,hiennguyendong,Hien,Nguyen,hiennguyendong@gmail.com,asemalghamdi07,Asem,Alghamdi,asemalghamdi07@gmail.com,,,,,,,,
Most Innovative Hack(TCS),Store Alerting System,https://revuc-viii.devpost.com/submissions/114756-store-alerting-system,Uses Dragon Boardand and sensor to detect emptiness and alert,3/3/2019 10:12,"Inspiration

Making customer service better. 
Detects objects and alerts the workers by beeping  buzzer and flashing an LED light signal when the inventory is out of stock. 

How I built it

We used Dragon Board 410 by Qualcom. We installed arduino through linux on the board. Then we started writing our code. Made connections of the sensors and other peripherals and just uploaded the code on the board.

Challenges I ran into

We had no clue how to operate Qualcom Dragon board, it also kept dying on us. Libraries were not working, we had to write code on a small keyboard.  Moreover, we had to try many trial and error based approaches to figure out the correct position for sensor to work desirably.

Accomplishments that I'm proud of

We are so proud that we all met as a team, most of us even had no clue of any hardware technology, let alone be a challenge of figuring out Dragon board to serve the purpose. We are really proud despite many obstacles we are able to finish our product and learnt so much from this experience.

What I learned

We learnt how to operate Dragon Board, use linux, and arduino IDE .

What's next for Alerting System

We are thinking of adding more functionality to it to send text alerts on phone or another peripheral device rather than than using buzzer or LED light. We are thinking of using Twilio's API for that purpose.
",,,,dragon-board,801-12,"The University of Toledo, University of Cincinatti",DragonBoard 410C,Qualcomm,ChandBabuHaryani,Chand Babu,Haryani,chandharyani@yahoo.com,"The University of Toledo, University of Cincinnati",2,hiennguyendong,Hien,Nguyen,hiennguyendong@gmail.com,asemalghamdi07,Asem,Alghamdi,asemalghamdi07@gmail.com,,,,,,,,
Best Hardware Hack,Store Alerting System,https://revuc-viii.devpost.com/submissions/114756-store-alerting-system,Uses Dragon Boardand and sensor to detect emptiness and alert,3/3/2019 10:12,"Inspiration

Making customer service better. 
Detects objects and alerts the workers by beeping  buzzer and flashing an LED light signal when the inventory is out of stock. 

How I built it

We used Dragon Board 410 by Qualcom. We installed arduino through linux on the board. Then we started writing our code. Made connections of the sensors and other peripherals and just uploaded the code on the board.

Challenges I ran into

We had no clue how to operate Qualcom Dragon board, it also kept dying on us. Libraries were not working, we had to write code on a small keyboard.  Moreover, we had to try many trial and error based approaches to figure out the correct position for sensor to work desirably.

Accomplishments that I'm proud of

We are so proud that we all met as a team, most of us even had no clue of any hardware technology, let alone be a challenge of figuring out Dragon board to serve the purpose. We are really proud despite many obstacles we are able to finish our product and learnt so much from this experience.

What I learned

We learnt how to operate Dragon Board, use linux, and arduino IDE .

What's next for Alerting System

We are thinking of adding more functionality to it to send text alerts on phone or another peripheral device rather than than using buzzer or LED light. We are thinking of using Twilio's API for that purpose.
",,,,dragon-board,801-12,"The University of Toledo, University of Cincinatti",DragonBoard 410C,Qualcomm,ChandBabuHaryani,Chand Babu,Haryani,chandharyani@yahoo.com,"The University of Toledo, University of Cincinnati",2,hiennguyendong,Hien,Nguyen,hiennguyendong@gmail.com,asemalghamdi07,Asem,Alghamdi,asemalghamdi07@gmail.com,,,,,,,,
Best High School Hack,Store Alerting System,https://revuc-viii.devpost.com/submissions/114756-store-alerting-system,Uses Dragon Boardand and sensor to detect emptiness and alert,3/3/2019 10:12,"Inspiration

Making customer service better. 
Detects objects and alerts the workers by beeping  buzzer and flashing an LED light signal when the inventory is out of stock. 

How I built it

We used Dragon Board 410 by Qualcom. We installed arduino through linux on the board. Then we started writing our code. Made connections of the sensors and other peripherals and just uploaded the code on the board.

Challenges I ran into

We had no clue how to operate Qualcom Dragon board, it also kept dying on us. Libraries were not working, we had to write code on a small keyboard.  Moreover, we had to try many trial and error based approaches to figure out the correct position for sensor to work desirably.

Accomplishments that I'm proud of

We are so proud that we all met as a team, most of us even had no clue of any hardware technology, let alone be a challenge of figuring out Dragon board to serve the purpose. We are really proud despite many obstacles we are able to finish our product and learnt so much from this experience.

What I learned

We learnt how to operate Dragon Board, use linux, and arduino IDE .

What's next for Alerting System

We are thinking of adding more functionality to it to send text alerts on phone or another peripheral device rather than than using buzzer or LED light. We are thinking of using Twilio's API for that purpose.
",,,,dragon-board,801-12,"The University of Toledo, University of Cincinatti",DragonBoard 410C,Qualcomm,ChandBabuHaryani,Chand Babu,Haryani,chandharyani@yahoo.com,"The University of Toledo, University of Cincinnati",2,hiennguyendong,Hien,Nguyen,hiennguyendong@gmail.com,asemalghamdi07,Asem,Alghamdi,asemalghamdi07@gmail.com,,,,,,,,
 Best Domain Registered with Domain.com (MLH),Store Alerting System,https://revuc-viii.devpost.com/submissions/114756-store-alerting-system,Uses Dragon Boardand and sensor to detect emptiness and alert,3/3/2019 10:12,"Inspiration

Making customer service better. 
Detects objects and alerts the workers by beeping  buzzer and flashing an LED light signal when the inventory is out of stock. 

How I built it

We used Dragon Board 410 by Qualcom. We installed arduino through linux on the board. Then we started writing our code. Made connections of the sensors and other peripherals and just uploaded the code on the board.

Challenges I ran into

We had no clue how to operate Qualcom Dragon board, it also kept dying on us. Libraries were not working, we had to write code on a small keyboard.  Moreover, we had to try many trial and error based approaches to figure out the correct position for sensor to work desirably.

Accomplishments that I'm proud of

We are so proud that we all met as a team, most of us even had no clue of any hardware technology, let alone be a challenge of figuring out Dragon board to serve the purpose. We are really proud despite many obstacles we are able to finish our product and learnt so much from this experience.

What I learned

We learnt how to operate Dragon Board, use linux, and arduino IDE .

What's next for Alerting System

We are thinking of adding more functionality to it to send text alerts on phone or another peripheral device rather than than using buzzer or LED light. We are thinking of using Twilio's API for that purpose.
",,,,dragon-board,801-12,"The University of Toledo, University of Cincinatti",DragonBoard 410C,Qualcomm,ChandBabuHaryani,Chand Babu,Haryani,chandharyani@yahoo.com,"The University of Toledo, University of Cincinnati",2,hiennguyendong,Hien,Nguyen,hiennguyendong@gmail.com,asemalghamdi07,Asem,Alghamdi,asemalghamdi07@gmail.com,,,,,,,,
Best Design,Store Alerting System,https://revuc-viii.devpost.com/submissions/114756-store-alerting-system,Uses Dragon Boardand and sensor to detect emptiness and alert,3/3/2019 10:12,"Inspiration

Making customer service better. 
Detects objects and alerts the workers by beeping  buzzer and flashing an LED light signal when the inventory is out of stock. 

How I built it

We used Dragon Board 410 by Qualcom. We installed arduino through linux on the board. Then we started writing our code. Made connections of the sensors and other peripherals and just uploaded the code on the board.

Challenges I ran into

We had no clue how to operate Qualcom Dragon board, it also kept dying on us. Libraries were not working, we had to write code on a small keyboard.  Moreover, we had to try many trial and error based approaches to figure out the correct position for sensor to work desirably.

Accomplishments that I'm proud of

We are so proud that we all met as a team, most of us even had no clue of any hardware technology, let alone be a challenge of figuring out Dragon board to serve the purpose. We are really proud despite many obstacles we are able to finish our product and learnt so much from this experience.

What I learned

We learnt how to operate Dragon Board, use linux, and arduino IDE .

What's next for Alerting System

We are thinking of adding more functionality to it to send text alerts on phone or another peripheral device rather than than using buzzer or LED light. We are thinking of using Twilio's API for that purpose.
",,,,dragon-board,801-12,"The University of Toledo, University of Cincinatti",DragonBoard 410C,Qualcomm,ChandBabuHaryani,Chand Babu,Haryani,chandharyani@yahoo.com,"The University of Toledo, University of Cincinnati",2,hiennguyendong,Hien,Nguyen,hiennguyendong@gmail.com,asemalghamdi07,Asem,Alghamdi,asemalghamdi07@gmail.com,,,,,,,,
Best Useless Hack,Store Alerting System,https://revuc-viii.devpost.com/submissions/114756-store-alerting-system,Uses Dragon Boardand and sensor to detect emptiness and alert,3/3/2019 10:12,"Inspiration

Making customer service better. 
Detects objects and alerts the workers by beeping  buzzer and flashing an LED light signal when the inventory is out of stock. 

How I built it

We used Dragon Board 410 by Qualcom. We installed arduino through linux on the board. Then we started writing our code. Made connections of the sensors and other peripherals and just uploaded the code on the board.

Challenges I ran into

We had no clue how to operate Qualcom Dragon board, it also kept dying on us. Libraries were not working, we had to write code on a small keyboard.  Moreover, we had to try many trial and error based approaches to figure out the correct position for sensor to work desirably.

Accomplishments that I'm proud of

We are so proud that we all met as a team, most of us even had no clue of any hardware technology, let alone be a challenge of figuring out Dragon board to serve the purpose. We are really proud despite many obstacles we are able to finish our product and learnt so much from this experience.

What I learned

We learnt how to operate Dragon Board, use linux, and arduino IDE .

What's next for Alerting System

We are thinking of adding more functionality to it to send text alerts on phone or another peripheral device rather than than using buzzer or LED light. We are thinking of using Twilio's API for that purpose.
",,,,dragon-board,801-12,"The University of Toledo, University of Cincinatti",DragonBoard 410C,Qualcomm,ChandBabuHaryani,Chand Babu,Haryani,chandharyani@yahoo.com,"The University of Toledo, University of Cincinnati",2,hiennguyendong,Hien,Nguyen,hiennguyendong@gmail.com,asemalghamdi07,Asem,Alghamdi,asemalghamdi07@gmail.com,,,,,,,,
Make the Customer's Life Easier (84.51),Store Alerting System,https://revuc-viii.devpost.com/submissions/114756-store-alerting-system,Uses Dragon Boardand and sensor to detect emptiness and alert,3/3/2019 10:12,"Inspiration

Making customer service better. 
Detects objects and alerts the workers by beeping  buzzer and flashing an LED light signal when the inventory is out of stock. 

How I built it

We used Dragon Board 410 by Qualcom. We installed arduino through linux on the board. Then we started writing our code. Made connections of the sensors and other peripherals and just uploaded the code on the board.

Challenges I ran into

We had no clue how to operate Qualcom Dragon board, it also kept dying on us. Libraries were not working, we had to write code on a small keyboard.  Moreover, we had to try many trial and error based approaches to figure out the correct position for sensor to work desirably.

Accomplishments that I'm proud of

We are so proud that we all met as a team, most of us even had no clue of any hardware technology, let alone be a challenge of figuring out Dragon board to serve the purpose. We are really proud despite many obstacles we are able to finish our product and learnt so much from this experience.

What I learned

We learnt how to operate Dragon Board, use linux, and arduino IDE .

What's next for Alerting System

We are thinking of adding more functionality to it to send text alerts on phone or another peripheral device rather than than using buzzer or LED light. We are thinking of using Twilio's API for that purpose.
",,,,dragon-board,801-12,"The University of Toledo, University of Cincinatti",DragonBoard 410C,Qualcomm,ChandBabuHaryani,Chand Babu,Haryani,chandharyani@yahoo.com,"The University of Toledo, University of Cincinnati",2,hiennguyendong,Hien,Nguyen,hiennguyendong@gmail.com,asemalghamdi07,Asem,Alghamdi,asemalghamdi07@gmail.com,,,,,,,,
Best Use of Google Cloud Platform (MLH),ScanAway,https://revuc-viii.devpost.com/submissions/114758-scanaway,Cloud Based Environment Control - An App to help conserve energy and make students more responsible,3/3/2019 10:15,"Inspiration

How many times have you wondered in your workspace,
 ""Why is so cold in here?"" or 
""It's so late in the night. Why are the lights still on?"" or
""I wish the washroom trash was not overflowing""

At all these instances, you would have wanted to tell someone the issue you face. We know we have.

So we built an app to do exactly that.

What it does

This App is called ScanAway. 

 The Icon of the App is the QR code for GO-BEARCATS #Interesting Fact  

Based on a location and type of place, a QR Code is generated for a given location. 
The app scans the QR Code and allows you to inform the administrators about common energy issues you face.

We have extended this app to include reporting issued faced in a restroom as well.

How We built it

It is an Android Application with a Flask server deployed on GCP's App Engine and GCP's SQL datastore.

Challenges we ran into

A significant time was spent bouncing between ideas and brainstorming before we settled on this one.
Debugging Database connection errors and configurations, especially while running the server on localhost.

Accomplishments that we're proud of

Being able to build and deploy an application in a short amount of time available.

What we learned

Learned to make an Android App.
Building a Flask app and deploying it on App Engine.

What's next for ScanAway

Data Visualization from collected data to make it easy for reducing the complaints and to spot patterns
Badges of recognition for students who are responsible enough to report the issues on a regular basis.
",,https://github.com/PriyaKolliC/Bearcat,,"android-studio, google-cloud, flask, java, android",801M-3,"University of Cincinnati; University Of Illinois,Chicago",,Google Cloud Platform,NithyasriBabu,Nithyasri,Babu,nithyasri.babu@gmail.com,"University of Cincinnati, Unversity Of Cincinnati, University of Illinois at Chicago",3,akash9182,Akash,Rana,akash9182akash@gmail.com,lakshmipriyakolli1,Lakshmi Priya,Kolli,lakshmipriya.kolli1@gmail.com,RiyanshKarani011235,Riyansh,Karani,riyansh.karani.011235@gmail.com,,,,
Most Innovative Hack(TCS),ScanAway,https://revuc-viii.devpost.com/submissions/114758-scanaway,Cloud Based Environment Control - An App to help conserve energy and make students more responsible,3/3/2019 10:15,"Inspiration

How many times have you wondered in your workspace,
 ""Why is so cold in here?"" or 
""It's so late in the night. Why are the lights still on?"" or
""I wish the washroom trash was not overflowing""

At all these instances, you would have wanted to tell someone the issue you face. We know we have.

So we built an app to do exactly that.

What it does

This App is called ScanAway. 

 The Icon of the App is the QR code for GO-BEARCATS #Interesting Fact  

Based on a location and type of place, a QR Code is generated for a given location. 
The app scans the QR Code and allows you to inform the administrators about common energy issues you face.

We have extended this app to include reporting issued faced in a restroom as well.

How We built it

It is an Android Application with a Flask server deployed on GCP's App Engine and GCP's SQL datastore.

Challenges we ran into

A significant time was spent bouncing between ideas and brainstorming before we settled on this one.
Debugging Database connection errors and configurations, especially while running the server on localhost.

Accomplishments that we're proud of

Being able to build and deploy an application in a short amount of time available.

What we learned

Learned to make an Android App.
Building a Flask app and deploying it on App Engine.

What's next for ScanAway

Data Visualization from collected data to make it easy for reducing the complaints and to spot patterns
Badges of recognition for students who are responsible enough to report the issues on a regular basis.
",,https://github.com/PriyaKolliC/Bearcat,,"android-studio, google-cloud, flask, java, android",801M-3,"University of Cincinnati; University Of Illinois,Chicago",,Google Cloud Platform,NithyasriBabu,Nithyasri,Babu,nithyasri.babu@gmail.com,"University of Cincinnati, Unversity Of Cincinnati, University of Illinois at Chicago",3,akash9182,Akash,Rana,akash9182akash@gmail.com,lakshmipriyakolli1,Lakshmi Priya,Kolli,lakshmipriya.kolli1@gmail.com,RiyanshKarani011235,Riyansh,Karani,riyansh.karani.011235@gmail.com,,,,
Best Design,ScanAway,https://revuc-viii.devpost.com/submissions/114758-scanaway,Cloud Based Environment Control - An App to help conserve energy and make students more responsible,3/3/2019 10:15,"Inspiration

How many times have you wondered in your workspace,
 ""Why is so cold in here?"" or 
""It's so late in the night. Why are the lights still on?"" or
""I wish the washroom trash was not overflowing""

At all these instances, you would have wanted to tell someone the issue you face. We know we have.

So we built an app to do exactly that.

What it does

This App is called ScanAway. 

 The Icon of the App is the QR code for GO-BEARCATS #Interesting Fact  

Based on a location and type of place, a QR Code is generated for a given location. 
The app scans the QR Code and allows you to inform the administrators about common energy issues you face.

We have extended this app to include reporting issued faced in a restroom as well.

How We built it

It is an Android Application with a Flask server deployed on GCP's App Engine and GCP's SQL datastore.

Challenges we ran into

A significant time was spent bouncing between ideas and brainstorming before we settled on this one.
Debugging Database connection errors and configurations, especially while running the server on localhost.

Accomplishments that we're proud of

Being able to build and deploy an application in a short amount of time available.

What we learned

Learned to make an Android App.
Building a Flask app and deploying it on App Engine.

What's next for ScanAway

Data Visualization from collected data to make it easy for reducing the complaints and to spot patterns
Badges of recognition for students who are responsible enough to report the issues on a regular basis.
",,https://github.com/PriyaKolliC/Bearcat,,"android-studio, google-cloud, flask, java, android",801M-3,"University of Cincinnati; University Of Illinois,Chicago",,Google Cloud Platform,NithyasriBabu,Nithyasri,Babu,nithyasri.babu@gmail.com,"University of Cincinnati, Unversity Of Cincinnati, University of Illinois at Chicago",3,akash9182,Akash,Rana,akash9182akash@gmail.com,lakshmipriyakolli1,Lakshmi Priya,Kolli,lakshmipriya.kolli1@gmail.com,RiyanshKarani011235,Riyansh,Karani,riyansh.karani.011235@gmail.com,,,,
Make the Customer's Life Easier (84.51),ScanAway,https://revuc-viii.devpost.com/submissions/114758-scanaway,Cloud Based Environment Control - An App to help conserve energy and make students more responsible,3/3/2019 10:15,"Inspiration

How many times have you wondered in your workspace,
 ""Why is so cold in here?"" or 
""It's so late in the night. Why are the lights still on?"" or
""I wish the washroom trash was not overflowing""

At all these instances, you would have wanted to tell someone the issue you face. We know we have.

So we built an app to do exactly that.

What it does

This App is called ScanAway. 

 The Icon of the App is the QR code for GO-BEARCATS #Interesting Fact  

Based on a location and type of place, a QR Code is generated for a given location. 
The app scans the QR Code and allows you to inform the administrators about common energy issues you face.

We have extended this app to include reporting issued faced in a restroom as well.

How We built it

It is an Android Application with a Flask server deployed on GCP's App Engine and GCP's SQL datastore.

Challenges we ran into

A significant time was spent bouncing between ideas and brainstorming before we settled on this one.
Debugging Database connection errors and configurations, especially while running the server on localhost.

Accomplishments that we're proud of

Being able to build and deploy an application in a short amount of time available.

What we learned

Learned to make an Android App.
Building a Flask app and deploying it on App Engine.

What's next for ScanAway

Data Visualization from collected data to make it easy for reducing the complaints and to spot patterns
Badges of recognition for students who are responsible enough to report the issues on a regular basis.
",,https://github.com/PriyaKolliC/Bearcat,,"android-studio, google-cloud, flask, java, android",801M-3,"University of Cincinnati; University Of Illinois,Chicago",,Google Cloud Platform,NithyasriBabu,Nithyasri,Babu,nithyasri.babu@gmail.com,"University of Cincinnati, Unversity Of Cincinnati, University of Illinois at Chicago",3,akash9182,Akash,Rana,akash9182akash@gmail.com,lakshmipriyakolli1,Lakshmi Priya,Kolli,lakshmipriya.kolli1@gmail.com,RiyanshKarani011235,Riyansh,Karani,riyansh.karani.011235@gmail.com,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,ScanAway,https://revuc-viii.devpost.com/submissions/114758-scanaway,Cloud Based Environment Control - An App to help conserve energy and make students more responsible,3/3/2019 10:15,"Inspiration

How many times have you wondered in your workspace,
 ""Why is so cold in here?"" or 
""It's so late in the night. Why are the lights still on?"" or
""I wish the washroom trash was not overflowing""

At all these instances, you would have wanted to tell someone the issue you face. We know we have.

So we built an app to do exactly that.

What it does

This App is called ScanAway. 

 The Icon of the App is the QR code for GO-BEARCATS #Interesting Fact  

Based on a location and type of place, a QR Code is generated for a given location. 
The app scans the QR Code and allows you to inform the administrators about common energy issues you face.

We have extended this app to include reporting issued faced in a restroom as well.

How We built it

It is an Android Application with a Flask server deployed on GCP's App Engine and GCP's SQL datastore.

Challenges we ran into

A significant time was spent bouncing between ideas and brainstorming before we settled on this one.
Debugging Database connection errors and configurations, especially while running the server on localhost.

Accomplishments that we're proud of

Being able to build and deploy an application in a short amount of time available.

What we learned

Learned to make an Android App.
Building a Flask app and deploying it on App Engine.

What's next for ScanAway

Data Visualization from collected data to make it easy for reducing the complaints and to spot patterns
Badges of recognition for students who are responsible enough to report the issues on a regular basis.
",,https://github.com/PriyaKolliC/Bearcat,,"android-studio, google-cloud, flask, java, android",801M-3,"University of Cincinnati; University Of Illinois,Chicago",,Google Cloud Platform,NithyasriBabu,Nithyasri,Babu,nithyasri.babu@gmail.com,"University of Cincinnati, Unversity Of Cincinnati, University of Illinois at Chicago",3,akash9182,Akash,Rana,akash9182akash@gmail.com,lakshmipriyakolli1,Lakshmi Priya,Kolli,lakshmipriya.kolli1@gmail.com,RiyanshKarani011235,Riyansh,Karani,riyansh.karani.011235@gmail.com,,,,
Best Hack for Social Good (JP Morgan Chase & Co),ScanAway,https://revuc-viii.devpost.com/submissions/114758-scanaway,Cloud Based Environment Control - An App to help conserve energy and make students more responsible,3/3/2019 10:15,"Inspiration

How many times have you wondered in your workspace,
 ""Why is so cold in here?"" or 
""It's so late in the night. Why are the lights still on?"" or
""I wish the washroom trash was not overflowing""

At all these instances, you would have wanted to tell someone the issue you face. We know we have.

So we built an app to do exactly that.

What it does

This App is called ScanAway. 

 The Icon of the App is the QR code for GO-BEARCATS #Interesting Fact  

Based on a location and type of place, a QR Code is generated for a given location. 
The app scans the QR Code and allows you to inform the administrators about common energy issues you face.

We have extended this app to include reporting issued faced in a restroom as well.

How We built it

It is an Android Application with a Flask server deployed on GCP's App Engine and GCP's SQL datastore.

Challenges we ran into

A significant time was spent bouncing between ideas and brainstorming before we settled on this one.
Debugging Database connection errors and configurations, especially while running the server on localhost.

Accomplishments that we're proud of

Being able to build and deploy an application in a short amount of time available.

What we learned

Learned to make an Android App.
Building a Flask app and deploying it on App Engine.

What's next for ScanAway

Data Visualization from collected data to make it easy for reducing the complaints and to spot patterns
Badges of recognition for students who are responsible enough to report the issues on a regular basis.
",,https://github.com/PriyaKolliC/Bearcat,,"android-studio, google-cloud, flask, java, android",801M-3,"University of Cincinnati; University Of Illinois,Chicago",,Google Cloud Platform,NithyasriBabu,Nithyasri,Babu,nithyasri.babu@gmail.com,"University of Cincinnati, Unversity Of Cincinnati, University of Illinois at Chicago",3,akash9182,Akash,Rana,akash9182akash@gmail.com,lakshmipriyakolli1,Lakshmi Priya,Kolli,lakshmipriya.kolli1@gmail.com,RiyanshKarani011235,Riyansh,Karani,riyansh.karani.011235@gmail.com,,,,
Best Useless Hack,Java Raycasting Engine,https://revuc-viii.devpost.com/submissions/114762-java-raycasting-engine,Raycasting engine built in java with no APIs or libraries,3/3/2019 10:23,"Inspiration

Wanted to create a three dimensional game from scratch and learn how basic 3d graphics worked.

What it does

Simulates 2d scene and raycasts from the player/camera over many angles in their field of view. Uses the distances from the player to determine how tall the wall should be at that x-coordinate.

How we built it

Created two iterations of the program in order to make it faster and condense multiple classes together.

Challenges we ran into

Some walls continue infinitely while others are cut short. Movement behaves unpredictably when player's coordinates are outside of the first quadrant. Finding a way to represent the map in a way that is understood by the program was difficult. The camera has a constant fish eye distortion. 

Accomplishments that we're proud of

Extremely lightweight with 235 lines of code.

What we learned

Basics of raycasting. Recursive flood fill algorithms (in first iteration). Implementation of key listeners in java. Integrating many classes together (in first iteration). 

What's next for Java Raycasting Engine

Fix fisheye distortion, input issues, and wall rendering issues. Add gameplay mechanics to the engine. 
",,,https://s3.amazonaws.com/challengepost/zip_files/production/41683/zip_files/JavaRaycastEngine.zip,java,801M-6,University of Toledo (x3),,,aohls,Adam,Ohls,aohls@rockets.utoledo.edu,University of Toledo,2,ajthomas,Andrew,Thomas,ajthomas@axisengineering.com,ianmahoney,Ian,Mahoney,ianmahoney@protonmail.com,,,,,,,,
Best Design,slimeboy,https://revuc-viii.devpost.com/submissions/114765-slimeboy,a video game about a slimy slimy boy,3/3/2019 10:36,"Inspiration

slime

What it does

you play as a slime character, you gotta defeat the bad guys, it's a video game

How we built it

game maker 2!!

Challenges we ran into

lots!! coding is hard

Accomplishments that we're proud of

the game!

What we learned

game make 2!!

What's next for slimeboy

gotta finish it honestly
",,,,,801-18,Kent State University,,,bhollan5,Ben,Holland,bhollan5@kent.edu,Kent State University,1,edwardallanpoe,edwardallanpoe,,ekmatyja98@gmail.com,,,,,,,,,,,,
Best Useless Hack,slimeboy,https://revuc-viii.devpost.com/submissions/114765-slimeboy,a video game about a slimy slimy boy,3/3/2019 10:36,"Inspiration

slime

What it does

you play as a slime character, you gotta defeat the bad guys, it's a video game

How we built it

game maker 2!!

Challenges we ran into

lots!! coding is hard

Accomplishments that we're proud of

the game!

What we learned

game make 2!!

What's next for slimeboy

gotta finish it honestly
",,,,,801-18,Kent State University,,,bhollan5,Ben,Holland,bhollan5@kent.edu,Kent State University,1,edwardallanpoe,edwardallanpoe,,ekmatyja98@gmail.com,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),slimeboy,https://revuc-viii.devpost.com/submissions/114765-slimeboy,a video game about a slimy slimy boy,3/3/2019 10:36,"Inspiration

slime

What it does

you play as a slime character, you gotta defeat the bad guys, it's a video game

How we built it

game maker 2!!

Challenges we ran into

lots!! coding is hard

Accomplishments that we're proud of

the game!

What we learned

game make 2!!

What's next for slimeboy

gotta finish it honestly
",,,,,801-18,Kent State University,,,bhollan5,Ben,Holland,bhollan5@kent.edu,Kent State University,1,edwardallanpoe,edwardallanpoe,,ekmatyja98@gmail.com,,,,,,,,,,,,
Best Aviation Hack (GE Aviation),Vimana Sahai,https://revuc-viii.devpost.com/submissions/114778-vimana-sahai,The AI Companion that helps you get around the airport.,3/3/2019 10:54,"Inspiration

Being an avid traveller myself and traveling to around 50 countries, I have experienced how airports of major cities work. A major problem that I faced was that it was so crowded that I cannot find my way through the airport. This idea was born out of this problem.

What it does

It is an AI bot which asks about your route and then updates you about the directions to your boarding gate. You can also ask any questions you want about the airport and the AI acts as a companion during the trip, You can use the bot to get information about delays in the flight, changes with the boarding gates and also more information about food and duty free.

How I built it

I used Recast.ai as it is a better tool for conversational AI and using this approach to solve the problem will be a better idea. 

Challenges I ran into

The workflow of the AI was a challenge as I had to make the AI understand what the user will say and it is unexpected 
for us what and how the user will approach the AI.

Accomplishments that I'm proud of

The bot can understand between different cities and also tell the user if it needs more information. The AI can distinguish between different airlines and airports.

What I learned

What I learned was how we can train the AI in such a way that we can use it for other purposes such as making it understand that different airlines can go to the same airport.

What's next for Vimana Sahai

To work on more features for the app.
",,https://amritshenava98.github.io/vimanasahai/,,"recast.ai, html, javascript",801-18,Kent State University,,,ashenava,Amrth Ashok,Shenava,ashenava@kent.edu,Kent State University,0,,,,,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),Vimana Sahai,https://revuc-viii.devpost.com/submissions/114778-vimana-sahai,The AI Companion that helps you get around the airport.,3/3/2019 10:54,"Inspiration

Being an avid traveller myself and traveling to around 50 countries, I have experienced how airports of major cities work. A major problem that I faced was that it was so crowded that I cannot find my way through the airport. This idea was born out of this problem.

What it does

It is an AI bot which asks about your route and then updates you about the directions to your boarding gate. You can also ask any questions you want about the airport and the AI acts as a companion during the trip, You can use the bot to get information about delays in the flight, changes with the boarding gates and also more information about food and duty free.

How I built it

I used Recast.ai as it is a better tool for conversational AI and using this approach to solve the problem will be a better idea. 

Challenges I ran into

The workflow of the AI was a challenge as I had to make the AI understand what the user will say and it is unexpected 
for us what and how the user will approach the AI.

Accomplishments that I'm proud of

The bot can understand between different cities and also tell the user if it needs more information. The AI can distinguish between different airlines and airports.

What I learned

What I learned was how we can train the AI in such a way that we can use it for other purposes such as making it understand that different airlines can go to the same airport.

What's next for Vimana Sahai

To work on more features for the app.
",,https://amritshenava98.github.io/vimanasahai/,,"recast.ai, html, javascript",801-18,Kent State University,,,ashenava,Amrth Ashok,Shenava,ashenava@kent.edu,Kent State University,0,,,,,,,,,,,,,,,,
 Best IoT Hack using a Qualcomm Device (MLH),ZeroTrace,https://revuc-viii.devpost.com/submissions/114789-zerotrace," Built upon IPFS, ZeroTrace is a decentralized chat app without conversation history or an ability to be censored.",3/3/2019 10:58,"Inspiration

I like the features of SnapChat, but I don't like how bulky its gotten or the fact that service operates using centralized servers that could be doing who-knows-what with my data.

What it does

This hack is a simple p2p chat app built upon the IPFS framework. Anyone with the project can communicate with other users in the same chat room, regardless of location or device. 

How I built it

First I built it using nodejs and ngrok, then I used browserify to compile the JavaScript so that I could run server-side script in the clients browser. Once I had a decent program, I migrated the project to an electron app so that it could be distributed as a cross-platform executable.(It behaves the same in browser and on the desktop.)

Challenges I ran into

I had trouble with styling the app so that it looked nice. It still doesn't look nice. I did not implement the more complex features such as direct messaging and custom aliasing.

Accomplishments that I'm proud of

This project is actually my senior project for my CS major. I started from scratch and I've gotten more accomplished at this hackathon than I have in 8 weeks of my Senior Projects course.

What I learned

I learned more about the IPFS network, how to add content to IPFS so that it can be accessed outside of a local network. I learned more about programming in pure Javascript and CSS styling.

What's next for ZeroTrace

I would like to add features such as a custom human-readable alias associated with each user in the room, direct messaging between users, the ability to save individual messages by each user (a feature of SnapChat) and the ability to send multimedia messages. The end goal would be to have a SnapChat like app that is usable enough that I could share it with my friends and communicate with them on this instead. There would also be the need for security and the ability to prove identity, which should go hand in hand. I would also want to host the project on a human readable website, powered by IPFS. 
",,https://github.com/davisv7/ZeroTrace,,"javascript, node.js, html5, ipfs, electron",860D-3,Berea College,DragonBoard 410C,,vincent_davis,Vincent,Davis,vincent_davis@berea.edu,,0,,,,,,,,,,,,,,,,
Most Innovative Hack(TCS),ZeroTrace,https://revuc-viii.devpost.com/submissions/114789-zerotrace," Built upon IPFS, ZeroTrace is a decentralized chat app without conversation history or an ability to be censored.",3/3/2019 10:58,"Inspiration

I like the features of SnapChat, but I don't like how bulky its gotten or the fact that service operates using centralized servers that could be doing who-knows-what with my data.

What it does

This hack is a simple p2p chat app built upon the IPFS framework. Anyone with the project can communicate with other users in the same chat room, regardless of location or device. 

How I built it

First I built it using nodejs and ngrok, then I used browserify to compile the JavaScript so that I could run server-side script in the clients browser. Once I had a decent program, I migrated the project to an electron app so that it could be distributed as a cross-platform executable.(It behaves the same in browser and on the desktop.)

Challenges I ran into

I had trouble with styling the app so that it looked nice. It still doesn't look nice. I did not implement the more complex features such as direct messaging and custom aliasing.

Accomplishments that I'm proud of

This project is actually my senior project for my CS major. I started from scratch and I've gotten more accomplished at this hackathon than I have in 8 weeks of my Senior Projects course.

What I learned

I learned more about the IPFS network, how to add content to IPFS so that it can be accessed outside of a local network. I learned more about programming in pure Javascript and CSS styling.

What's next for ZeroTrace

I would like to add features such as a custom human-readable alias associated with each user in the room, direct messaging between users, the ability to save individual messages by each user (a feature of SnapChat) and the ability to send multimedia messages. The end goal would be to have a SnapChat like app that is usable enough that I could share it with my friends and communicate with them on this instead. There would also be the need for security and the ability to prove identity, which should go hand in hand. I would also want to host the project on a human readable website, powered by IPFS. 
",,https://github.com/davisv7/ZeroTrace,,"javascript, node.js, html5, ipfs, electron",860D-3,Berea College,DragonBoard 410C,,vincent_davis,Vincent,Davis,vincent_davis@berea.edu,,0,,,,,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),ZeroTrace,https://revuc-viii.devpost.com/submissions/114789-zerotrace," Built upon IPFS, ZeroTrace is a decentralized chat app without conversation history or an ability to be censored.",3/3/2019 10:58,"Inspiration

I like the features of SnapChat, but I don't like how bulky its gotten or the fact that service operates using centralized servers that could be doing who-knows-what with my data.

What it does

This hack is a simple p2p chat app built upon the IPFS framework. Anyone with the project can communicate with other users in the same chat room, regardless of location or device. 

How I built it

First I built it using nodejs and ngrok, then I used browserify to compile the JavaScript so that I could run server-side script in the clients browser. Once I had a decent program, I migrated the project to an electron app so that it could be distributed as a cross-platform executable.(It behaves the same in browser and on the desktop.)

Challenges I ran into

I had trouble with styling the app so that it looked nice. It still doesn't look nice. I did not implement the more complex features such as direct messaging and custom aliasing.

Accomplishments that I'm proud of

This project is actually my senior project for my CS major. I started from scratch and I've gotten more accomplished at this hackathon than I have in 8 weeks of my Senior Projects course.

What I learned

I learned more about the IPFS network, how to add content to IPFS so that it can be accessed outside of a local network. I learned more about programming in pure Javascript and CSS styling.

What's next for ZeroTrace

I would like to add features such as a custom human-readable alias associated with each user in the room, direct messaging between users, the ability to save individual messages by each user (a feature of SnapChat) and the ability to send multimedia messages. The end goal would be to have a SnapChat like app that is usable enough that I could share it with my friends and communicate with them on this instead. There would also be the need for security and the ability to prove identity, which should go hand in hand. I would also want to host the project on a human readable website, powered by IPFS. 
",,https://github.com/davisv7/ZeroTrace,,"javascript, node.js, html5, ipfs, electron",860D-3,Berea College,DragonBoard 410C,,vincent_davis,Vincent,Davis,vincent_davis@berea.edu,,0,,,,,,,,,,,,,,,,
Best Aviation Hack (GE Aviation),Lil’ Drone,https://revuc-viii.devpost.com/submissions/114796-lil-drone,The little Drone that Couldn’t,3/3/2019 11:00,"Inspiration

Twilio demonstration at the opening ceremony.

What it does

Our drone can fly through text commands, sent to a Twilio.

How we built it

We used a raspberry pi to communicate with an Arduino that would communicate with the drone using python and interpret the commands to tell the drone how to fly. After we could establish a connection between the two we then need to create the commands that the drone could interpret to distances and use to tell the drone which attributes to use(ex: throttle, pitch, yaw, and roll)

Challenges we ran into

The biggest challenge we faced was getting the Arduino and raspberry pi to communicate. Apparently it has never been done before or so the lack of resource online lead us to believe so. Thus we have had to code and troubleshoot little by little using our best knowledge of how we could get the numbers to convert correctly and how to get the Arduino to receive what we wanted from the python. 

Accomplishments that we're proud of


Not Pulling our hair out during this Hackathon. 
## What we learned
Not every member of a team has to be great at coding in order to have a successful Hackathon.
## What's next for Lil’ Drone
Speech to Text Recognition to allow Phone Call Speech Commands

",,,,"raspberry-pi, arduino, betaflight",801c-2,UC,,,Jacobhd21,Jake,Picklesimer,picklesimer21@outlook.com,University of Cincinnati,3,Nicjtriplett,,,triplenj@mail.uc.edu,marti2rj,Robby,Martini,marti2rj@mail.uc.edu,Greeneb2,,,greeneb2@mail.uc.edu,,,,
Most Innovative Hack(TCS),Lil’ Drone,https://revuc-viii.devpost.com/submissions/114796-lil-drone,The little Drone that Couldn’t,3/3/2019 11:00,"Inspiration

Twilio demonstration at the opening ceremony.

What it does

Our drone can fly through text commands, sent to a Twilio.

How we built it

We used a raspberry pi to communicate with an Arduino that would communicate with the drone using python and interpret the commands to tell the drone how to fly. After we could establish a connection between the two we then need to create the commands that the drone could interpret to distances and use to tell the drone which attributes to use(ex: throttle, pitch, yaw, and roll)

Challenges we ran into

The biggest challenge we faced was getting the Arduino and raspberry pi to communicate. Apparently it has never been done before or so the lack of resource online lead us to believe so. Thus we have had to code and troubleshoot little by little using our best knowledge of how we could get the numbers to convert correctly and how to get the Arduino to receive what we wanted from the python. 

Accomplishments that we're proud of


Not Pulling our hair out during this Hackathon. 
## What we learned
Not every member of a team has to be great at coding in order to have a successful Hackathon.
## What's next for Lil’ Drone
Speech to Text Recognition to allow Phone Call Speech Commands

",,,,"raspberry-pi, arduino, betaflight",801c-2,UC,,,Jacobhd21,Jake,Picklesimer,picklesimer21@outlook.com,University of Cincinnati,3,Nicjtriplett,,,triplenj@mail.uc.edu,marti2rj,Robby,Martini,marti2rj@mail.uc.edu,Greeneb2,,,greeneb2@mail.uc.edu,,,,
Best Hardware Hack,Lil’ Drone,https://revuc-viii.devpost.com/submissions/114796-lil-drone,The little Drone that Couldn’t,3/3/2019 11:00,"Inspiration

Twilio demonstration at the opening ceremony.

What it does

Our drone can fly through text commands, sent to a Twilio.

How we built it

We used a raspberry pi to communicate with an Arduino that would communicate with the drone using python and interpret the commands to tell the drone how to fly. After we could establish a connection between the two we then need to create the commands that the drone could interpret to distances and use to tell the drone which attributes to use(ex: throttle, pitch, yaw, and roll)

Challenges we ran into

The biggest challenge we faced was getting the Arduino and raspberry pi to communicate. Apparently it has never been done before or so the lack of resource online lead us to believe so. Thus we have had to code and troubleshoot little by little using our best knowledge of how we could get the numbers to convert correctly and how to get the Arduino to receive what we wanted from the python. 

Accomplishments that we're proud of


Not Pulling our hair out during this Hackathon. 
## What we learned
Not every member of a team has to be great at coding in order to have a successful Hackathon.
## What's next for Lil’ Drone
Speech to Text Recognition to allow Phone Call Speech Commands

",,,,"raspberry-pi, arduino, betaflight",801c-2,UC,,,Jacobhd21,Jake,Picklesimer,picklesimer21@outlook.com,University of Cincinnati,3,Nicjtriplett,,,triplenj@mail.uc.edu,marti2rj,Robby,Martini,marti2rj@mail.uc.edu,Greeneb2,,,greeneb2@mail.uc.edu,,,,
Best Use of Twilio,Lil’ Drone,https://revuc-viii.devpost.com/submissions/114796-lil-drone,The little Drone that Couldn’t,3/3/2019 11:00,"Inspiration

Twilio demonstration at the opening ceremony.

What it does

Our drone can fly through text commands, sent to a Twilio.

How we built it

We used a raspberry pi to communicate with an Arduino that would communicate with the drone using python and interpret the commands to tell the drone how to fly. After we could establish a connection between the two we then need to create the commands that the drone could interpret to distances and use to tell the drone which attributes to use(ex: throttle, pitch, yaw, and roll)

Challenges we ran into

The biggest challenge we faced was getting the Arduino and raspberry pi to communicate. Apparently it has never been done before or so the lack of resource online lead us to believe so. Thus we have had to code and troubleshoot little by little using our best knowledge of how we could get the numbers to convert correctly and how to get the Arduino to receive what we wanted from the python. 

Accomplishments that we're proud of


Not Pulling our hair out during this Hackathon. 
## What we learned
Not every member of a team has to be great at coding in order to have a successful Hackathon.
## What's next for Lil’ Drone
Speech to Text Recognition to allow Phone Call Speech Commands

",,,,"raspberry-pi, arduino, betaflight",801c-2,UC,,,Jacobhd21,Jake,Picklesimer,picklesimer21@outlook.com,University of Cincinnati,3,Nicjtriplett,,,triplenj@mail.uc.edu,marti2rj,Robby,Martini,marti2rj@mail.uc.edu,Greeneb2,,,greeneb2@mail.uc.edu,,,,
Best Useless Hack,Lil’ Drone,https://revuc-viii.devpost.com/submissions/114796-lil-drone,The little Drone that Couldn’t,3/3/2019 11:00,"Inspiration

Twilio demonstration at the opening ceremony.

What it does

Our drone can fly through text commands, sent to a Twilio.

How we built it

We used a raspberry pi to communicate with an Arduino that would communicate with the drone using python and interpret the commands to tell the drone how to fly. After we could establish a connection between the two we then need to create the commands that the drone could interpret to distances and use to tell the drone which attributes to use(ex: throttle, pitch, yaw, and roll)

Challenges we ran into

The biggest challenge we faced was getting the Arduino and raspberry pi to communicate. Apparently it has never been done before or so the lack of resource online lead us to believe so. Thus we have had to code and troubleshoot little by little using our best knowledge of how we could get the numbers to convert correctly and how to get the Arduino to receive what we wanted from the python. 

Accomplishments that we're proud of


Not Pulling our hair out during this Hackathon. 
## What we learned
Not every member of a team has to be great at coding in order to have a successful Hackathon.
## What's next for Lil’ Drone
Speech to Text Recognition to allow Phone Call Speech Commands

",,,,"raspberry-pi, arduino, betaflight",801c-2,UC,,,Jacobhd21,Jake,Picklesimer,picklesimer21@outlook.com,University of Cincinnati,3,Nicjtriplett,,,triplenj@mail.uc.edu,marti2rj,Robby,Martini,marti2rj@mail.uc.edu,Greeneb2,,,greeneb2@mail.uc.edu,,,,
Best Useless Hack,MEME,https://revuc-viii.devpost.com/submissions/114798-meme,An fps horror based on putting dead memes where they belong.,3/3/2019 11:03,"Inspiration

Connor had an idea and we decided it sounded fun.

What it does

Created to give a haunting feeling as you waltz through a dystopian cityscape being attacked by suspicious figures. Defend yourself as you make your way to the mastermind of this invasion!

How we built it

We used unity to make the project. We also used ableton studio for original music.

Challenges we ran into

Working with unity was actually very intuitive. There were some challenging moments, like getting the health bar to function properly, but we pushed our way through.

Accomplishments that we're proud of

We made our first 3D game that's actually functional within 24 hours. Also, raycast shooting.

What we learned

We learned everything we know about unity from this weekend. Two of us have some 2D game making experience with Gamemaker Studio, but this was our first time with unity and our first 3D game.

What's next for MEME

We plan to build it and release it for free.
",https://youtu.be/kFRD8Ws2dOg,https://github.com/jib9001/MEME,,"unity, c#, ableton",801M-1,Northern Kentucky University,,,navett52,Evan,Tellep,evantellep@yahoo.com,"Northern Kentucky University, University of Cincinnati Clermont College",2,jib9001,Connor,Tellep,jib11@live.com,schuter33,Clinton,Schultz,schuter33@gmail.com,,,,,,,,
,SnapShop,https://revuc-viii.devpost.com/submissions/114799-snapshop,A clothing recognition app.,3/3/2019 11:05,"Inspiration

// Duh

What it does

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for SnapShop
",,,,"django, flutter",860B-1,Purdue,,,jamesjweber,James,Weber,weber99@purdue.edu,Purdue University,0,,,,,,,,,,,,,,,,
Most Innovative Hack(TCS),Punderwhelming.com,https://revuc-viii.devpost.com/submissions/114803-punderwhelming-com,"Entertainment website with content generated from puns. Horrifically poor, yet enjoyable puns ",3/3/2019 11:07,"Inspiration

We got here, we didn't know what we wanted to do and were unprepared before hand, so we picked something near and dear to our hearts, which was memes. Unfortunately, meme auto generation is difficult, so we settled with puns.

What it does

It uses a Markov predictability to break up sentences and mangle them back into ""sentences"". There is a pun generator button, an Markov ""enhanced"" generator button, and a Markov ""enhanced"" Bee Movie quote generator button.

How we built it

We built the website using C++, JavaScript, and the Wix Editor.

Challenges we ran into

Meme auto generation is hard. Sentence structure is hard. Servers on Google Cloud Platform are hard. Anything with Domain.com is really hard/expensive.

Accomplishments that we're proud of

Our artiste, Ethan Craig, who also does portraits in MS Paint for free (but only for the first one).

What we learned

Meme auto generation is hard. Sentence structure is hard. Servers on Google Cloud Platform are hard. Anything with Domain.com is really hard/expensive. Humor is not copy-paste. JavaScript is nifty. PHP is weird. Free doesn't necessarily mean free. Google Cloud Platform is really forgiving.

What's next for Punderwhelming

Homophone pun generation using things that work. Maybe.
",,https://huffsbus14.wixsite.com/punderwhelming,,"website, wix, javascript, c++, technical-institute-of-wikipedia",801M-4,"Ohio Northern University, University of Cincinnati, University of Cincinnati, University of Cincinnati",,,t-huff,Tim,Huff,t-huff@onu.edu,"Ohio Northern University, University of Cincinnati, University of Cincinnati Clermont College",3,huffsl,Sam,Huff,huffsl@mail.uc.edu,zachfilla,Zach,Filla,zach.filla@gmail.com,craigep,Ethan,Craig,craigep@mail.uc.edu,,,,
Best Useless Hack,Punderwhelming.com,https://revuc-viii.devpost.com/submissions/114803-punderwhelming-com,"Entertainment website with content generated from puns. Horrifically poor, yet enjoyable puns ",3/3/2019 11:07,"Inspiration

We got here, we didn't know what we wanted to do and were unprepared before hand, so we picked something near and dear to our hearts, which was memes. Unfortunately, meme auto generation is difficult, so we settled with puns.

What it does

It uses a Markov predictability to break up sentences and mangle them back into ""sentences"". There is a pun generator button, an Markov ""enhanced"" generator button, and a Markov ""enhanced"" Bee Movie quote generator button.

How we built it

We built the website using C++, JavaScript, and the Wix Editor.

Challenges we ran into

Meme auto generation is hard. Sentence structure is hard. Servers on Google Cloud Platform are hard. Anything with Domain.com is really hard/expensive.

Accomplishments that we're proud of

Our artiste, Ethan Craig, who also does portraits in MS Paint for free (but only for the first one).

What we learned

Meme auto generation is hard. Sentence structure is hard. Servers on Google Cloud Platform are hard. Anything with Domain.com is really hard/expensive. Humor is not copy-paste. JavaScript is nifty. PHP is weird. Free doesn't necessarily mean free. Google Cloud Platform is really forgiving.

What's next for Punderwhelming

Homophone pun generation using things that work. Maybe.
",,https://huffsbus14.wixsite.com/punderwhelming,,"website, wix, javascript, c++, technical-institute-of-wikipedia",801M-4,"Ohio Northern University, University of Cincinnati, University of Cincinnati, University of Cincinnati",,,t-huff,Tim,Huff,t-huff@onu.edu,"Ohio Northern University, University of Cincinnati, University of Cincinnati Clermont College",3,huffsl,Sam,Huff,huffsl@mail.uc.edu,zachfilla,Zach,Filla,zach.filla@gmail.com,craigep,Ethan,Craig,craigep@mail.uc.edu,,,,
Best Undergrad Hack (Undergrad Research),Punderwhelming.com,https://revuc-viii.devpost.com/submissions/114803-punderwhelming-com,"Entertainment website with content generated from puns. Horrifically poor, yet enjoyable puns ",3/3/2019 11:07,"Inspiration

We got here, we didn't know what we wanted to do and were unprepared before hand, so we picked something near and dear to our hearts, which was memes. Unfortunately, meme auto generation is difficult, so we settled with puns.

What it does

It uses a Markov predictability to break up sentences and mangle them back into ""sentences"". There is a pun generator button, an Markov ""enhanced"" generator button, and a Markov ""enhanced"" Bee Movie quote generator button.

How we built it

We built the website using C++, JavaScript, and the Wix Editor.

Challenges we ran into

Meme auto generation is hard. Sentence structure is hard. Servers on Google Cloud Platform are hard. Anything with Domain.com is really hard/expensive.

Accomplishments that we're proud of

Our artiste, Ethan Craig, who also does portraits in MS Paint for free (but only for the first one).

What we learned

Meme auto generation is hard. Sentence structure is hard. Servers on Google Cloud Platform are hard. Anything with Domain.com is really hard/expensive. Humor is not copy-paste. JavaScript is nifty. PHP is weird. Free doesn't necessarily mean free. Google Cloud Platform is really forgiving.

What's next for Punderwhelming

Homophone pun generation using things that work. Maybe.
",,https://huffsbus14.wixsite.com/punderwhelming,,"website, wix, javascript, c++, technical-institute-of-wikipedia",801M-4,"Ohio Northern University, University of Cincinnati, University of Cincinnati, University of Cincinnati",,,t-huff,Tim,Huff,t-huff@onu.edu,"Ohio Northern University, University of Cincinnati, University of Cincinnati Clermont College",3,huffsl,Sam,Huff,huffsl@mail.uc.edu,zachfilla,Zach,Filla,zach.filla@gmail.com,craigep,Ethan,Craig,craigep@mail.uc.edu,,,,
Best Use of Google Cloud Platform (MLH),Rejuvenating Recipes ,https://revuc-viii.devpost.com/submissions/114804-rejuvenating-recipes,"Recipes, designed at the core to make you feel better. Powered by machine learning, and a large set of health data. ",3/3/2019 11:07,"Inspiration

We've always found the intersection of health and technology to be fascinating, so we wanted to explore the very boundaries of it, and create an app that improves peoples health. This was all the inspiration we needed!  

What it does

We take data from health sources, community members, and machine learning and apply this towards a suggestion model that can help predict what foods/recipes can best help you feel better!

How we built it

We made use of lots of web technologies like flask, requests, etc. We also used allot of python to create our own API for getting our web data we used during the project. Vue.js was used in this project to create the entire front end, and mobile apps for iOS and Android have been made!

Challenges we ran into

We had challenges with gathering the data/putting it together with the correct relationships. Data science is an amazing platform that we have not worked with in the past but we were excited to work with it this time around!

Accomplishments that we're proud of

We accomplished a fully working demo with a working database, web app, mobile apps. And we learned allot of new technologies in the meantime!

What we learned

We learned allot of data science and how you can apply that into a software application. We also learned about how to program a dynamic front end with Vue.js. Working with swift was out of our experience, but we were excited to have it running on the iOS platform. 

What's next for Rejuvenating Recipes

The next things for our project would be to include a better machine learning model, one that is trained with highly confident data, and could better serve those who used the app. 
",,,,"json, vue, swift, java, flask, requests, firebase, google-cloud, database, docker, kubernetes, bootstrap, apache, api, nginx",801B-5,University of Cincinnati,,,Skytek65,Skyler,Martin,skytek65@gmail.com,"Unversity Of Cincinnati, University of Cincinnati",3,griffihs,Henry,Griffiths,griffihs@mail.uc.edu,Pr0metheus,Aidan,Hembree,aidan.hembree56@gmail.com,noahbirrer,Noah,Birrer,noahbirrer@gmail.com,,,,
Best Design,Rejuvenating Recipes ,https://revuc-viii.devpost.com/submissions/114804-rejuvenating-recipes,"Recipes, designed at the core to make you feel better. Powered by machine learning, and a large set of health data. ",3/3/2019 11:07,"Inspiration

We've always found the intersection of health and technology to be fascinating, so we wanted to explore the very boundaries of it, and create an app that improves peoples health. This was all the inspiration we needed!  

What it does

We take data from health sources, community members, and machine learning and apply this towards a suggestion model that can help predict what foods/recipes can best help you feel better!

How we built it

We made use of lots of web technologies like flask, requests, etc. We also used allot of python to create our own API for getting our web data we used during the project. Vue.js was used in this project to create the entire front end, and mobile apps for iOS and Android have been made!

Challenges we ran into

We had challenges with gathering the data/putting it together with the correct relationships. Data science is an amazing platform that we have not worked with in the past but we were excited to work with it this time around!

Accomplishments that we're proud of

We accomplished a fully working demo with a working database, web app, mobile apps. And we learned allot of new technologies in the meantime!

What we learned

We learned allot of data science and how you can apply that into a software application. We also learned about how to program a dynamic front end with Vue.js. Working with swift was out of our experience, but we were excited to have it running on the iOS platform. 

What's next for Rejuvenating Recipes

The next things for our project would be to include a better machine learning model, one that is trained with highly confident data, and could better serve those who used the app. 
",,,,"json, vue, swift, java, flask, requests, firebase, google-cloud, database, docker, kubernetes, bootstrap, apache, api, nginx",801B-5,University of Cincinnati,,,Skytek65,Skyler,Martin,skytek65@gmail.com,"Unversity Of Cincinnati, University of Cincinnati",3,griffihs,Henry,Griffiths,griffihs@mail.uc.edu,Pr0metheus,Aidan,Hembree,aidan.hembree56@gmail.com,noahbirrer,Noah,Birrer,noahbirrer@gmail.com,,,,
Make the Customer's Life Easier (84.51),Rejuvenating Recipes ,https://revuc-viii.devpost.com/submissions/114804-rejuvenating-recipes,"Recipes, designed at the core to make you feel better. Powered by machine learning, and a large set of health data. ",3/3/2019 11:07,"Inspiration

We've always found the intersection of health and technology to be fascinating, so we wanted to explore the very boundaries of it, and create an app that improves peoples health. This was all the inspiration we needed!  

What it does

We take data from health sources, community members, and machine learning and apply this towards a suggestion model that can help predict what foods/recipes can best help you feel better!

How we built it

We made use of lots of web technologies like flask, requests, etc. We also used allot of python to create our own API for getting our web data we used during the project. Vue.js was used in this project to create the entire front end, and mobile apps for iOS and Android have been made!

Challenges we ran into

We had challenges with gathering the data/putting it together with the correct relationships. Data science is an amazing platform that we have not worked with in the past but we were excited to work with it this time around!

Accomplishments that we're proud of

We accomplished a fully working demo with a working database, web app, mobile apps. And we learned allot of new technologies in the meantime!

What we learned

We learned allot of data science and how you can apply that into a software application. We also learned about how to program a dynamic front end with Vue.js. Working with swift was out of our experience, but we were excited to have it running on the iOS platform. 

What's next for Rejuvenating Recipes

The next things for our project would be to include a better machine learning model, one that is trained with highly confident data, and could better serve those who used the app. 
",,,,"json, vue, swift, java, flask, requests, firebase, google-cloud, database, docker, kubernetes, bootstrap, apache, api, nginx",801B-5,University of Cincinnati,,,Skytek65,Skyler,Martin,skytek65@gmail.com,"Unversity Of Cincinnati, University of Cincinnati",3,griffihs,Henry,Griffiths,griffihs@mail.uc.edu,Pr0metheus,Aidan,Hembree,aidan.hembree56@gmail.com,noahbirrer,Noah,Birrer,noahbirrer@gmail.com,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,Rejuvenating Recipes ,https://revuc-viii.devpost.com/submissions/114804-rejuvenating-recipes,"Recipes, designed at the core to make you feel better. Powered by machine learning, and a large set of health data. ",3/3/2019 11:07,"Inspiration

We've always found the intersection of health and technology to be fascinating, so we wanted to explore the very boundaries of it, and create an app that improves peoples health. This was all the inspiration we needed!  

What it does

We take data from health sources, community members, and machine learning and apply this towards a suggestion model that can help predict what foods/recipes can best help you feel better!

How we built it

We made use of lots of web technologies like flask, requests, etc. We also used allot of python to create our own API for getting our web data we used during the project. Vue.js was used in this project to create the entire front end, and mobile apps for iOS and Android have been made!

Challenges we ran into

We had challenges with gathering the data/putting it together with the correct relationships. Data science is an amazing platform that we have not worked with in the past but we were excited to work with it this time around!

Accomplishments that we're proud of

We accomplished a fully working demo with a working database, web app, mobile apps. And we learned allot of new technologies in the meantime!

What we learned

We learned allot of data science and how you can apply that into a software application. We also learned about how to program a dynamic front end with Vue.js. Working with swift was out of our experience, but we were excited to have it running on the iOS platform. 

What's next for Rejuvenating Recipes

The next things for our project would be to include a better machine learning model, one that is trained with highly confident data, and could better serve those who used the app. 
",,,,"json, vue, swift, java, flask, requests, firebase, google-cloud, database, docker, kubernetes, bootstrap, apache, api, nginx",801B-5,University of Cincinnati,,,Skytek65,Skyler,Martin,skytek65@gmail.com,"Unversity Of Cincinnati, University of Cincinnati",3,griffihs,Henry,Griffiths,griffihs@mail.uc.edu,Pr0metheus,Aidan,Hembree,aidan.hembree56@gmail.com,noahbirrer,Noah,Birrer,noahbirrer@gmail.com,,,,
Best Hack for Social Good (JP Morgan Chase & Co),Rejuvenating Recipes ,https://revuc-viii.devpost.com/submissions/114804-rejuvenating-recipes,"Recipes, designed at the core to make you feel better. Powered by machine learning, and a large set of health data. ",3/3/2019 11:07,"Inspiration

We've always found the intersection of health and technology to be fascinating, so we wanted to explore the very boundaries of it, and create an app that improves peoples health. This was all the inspiration we needed!  

What it does

We take data from health sources, community members, and machine learning and apply this towards a suggestion model that can help predict what foods/recipes can best help you feel better!

How we built it

We made use of lots of web technologies like flask, requests, etc. We also used allot of python to create our own API for getting our web data we used during the project. Vue.js was used in this project to create the entire front end, and mobile apps for iOS and Android have been made!

Challenges we ran into

We had challenges with gathering the data/putting it together with the correct relationships. Data science is an amazing platform that we have not worked with in the past but we were excited to work with it this time around!

Accomplishments that we're proud of

We accomplished a fully working demo with a working database, web app, mobile apps. And we learned allot of new technologies in the meantime!

What we learned

We learned allot of data science and how you can apply that into a software application. We also learned about how to program a dynamic front end with Vue.js. Working with swift was out of our experience, but we were excited to have it running on the iOS platform. 

What's next for Rejuvenating Recipes

The next things for our project would be to include a better machine learning model, one that is trained with highly confident data, and could better serve those who used the app. 
",,,,"json, vue, swift, java, flask, requests, firebase, google-cloud, database, docker, kubernetes, bootstrap, apache, api, nginx",801B-5,University of Cincinnati,,,Skytek65,Skyler,Martin,skytek65@gmail.com,"Unversity Of Cincinnati, University of Cincinnati",3,griffihs,Henry,Griffiths,griffihs@mail.uc.edu,Pr0metheus,Aidan,Hembree,aidan.hembree56@gmail.com,noahbirrer,Noah,Birrer,noahbirrer@gmail.com,,,,
Best Design,Cover Art Mosaic,https://revuc-viii.devpost.com/submissions/114806-cover-art-mosaic,Ever wanted to see what your favorite album's cover art looks like made out of OTHER cover art? Now you can!,3/3/2019 11:13,"Inspiration

I came to this hackathon not knowing what exactly to make, only that I wanted to use the Spotify API and some kind of image processing with OpenCV. What I ended up producing is more of an art project, the finds the average color of a chunk of pixels, and finds the closest match in a local repository of album art to make a pretty mosaic!

Process

I ended up downloading the album art from musicbrainz, an online database of all things music (song titles, years, metadata, etc.). This is taking up about 500MB or half a gigabyte of data on my computer. Storing the images this way is much better for speed and making less API calls when the script is running. 
Because this image processing app is running on a few year old laptop, I had to think a lot about efficiency and storing things in sensible ways. This also included cleaning data with Powershell scripts, running tens of command prompts running a python script at the same time with a batch file. 

Problems

The ""official"" python API implementation listed on Spotify's website was very outdated, and the API itself has changed so that this library doesn't work. I ended up finding an open source, and well-kept Python web API for Spotify that worked great. 
Since I'm running an image processing app, it's fairly computing intensive. Being that this is running and crunching a lot of numbers, I have to limit the resolution that I can make the mosaic out of, and it still takes a good amount of time to run.
",,https://github.com/mattertater/album-art-collage,,"python, opencv, spotify, musicbrainz, powershell, batch",801-14,The University of Akron,,,mattertater,Matt,McDade,mmcdade9@gmail.com,The University of Akron,0,,,,,,,,,,,,,,,,
Best Useless Hack,Cover Art Mosaic,https://revuc-viii.devpost.com/submissions/114806-cover-art-mosaic,Ever wanted to see what your favorite album's cover art looks like made out of OTHER cover art? Now you can!,3/3/2019 11:13,"Inspiration

I came to this hackathon not knowing what exactly to make, only that I wanted to use the Spotify API and some kind of image processing with OpenCV. What I ended up producing is more of an art project, the finds the average color of a chunk of pixels, and finds the closest match in a local repository of album art to make a pretty mosaic!

Process

I ended up downloading the album art from musicbrainz, an online database of all things music (song titles, years, metadata, etc.). This is taking up about 500MB or half a gigabyte of data on my computer. Storing the images this way is much better for speed and making less API calls when the script is running. 
Because this image processing app is running on a few year old laptop, I had to think a lot about efficiency and storing things in sensible ways. This also included cleaning data with Powershell scripts, running tens of command prompts running a python script at the same time with a batch file. 

Problems

The ""official"" python API implementation listed on Spotify's website was very outdated, and the API itself has changed so that this library doesn't work. I ended up finding an open source, and well-kept Python web API for Spotify that worked great. 
Since I'm running an image processing app, it's fairly computing intensive. Being that this is running and crunching a lot of numbers, I have to limit the resolution that I can make the mosaic out of, and it still takes a good amount of time to run.
",,https://github.com/mattertater/album-art-collage,,"python, opencv, spotify, musicbrainz, powershell, batch",801-14,The University of Akron,,,mattertater,Matt,McDade,mmcdade9@gmail.com,The University of Akron,0,,,,,,,,,,,,,,,,
Best Use of Snapkit (MLH),"Snap, Paper, Scissors!",https://revuc-viii.devpost.com/submissions/114807-snap-paper-scissors,"Need to settle a score with your friends?  Snap, Paper, Scissors! is the best way to settle a dispute.",3/3/2019 11:15,"Inspiration

If you ever needed to settle a dispute, like who will take out the garbage or what language should we code in, then you probably played rock-paper-scissors.  If there is a dispute in your SnapChat group chat, then Snap, Paper, Scissors! is for you!

What it does

This is a web-based app that plays rock paper scissors against an opponent.  The game keeps score of the wins and losses for each player and displays them in the scoreboard.  You can log in with your SnapChat and play with your friends.

How I built it

Snap, Paper, Scissors! is built using HTML and Javascript.  With the integration of SnapKit's Web SDK, players can against their SnapChat friends.

Challenges I ran into

Many challenges hindered the progress of the application, including typos in file names and incompatible image types.  I am used to programming in Notepad++, but for this project decided to switch to the atom IDE for all HTML, CSS, and Javascript files.  The SnapKit SDK would be blocked by the network's firewall that prevented testing on the login for SnapChat users.

Accomplishments that I'm proud of

I am proud of the UI and backend script.  It was a challenge to try to program a beautiful user interface (while I'm not a graphics designer) and the backend programming is not my strength either.  I am proud that I was able to develop the UI.

What I learned

I learned how to use the atom IDE to create web apps and script files.  I also learned how to code the logic for a rock-paper-scissors game.

What's next for Snap, Paper, Scissors!

We hope to make the web app mobile friendly and integrate the SnapKit to be used in SnapChat group chats.
",,https://github.com/CringeCoder/Snap-paper-scissors,https://s3.amazonaws.com/challengepost/zip_files/production/41718/zip_files/snap-paper-scissors.zip,"html5, css3, javascript, snapchat, snapkit",860D-4,Lawrence Technological University,,,nfraylick,Neil,Fraylick,29neiljf@gmail.com,Lawrence Technological University,2,kyletomczik,kyletomczik,Tomczik,ktomczik@ltu.edu,hdavies,Hunter,Davies,hdavies@ltu.edu,,,,,,,,
Best Design,"Snap, Paper, Scissors!",https://revuc-viii.devpost.com/submissions/114807-snap-paper-scissors,"Need to settle a score with your friends?  Snap, Paper, Scissors! is the best way to settle a dispute.",3/3/2019 11:15,"Inspiration

If you ever needed to settle a dispute, like who will take out the garbage or what language should we code in, then you probably played rock-paper-scissors.  If there is a dispute in your SnapChat group chat, then Snap, Paper, Scissors! is for you!

What it does

This is a web-based app that plays rock paper scissors against an opponent.  The game keeps score of the wins and losses for each player and displays them in the scoreboard.  You can log in with your SnapChat and play with your friends.

How I built it

Snap, Paper, Scissors! is built using HTML and Javascript.  With the integration of SnapKit's Web SDK, players can against their SnapChat friends.

Challenges I ran into

Many challenges hindered the progress of the application, including typos in file names and incompatible image types.  I am used to programming in Notepad++, but for this project decided to switch to the atom IDE for all HTML, CSS, and Javascript files.  The SnapKit SDK would be blocked by the network's firewall that prevented testing on the login for SnapChat users.

Accomplishments that I'm proud of

I am proud of the UI and backend script.  It was a challenge to try to program a beautiful user interface (while I'm not a graphics designer) and the backend programming is not my strength either.  I am proud that I was able to develop the UI.

What I learned

I learned how to use the atom IDE to create web apps and script files.  I also learned how to code the logic for a rock-paper-scissors game.

What's next for Snap, Paper, Scissors!

We hope to make the web app mobile friendly and integrate the SnapKit to be used in SnapChat group chats.
",,https://github.com/CringeCoder/Snap-paper-scissors,https://s3.amazonaws.com/challengepost/zip_files/production/41718/zip_files/snap-paper-scissors.zip,"html5, css3, javascript, snapchat, snapkit",860D-4,Lawrence Technological University,,,nfraylick,Neil,Fraylick,29neiljf@gmail.com,Lawrence Technological University,2,kyletomczik,kyletomczik,Tomczik,ktomczik@ltu.edu,hdavies,Hunter,Davies,hdavies@ltu.edu,,,,,,,,
Best Use of Google Cloud Platform (MLH),Codan the Programming Barbarian,https://revuc-viii.devpost.com/submissions/114809-codan-the-programming-barbarian,A sidescroller where you battle Bad Code,3/3/2019 11:20,"Codan the Programming Barbarian is a game that a few of us have wanted to make after John first came up with it. We made this game mostly for experience, none of us had much experience in game development, and Unity made our first experience fairly painless. While we faced many challenges, I couldn't imagine trying to learn a new language too. We all use C# in our classes, so C# being offered with Unity is a big bonus.

Codan is a WebGL game, which can easily be ported to a standalone app, Windows Store app, Mobile app, or anything else that Unity Supports. We attempted to host our project on our website domain we got from domains.com, but ran into many many issues. This was unfortunate, we were proud of the domain www.codanbarbarian.net. But we were focused on a web game and managed to use UCFilespace for the project.
",,http://homepages.uc.edu/~godseyte/Codan/index.html,,"unity, c#",801M-1,University of Cincinnati Clermont,,,tuckergodsey,tucker,godsey,tucker.godsey@gmail.com,University of Cincinnati Clermont College,3,SirPounceAlot,SirPounceAlot,,johnrlocklear@gmail.com,cturner0098,cturner0098,,cturner0098@gmail.com,DrSlugger,DrSlugger,,kylemarler@outlook.com,,,,
 Best Domain Registered with Domain.com (MLH),Codan the Programming Barbarian,https://revuc-viii.devpost.com/submissions/114809-codan-the-programming-barbarian,A sidescroller where you battle Bad Code,3/3/2019 11:20,"Codan the Programming Barbarian is a game that a few of us have wanted to make after John first came up with it. We made this game mostly for experience, none of us had much experience in game development, and Unity made our first experience fairly painless. While we faced many challenges, I couldn't imagine trying to learn a new language too. We all use C# in our classes, so C# being offered with Unity is a big bonus.

Codan is a WebGL game, which can easily be ported to a standalone app, Windows Store app, Mobile app, or anything else that Unity Supports. We attempted to host our project on our website domain we got from domains.com, but ran into many many issues. This was unfortunate, we were proud of the domain www.codanbarbarian.net. But we were focused on a web game and managed to use UCFilespace for the project.
",,http://homepages.uc.edu/~godseyte/Codan/index.html,,"unity, c#",801M-1,University of Cincinnati Clermont,,,tuckergodsey,tucker,godsey,tucker.godsey@gmail.com,University of Cincinnati Clermont College,3,SirPounceAlot,SirPounceAlot,,johnrlocklear@gmail.com,cturner0098,cturner0098,,cturner0098@gmail.com,DrSlugger,DrSlugger,,kylemarler@outlook.com,,,,
Best Design,Codan the Programming Barbarian,https://revuc-viii.devpost.com/submissions/114809-codan-the-programming-barbarian,A sidescroller where you battle Bad Code,3/3/2019 11:20,"Codan the Programming Barbarian is a game that a few of us have wanted to make after John first came up with it. We made this game mostly for experience, none of us had much experience in game development, and Unity made our first experience fairly painless. While we faced many challenges, I couldn't imagine trying to learn a new language too. We all use C# in our classes, so C# being offered with Unity is a big bonus.

Codan is a WebGL game, which can easily be ported to a standalone app, Windows Store app, Mobile app, or anything else that Unity Supports. We attempted to host our project on our website domain we got from domains.com, but ran into many many issues. This was unfortunate, we were proud of the domain www.codanbarbarian.net. But we were focused on a web game and managed to use UCFilespace for the project.
",,http://homepages.uc.edu/~godseyte/Codan/index.html,,"unity, c#",801M-1,University of Cincinnati Clermont,,,tuckergodsey,tucker,godsey,tucker.godsey@gmail.com,University of Cincinnati Clermont College,3,SirPounceAlot,SirPounceAlot,,johnrlocklear@gmail.com,cturner0098,cturner0098,,cturner0098@gmail.com,DrSlugger,DrSlugger,,kylemarler@outlook.com,,,,
Best Useless Hack,Codan the Programming Barbarian,https://revuc-viii.devpost.com/submissions/114809-codan-the-programming-barbarian,A sidescroller where you battle Bad Code,3/3/2019 11:20,"Codan the Programming Barbarian is a game that a few of us have wanted to make after John first came up with it. We made this game mostly for experience, none of us had much experience in game development, and Unity made our first experience fairly painless. While we faced many challenges, I couldn't imagine trying to learn a new language too. We all use C# in our classes, so C# being offered with Unity is a big bonus.

Codan is a WebGL game, which can easily be ported to a standalone app, Windows Store app, Mobile app, or anything else that Unity Supports. We attempted to host our project on our website domain we got from domains.com, but ran into many many issues. This was unfortunate, we were proud of the domain www.codanbarbarian.net. But we were focused on a web game and managed to use UCFilespace for the project.
",,http://homepages.uc.edu/~godseyte/Codan/index.html,,"unity, c#",801M-1,University of Cincinnati Clermont,,,tuckergodsey,tucker,godsey,tucker.godsey@gmail.com,University of Cincinnati Clermont College,3,SirPounceAlot,SirPounceAlot,,johnrlocklear@gmail.com,cturner0098,cturner0098,,cturner0098@gmail.com,DrSlugger,DrSlugger,,kylemarler@outlook.com,,,,
Best Undergrad Hack (Undergrad Research),Codan the Programming Barbarian,https://revuc-viii.devpost.com/submissions/114809-codan-the-programming-barbarian,A sidescroller where you battle Bad Code,3/3/2019 11:20,"Codan the Programming Barbarian is a game that a few of us have wanted to make after John first came up with it. We made this game mostly for experience, none of us had much experience in game development, and Unity made our first experience fairly painless. While we faced many challenges, I couldn't imagine trying to learn a new language too. We all use C# in our classes, so C# being offered with Unity is a big bonus.

Codan is a WebGL game, which can easily be ported to a standalone app, Windows Store app, Mobile app, or anything else that Unity Supports. We attempted to host our project on our website domain we got from domains.com, but ran into many many issues. This was unfortunate, we were proud of the domain www.codanbarbarian.net. But we were focused on a web game and managed to use UCFilespace for the project.
",,http://homepages.uc.edu/~godseyte/Codan/index.html,,"unity, c#",801M-1,University of Cincinnati Clermont,,,tuckergodsey,tucker,godsey,tucker.godsey@gmail.com,University of Cincinnati Clermont College,3,SirPounceAlot,SirPounceAlot,,johnrlocklear@gmail.com,cturner0098,cturner0098,,cturner0098@gmail.com,DrSlugger,DrSlugger,,kylemarler@outlook.com,,,,
,FastCheckOut,https://revuc-viii.devpost.com/submissions/114811-fastcheckout,Hackathon Project,3/3/2019 11:23,"Inspiration

Waiting in long queues at grocery shops really suck! Isn't there something we can do about it?

What it does

Our app gives user faster checkout options when shopping in-store. This application retains the fun of shopping in-store with the fast checkout convenience of online shopping.
When you are shopping for items, you can right away scan those and add them to your cart. After completing the cart, the app generate a QRCode for you. You can directly scan it at the POS to enable payment.
Our app provides ease of use, as it does not require login or other hassles of adding items manually.

How we built it

We built a super cool fast android application that uses barcode scanner on your android mobile application

Challenges we ran into

Running Android Studio and doing the initial configurations for doing the development, working with a lot of libraries for the QR Reader.

Accomplishments that we're proud of

We completed a fully functional mobile app, starting with absolutely 0 knowledge in android development. Kudos to us!!

What we learned

No one in our team had built a mobile app before, or even attended a hackathon. From brainstorming ideas to asking the mentors on what ide to download, we have learnt a lot in the last 24 hours.

What's next for FastCheckOut

Integrating it with the huge Kroger data, bringing in the functionalities for Kroger Card members and going big!
",,https://github.com/prasadrane/Rev_UC,,"java, android-studio",860B-3,University of Cincinnati,,,roypi,Pallavi,Roy,roypi@mail.uc.edu,University of Cincinnati,2,prasadrane,Prasad,Rane,emailprasadrane@gmail.com,mattkirsch13,Matthew,Kirsch,mattkirsch13@yahoo.com,,,,,,,,
Most Innovative Hack(TCS),cinGUI,https://revuc-viii.devpost.com/submissions/114812-cingui,Terminal and GUI combined at long last!,3/3/2019 11:24,"This program is cinGUI, an application designed to act as a mixture between a terminal and GUI by utilizing the curses library. The goal behind its development was to provide a tool for network administrators and programmers who may be restricted to only terminal use (whether due to SSH'ing into Linux machines or running in a command line only OS) to have a way to graphically represent data. The program can act almost exactly like a regular terminal could with additional features such as being able to make custom commands and functions for quick and easy access to repeatable tasks.
We created a program that took over the console window, redrawing every aspect of it while keeping the same functionality of the console. It can perform any console command including executing other programs. What was different our program and the console was that our program allowed live on the spot scripting allowing the user to increase their work efficiency. 
This project was a major learning experience for everyone on the team. At the time of creating the program, Chandler was only 5 weeks into an Intro to C++ class, so he experimented with reading data in from files, vectors, and cementing his mastery with arrays. He made the first sample file to test cinGUI and to demo, Austin oversaw figuring out how to make a C++ program start and run a separate, different program. With this, he ended up learning about parallel computing and race conditions which he wouldn't get to in his classes until a year after by the time of writing the program. Scott oversaw getting the GUI elements of the program to function and setting up the piping network. In the process, he learned how to implement the curses library, set up pipeline networks, and forking files.
",,https://github.com/d3bird/RevolutionHackathon,,"c++, makefile",801A-3,ohio university,,,d3bird,Scott,Crawford,dogbird9@gmail.com,"Ohio State University, Ohio University - Main Campus",2,brimstone925,Austin,Nutter,an021916@ohio.edu,GraveeTrain,GraveeTrain,,chanman_ok@yahoo.com,,,,,,,,
Best Design,cinGUI,https://revuc-viii.devpost.com/submissions/114812-cingui,Terminal and GUI combined at long last!,3/3/2019 11:24,"This program is cinGUI, an application designed to act as a mixture between a terminal and GUI by utilizing the curses library. The goal behind its development was to provide a tool for network administrators and programmers who may be restricted to only terminal use (whether due to SSH'ing into Linux machines or running in a command line only OS) to have a way to graphically represent data. The program can act almost exactly like a regular terminal could with additional features such as being able to make custom commands and functions for quick and easy access to repeatable tasks.
We created a program that took over the console window, redrawing every aspect of it while keeping the same functionality of the console. It can perform any console command including executing other programs. What was different our program and the console was that our program allowed live on the spot scripting allowing the user to increase their work efficiency. 
This project was a major learning experience for everyone on the team. At the time of creating the program, Chandler was only 5 weeks into an Intro to C++ class, so he experimented with reading data in from files, vectors, and cementing his mastery with arrays. He made the first sample file to test cinGUI and to demo, Austin oversaw figuring out how to make a C++ program start and run a separate, different program. With this, he ended up learning about parallel computing and race conditions which he wouldn't get to in his classes until a year after by the time of writing the program. Scott oversaw getting the GUI elements of the program to function and setting up the piping network. In the process, he learned how to implement the curses library, set up pipeline networks, and forking files.
",,https://github.com/d3bird/RevolutionHackathon,,"c++, makefile",801A-3,ohio university,,,d3bird,Scott,Crawford,dogbird9@gmail.com,"Ohio State University, Ohio University - Main Campus",2,brimstone925,Austin,Nutter,an021916@ohio.edu,GraveeTrain,GraveeTrain,,chanman_ok@yahoo.com,,,,,,,,
Best Use of Google Cloud Platform (MLH),SQRL,https://revuc-viii.devpost.com/submissions/114814-sqrl,We interfaced the Muse headband with Google Cloud Services to make an accessibility resources hub.,3/3/2019 11:27,"SQRL

Hackathon 2019 revolutionuc
",,https://github.com/56kyle/SQRL,,"python, css, html, google-spreadsheets, google-cloud, google-app-engine, flask, jinja",860D-4,University of Cincinnati,Muse Headband,Google Cloud Platform,56kyle,Kyle,Oliver,56kyleoliver@gmail.com,University of Cincinnati,1,khanjh,Jihad,Khan,khanjh@mail.uc.edu,,,,,,,,,,,,
Best Use of Twilio,SQRL,https://revuc-viii.devpost.com/submissions/114814-sqrl,We interfaced the Muse headband with Google Cloud Services to make an accessibility resources hub.,3/3/2019 11:27,"SQRL

Hackathon 2019 revolutionuc
",,https://github.com/56kyle/SQRL,,"python, css, html, google-spreadsheets, google-cloud, google-app-engine, flask, jinja",860D-4,University of Cincinnati,Muse Headband,Google Cloud Platform,56kyle,Kyle,Oliver,56kyleoliver@gmail.com,University of Cincinnati,1,khanjh,Jihad,Khan,khanjh@mail.uc.edu,,,,,,,,,,,,
Best Design,SQRL,https://revuc-viii.devpost.com/submissions/114814-sqrl,We interfaced the Muse headband with Google Cloud Services to make an accessibility resources hub.,3/3/2019 11:27,"SQRL

Hackathon 2019 revolutionuc
",,https://github.com/56kyle/SQRL,,"python, css, html, google-spreadsheets, google-cloud, google-app-engine, flask, jinja",860D-4,University of Cincinnati,Muse Headband,Google Cloud Platform,56kyle,Kyle,Oliver,56kyleoliver@gmail.com,University of Cincinnati,1,khanjh,Jihad,Khan,khanjh@mail.uc.edu,,,,,,,,,,,,
Best Useless Hack,SQRL,https://revuc-viii.devpost.com/submissions/114814-sqrl,We interfaced the Muse headband with Google Cloud Services to make an accessibility resources hub.,3/3/2019 11:27,"SQRL

Hackathon 2019 revolutionuc
",,https://github.com/56kyle/SQRL,,"python, css, html, google-spreadsheets, google-cloud, google-app-engine, flask, jinja",860D-4,University of Cincinnati,Muse Headband,Google Cloud Platform,56kyle,Kyle,Oliver,56kyleoliver@gmail.com,University of Cincinnati,1,khanjh,Jihad,Khan,khanjh@mail.uc.edu,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),SQRL,https://revuc-viii.devpost.com/submissions/114814-sqrl,We interfaced the Muse headband with Google Cloud Services to make an accessibility resources hub.,3/3/2019 11:27,"SQRL

Hackathon 2019 revolutionuc
",,https://github.com/56kyle/SQRL,,"python, css, html, google-spreadsheets, google-cloud, google-app-engine, flask, jinja",860D-4,University of Cincinnati,Muse Headband,Google Cloud Platform,56kyle,Kyle,Oliver,56kyleoliver@gmail.com,University of Cincinnati,1,khanjh,Jihad,Khan,khanjh@mail.uc.edu,,,,,,,,,,,,
Make the Customer's Life Easier (84.51),SQRL,https://revuc-viii.devpost.com/submissions/114814-sqrl,We interfaced the Muse headband with Google Cloud Services to make an accessibility resources hub.,3/3/2019 11:27,"SQRL

Hackathon 2019 revolutionuc
",,https://github.com/56kyle/SQRL,,"python, css, html, google-spreadsheets, google-cloud, google-app-engine, flask, jinja",860D-4,University of Cincinnati,Muse Headband,Google Cloud Platform,56kyle,Kyle,Oliver,56kyleoliver@gmail.com,University of Cincinnati,1,khanjh,Jihad,Khan,khanjh@mail.uc.edu,,,,,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,SQRL,https://revuc-viii.devpost.com/submissions/114814-sqrl,We interfaced the Muse headband with Google Cloud Services to make an accessibility resources hub.,3/3/2019 11:27,"SQRL

Hackathon 2019 revolutionuc
",,https://github.com/56kyle/SQRL,,"python, css, html, google-spreadsheets, google-cloud, google-app-engine, flask, jinja",860D-4,University of Cincinnati,Muse Headband,Google Cloud Platform,56kyle,Kyle,Oliver,56kyleoliver@gmail.com,University of Cincinnati,1,khanjh,Jihad,Khan,khanjh@mail.uc.edu,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),SQRL,https://revuc-viii.devpost.com/submissions/114814-sqrl,We interfaced the Muse headband with Google Cloud Services to make an accessibility resources hub.,3/3/2019 11:27,"SQRL

Hackathon 2019 revolutionuc
",,https://github.com/56kyle/SQRL,,"python, css, html, google-spreadsheets, google-cloud, google-app-engine, flask, jinja",860D-4,University of Cincinnati,Muse Headband,Google Cloud Platform,56kyle,Kyle,Oliver,56kyleoliver@gmail.com,University of Cincinnati,1,khanjh,Jihad,Khan,khanjh@mail.uc.edu,,,,,,,,,,,,
,Polyfy,https://revuc-viii.devpost.com/submissions/114818-polyfy,Create low poly art by video and images in realtime,3/3/2019 11:37,"Inspiration

Creating a unique piece of art for people that want a different perspective on art.

What it does

Creates low poly art from images and in real-time by video using Delaunay triangulation andFeatures from accelerated segment test (FAST)

How we built it

Javascript and using delaunator.

Challenges we ran into

Figuring out the math required to create the polygons.

Accomplishments that we're proud of

Creating the art in real-time.

What we learned

How we can further advance the art world by creating a more abstract version of art.

What's next for Polyfy

Extracting the image of someones face and only applying our application to the face.

Related articles

https://en.wikipedia.org/wiki/Delaunay_triangulation

https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test
",,https://github.com/ChrisDesigns/polyfy,,"javascript, delaunator, phoboslab",801-17,Kent State University,,,flarellation,flarellation,Redmond,redmondnj1@gmail.com,"Columbus State Community College, Kent State University",2,clenart4,Chris,Lenart,clenart4@kent.edu,ascheider525,ascheider525,,ascheider525@gmail.com,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),Stand Up,https://revuc-viii.devpost.com/submissions/114819-stand-up,An app to help people who are trying to buy products based on the effect that they have on the environment. ,3/3/2019 11:37,"Inspiration:

Throughout high school, I volunteered for a zoo for 4 years and I became passionate about conservation issues. Because of this, I am now a Communication major focusing on Public Relations because I loved talking to people about these issues. My life goal is to work for a company like World Wildlife Fund doing public relations. Having this background of caring for the environment, I like knowing that the products I am buying are as environmentally friendly as possible. That's where I got the idea for this app.

What it does:

This app scans the barcodes of products (currently only food- want to expand it to all other products as well) and tells you if that product does something good for the environment! Currently, it can tell you if the product uses sustainable palm oil, if it's vegan, if it the company has some sort of recycling plan, and if they do not use sustainable palm oil. 

How I built it:

I built this with android studio, java, an API called Nutritionix, and lots of tutorials!

Challenges I ran into:

I ran into lots of challenges trying to understand what different errors meant and how I should fix them. I also had a hard time understanding most of the things I was seeing in the tutorials because I have never done this before! 

Accomplishments that I'm proud of:

I'm proud because I have never coded anything before in my life. I've never looked at android studio or code before this hackathon! A few days before I downloaded android studio but I didn't have any time to really check it out before! 

What I learned:

I learned so much! I learned how android studio works and where different things go.  

What's next for Stand Up:

I would love to expand the scanning feature to all products so that while someone is walking through the store they can scan anything and know its impacts on the environment! I would also love to add more features like a section where you can find out how to help a specific animal in your daily life, a section to read different blogs, a section to sign petitions, etc. I would love if this app could be a ""one-stop shop"" for people who want to be conscious of their decisions! The possibilities are endless! 
",,,,"java, api, android-studio, barcode-scanner",801B-5,University of Cincinnati,,,pacean,Amanda,Pace,pacean@mail.uc.edu,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Useless Hack,ENED Simulator 2019,https://revuc-viii.devpost.com/submissions/114821-ened-simulator-2019,Just a realistic simulation of the beauty of ENED.,3/3/2019 11:41,"ENED-Simulator-2019

Just a realistic simulation of the beauty of ENED.
This project was a rollercoaster of sorrow and laughter. In short, our plan was to design a pointless game that would allow anyone to experience the horrors (and numerous inside jokes) associated with the introductory engineering courses at UC. Thus, ENED Simulator was born.

In order to get this whole thing running, our team had to learn SFML (a third party library) to utilize C++ code in a GUI. This process was incredibly challenging, but also very rewarding. We also implemented the numerous header files associated with VCPKG, a third party that allowed us to work with SFML in Visual Studio.

After much deliberation discussing how exactly we wanted the game to run, we spent the better part of 15 hours creating the greatest game known to mankind. Hope you enjoy!
",,https://github.com/corncob567/ENED-Simulator-2019,,"c++, sfml, vcpkg",801-15,University of Cincinnati CEAS,,,corncob567,Daniel,Hackney,corncob567dh@gmail.com,University of Cincinnati,2,mreagan3200,mreagan3200,,m.reagan3200@gmail.com,wpritschau,wpritschau,,wpritschau@gmail.com,,,,,,,,
Best Undergrad Hack (Undergrad Research),ENED Simulator 2019,https://revuc-viii.devpost.com/submissions/114821-ened-simulator-2019,Just a realistic simulation of the beauty of ENED.,3/3/2019 11:41,"ENED-Simulator-2019

Just a realistic simulation of the beauty of ENED.
This project was a rollercoaster of sorrow and laughter. In short, our plan was to design a pointless game that would allow anyone to experience the horrors (and numerous inside jokes) associated with the introductory engineering courses at UC. Thus, ENED Simulator was born.

In order to get this whole thing running, our team had to learn SFML (a third party library) to utilize C++ code in a GUI. This process was incredibly challenging, but also very rewarding. We also implemented the numerous header files associated with VCPKG, a third party that allowed us to work with SFML in Visual Studio.

After much deliberation discussing how exactly we wanted the game to run, we spent the better part of 15 hours creating the greatest game known to mankind. Hope you enjoy!
",,https://github.com/corncob567/ENED-Simulator-2019,,"c++, sfml, vcpkg",801-15,University of Cincinnati CEAS,,,corncob567,Daniel,Hackney,corncob567dh@gmail.com,University of Cincinnati,2,mreagan3200,mreagan3200,,m.reagan3200@gmail.com,wpritschau,wpritschau,,wpritschau@gmail.com,,,,,,,,
Best Design,Les Catacombes de Paris,https://revuc-viii.devpost.com/submissions/114825-les-catacombes-de-paris,"An Arcade-style dungeon crawl, with action for one or two players, where you are the monster in the depths below.",3/3/2019 11:44,"Inspiration

Inspired by a nightmare fever dream about haunting the Parisian underground, the madness of a torturous dream combined with the rush of a time limit culminate in a twisted tale. Play through the adventures of the wraith and a demon, as they feast upon the bodies and souls of human intruders. Will you succumb to the scourge of crusaders and tourists, or will you reign supreme in the Catacombs of Paris?

What it does

This game features the movement of two separate characters who must work together to defend against intruders. The demon, Terreur, who can feast on the flesh of humans, unless they are armed against unholy beings. The wraith, Peur, can unleash a pulse of wicked energy that will send even the boldest crusaders cowering defenselessly. Once scared, the crusaders are easily devoured, leaving a soul behind for Peur to consume.

How I built it

This game was built in Unity3d, albeit in a two-dimensional setting. All character pieces are locked onto a grid, where they are permitted to move one space per action. The characters have their individual collision boxes that let the determined interactions take place. All scores and kill counts are sent to a central processing object, which computes Win/Loss conditions, as well as score and game progress. 

Challenges I ran into

Collision avoidance for enemies was tricky, trying to think about it in terms of ""proximity rectangles,"" or bounds that exist relative to an objects location, that check for a target in its parameters. The discrete square-by-square movement was also tricky, this was resolved by giving the physics bodies a directional velocity for a time, after which the object would snap to its supposed final location. The velocity of the object is calculated such that it moves right into its final destination.

Accomplishments that I'm proud of

This whole game was a solo project, meaning I had to work tirelessly to start and complete the game within the 24 hour time limit. Not only did I have to do all the code and environment construction, all the character designs and spritework, as well as game design fell on my shoulders. It was a lot of work to get an aesthetic and functional object, but it was a thoroughly satisfying experience, as well as a great product to show to colleagues and family.

What I learned

Programming an enemy AI that responds to the player's input and positioning is the biggest learning curve I encountered in my project, since not only did I have to get an appropriate response, the response had to be reformatted to fit the movement rules of the game. 

What's next for Les Catacombes de Paris

I hope to polish up this game in the future, to smoke out a few bugs, as well as adding a few new features and levels, and maybe even an involved storyline. This game has great potential and can definitely be improved with more time and sanity.

Game Rules

The Wraith(Tall Skeletal One) is controlled with WASD. the Demon(Short Toothy One) is controlled with arrow keys. Movement occurs when the buttons are pushed. The Demon can  eat tourists (humans in yellow and orange), but will fall if touched by sane Crusader (red and white humans with the hats.)  Defeat all the human invaders to win. The Wraith can unleash a cross shaped blast that can cause humans to be frightened. (They will emit purple spheres when scared.) When crusaders are frightened, they can be eaten by the Demon. Although the Wraith will fall if touched by any humans, killed humans will drop a soul when killed. These souls are worth a lot of points, but will only persist for a bit before losing power and vanishing. If one character falls, they can be revived by the other. However, if both characters fall, it's game over! 
",,https://drive.google.com/open?id=1TitxQApgKlNlMIRWWcCWdn4QsfEkbpC8,https://s3.amazonaws.com/challengepost/zip_files/production/41724/zip_files/Catacombes.zip,"unity, artrage-lite, inkscape, c#",801-3,University of Cincinnati,,,tilicojedi,Nicolas,Ortiz,tilicojedi@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Useless Hack,Les Catacombes de Paris,https://revuc-viii.devpost.com/submissions/114825-les-catacombes-de-paris,"An Arcade-style dungeon crawl, with action for one or two players, where you are the monster in the depths below.",3/3/2019 11:44,"Inspiration

Inspired by a nightmare fever dream about haunting the Parisian underground, the madness of a torturous dream combined with the rush of a time limit culminate in a twisted tale. Play through the adventures of the wraith and a demon, as they feast upon the bodies and souls of human intruders. Will you succumb to the scourge of crusaders and tourists, or will you reign supreme in the Catacombs of Paris?

What it does

This game features the movement of two separate characters who must work together to defend against intruders. The demon, Terreur, who can feast on the flesh of humans, unless they are armed against unholy beings. The wraith, Peur, can unleash a pulse of wicked energy that will send even the boldest crusaders cowering defenselessly. Once scared, the crusaders are easily devoured, leaving a soul behind for Peur to consume.

How I built it

This game was built in Unity3d, albeit in a two-dimensional setting. All character pieces are locked onto a grid, where they are permitted to move one space per action. The characters have their individual collision boxes that let the determined interactions take place. All scores and kill counts are sent to a central processing object, which computes Win/Loss conditions, as well as score and game progress. 

Challenges I ran into

Collision avoidance for enemies was tricky, trying to think about it in terms of ""proximity rectangles,"" or bounds that exist relative to an objects location, that check for a target in its parameters. The discrete square-by-square movement was also tricky, this was resolved by giving the physics bodies a directional velocity for a time, after which the object would snap to its supposed final location. The velocity of the object is calculated such that it moves right into its final destination.

Accomplishments that I'm proud of

This whole game was a solo project, meaning I had to work tirelessly to start and complete the game within the 24 hour time limit. Not only did I have to do all the code and environment construction, all the character designs and spritework, as well as game design fell on my shoulders. It was a lot of work to get an aesthetic and functional object, but it was a thoroughly satisfying experience, as well as a great product to show to colleagues and family.

What I learned

Programming an enemy AI that responds to the player's input and positioning is the biggest learning curve I encountered in my project, since not only did I have to get an appropriate response, the response had to be reformatted to fit the movement rules of the game. 

What's next for Les Catacombes de Paris

I hope to polish up this game in the future, to smoke out a few bugs, as well as adding a few new features and levels, and maybe even an involved storyline. This game has great potential and can definitely be improved with more time and sanity.

Game Rules

The Wraith(Tall Skeletal One) is controlled with WASD. the Demon(Short Toothy One) is controlled with arrow keys. Movement occurs when the buttons are pushed. The Demon can  eat tourists (humans in yellow and orange), but will fall if touched by sane Crusader (red and white humans with the hats.)  Defeat all the human invaders to win. The Wraith can unleash a cross shaped blast that can cause humans to be frightened. (They will emit purple spheres when scared.) When crusaders are frightened, they can be eaten by the Demon. Although the Wraith will fall if touched by any humans, killed humans will drop a soul when killed. These souls are worth a lot of points, but will only persist for a bit before losing power and vanishing. If one character falls, they can be revived by the other. However, if both characters fall, it's game over! 
",,https://drive.google.com/open?id=1TitxQApgKlNlMIRWWcCWdn4QsfEkbpC8,https://s3.amazonaws.com/challengepost/zip_files/production/41724/zip_files/Catacombes.zip,"unity, artrage-lite, inkscape, c#",801-3,University of Cincinnati,,,tilicojedi,Nicolas,Ortiz,tilicojedi@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
 Best Domain Registered with Domain.com (MLH),Store Savr,https://revuc-viii.devpost.com/submissions/114828-store-savr,Easier way to save time and money,3/3/2019 11:45,"Inspiration

When looking at current solutions like ClickList and others that allow you to buy groceries online and have them brought to your car, we noticed a hole in the market. A large amount of people want the convenience of ordering before they go, but don't want to pay extra or wait around for the employees to bring the product to their car.

What it does

This app allows people to order their products online before they head to the store, then they can go to the store and pick them up themselves. Before leaving the employee would only have to check and make sure that the consumer has only the items they ordered. This saves tons of time for the consumer, while also saving the employer money. This in turn allows the consumers to have a lower overall cost.

How we built it

We built this app by starting with the backend service. We created an API that runs on an Express server and communicates with data stored in Postgresql. We containerized this application so that it can be run easily on any server. The server communicates through a REST api.

The website, or the admin page, is built in React and can be accessed through https://storesavr.com (username: dominic password: pa$$word), you will also have to accept the self-signed certificate. This page is made to edit the stores and their respective layouts. The layout editor has 3 different types of items you can click on and add to the editor. A long shelf, short shelf, and an end-cap. These can be dragged out and rotated after they are added. The entire editor can be panned as well.

The app that we built to demonstrate what the consumer would experience is built in react native. This gave us the flexibility to compile to both iOS and Android, along with having similar code to the admin web portal.

Challenges we ran into

One of the biggest challenges we ran into was running our continuous integration pipeline. We had it set such that if any one member creates a push to the repository, the server would automatically build this application. One of the largest challenges we had was that during the continuous building, we had an issue with one of the libraries we were using. It was our password hashing library and we could not avoid it. It turned out that we needed to install the C++ make files on our docker container to allow it to compile. This took way longer than we expected, but we learned a lot in the process.

Accomplishments that we're proud of

The biggest accomplishment of our application is the draggable editor that we used for the store layout. This took a while for us to perfect, and we are happy with how it came out. It allows users to move their store components into any location and rotation they want, along with choosing which items are in each component.

What we learned

We learned how to work together on one single GitHub repository. This was rocky at the start, but we quickly learned to split the work by files or concerns so that none of our changes conflicted with each other's. 

What's next for Store Savr

A few of the features we want to implement is to add more layout options, along with a fully feature-complete ordering experience. Finding a team member who has a design background would greatly help the app's overall look and feel, as developers can only go so far. We are excited to see the potential this app could bring to the market.
",,https://storesavr.com,,"kubernetes, docker, node.js, react, react-native, redux, javascript, express.js, domain.com, postgresql, rancher",801M-5,Ohio University,,Domain.com,nathanstead,Nathan,Steadman,nathanstead@gmail.com,Ohio University - Main Campus,2,BlenderDude,Daniel,Abdelsamed,legonxtphd@gmail.com,DominicBen,DominicBen,,bdominic00@gmail.com,,,,,,,,
Best Undergrad Hack (Undergrad Research),Store Savr,https://revuc-viii.devpost.com/submissions/114828-store-savr,Easier way to save time and money,3/3/2019 11:45,"Inspiration

When looking at current solutions like ClickList and others that allow you to buy groceries online and have them brought to your car, we noticed a hole in the market. A large amount of people want the convenience of ordering before they go, but don't want to pay extra or wait around for the employees to bring the product to their car.

What it does

This app allows people to order their products online before they head to the store, then they can go to the store and pick them up themselves. Before leaving the employee would only have to check and make sure that the consumer has only the items they ordered. This saves tons of time for the consumer, while also saving the employer money. This in turn allows the consumers to have a lower overall cost.

How we built it

We built this app by starting with the backend service. We created an API that runs on an Express server and communicates with data stored in Postgresql. We containerized this application so that it can be run easily on any server. The server communicates through a REST api.

The website, or the admin page, is built in React and can be accessed through https://storesavr.com (username: dominic password: pa$$word), you will also have to accept the self-signed certificate. This page is made to edit the stores and their respective layouts. The layout editor has 3 different types of items you can click on and add to the editor. A long shelf, short shelf, and an end-cap. These can be dragged out and rotated after they are added. The entire editor can be panned as well.

The app that we built to demonstrate what the consumer would experience is built in react native. This gave us the flexibility to compile to both iOS and Android, along with having similar code to the admin web portal.

Challenges we ran into

One of the biggest challenges we ran into was running our continuous integration pipeline. We had it set such that if any one member creates a push to the repository, the server would automatically build this application. One of the largest challenges we had was that during the continuous building, we had an issue with one of the libraries we were using. It was our password hashing library and we could not avoid it. It turned out that we needed to install the C++ make files on our docker container to allow it to compile. This took way longer than we expected, but we learned a lot in the process.

Accomplishments that we're proud of

The biggest accomplishment of our application is the draggable editor that we used for the store layout. This took a while for us to perfect, and we are happy with how it came out. It allows users to move their store components into any location and rotation they want, along with choosing which items are in each component.

What we learned

We learned how to work together on one single GitHub repository. This was rocky at the start, but we quickly learned to split the work by files or concerns so that none of our changes conflicted with each other's. 

What's next for Store Savr

A few of the features we want to implement is to add more layout options, along with a fully feature-complete ordering experience. Finding a team member who has a design background would greatly help the app's overall look and feel, as developers can only go so far. We are excited to see the potential this app could bring to the market.
",,https://storesavr.com,,"kubernetes, docker, node.js, react, react-native, redux, javascript, express.js, domain.com, postgresql, rancher",801M-5,Ohio University,,Domain.com,nathanstead,Nathan,Steadman,nathanstead@gmail.com,Ohio University - Main Campus,2,BlenderDude,Daniel,Abdelsamed,legonxtphd@gmail.com,DominicBen,DominicBen,,bdominic00@gmail.com,,,,,,,,
Make the Customer's Life Easier (84.51),Store Savr,https://revuc-viii.devpost.com/submissions/114828-store-savr,Easier way to save time and money,3/3/2019 11:45,"Inspiration

When looking at current solutions like ClickList and others that allow you to buy groceries online and have them brought to your car, we noticed a hole in the market. A large amount of people want the convenience of ordering before they go, but don't want to pay extra or wait around for the employees to bring the product to their car.

What it does

This app allows people to order their products online before they head to the store, then they can go to the store and pick them up themselves. Before leaving the employee would only have to check and make sure that the consumer has only the items they ordered. This saves tons of time for the consumer, while also saving the employer money. This in turn allows the consumers to have a lower overall cost.

How we built it

We built this app by starting with the backend service. We created an API that runs on an Express server and communicates with data stored in Postgresql. We containerized this application so that it can be run easily on any server. The server communicates through a REST api.

The website, or the admin page, is built in React and can be accessed through https://storesavr.com (username: dominic password: pa$$word), you will also have to accept the self-signed certificate. This page is made to edit the stores and their respective layouts. The layout editor has 3 different types of items you can click on and add to the editor. A long shelf, short shelf, and an end-cap. These can be dragged out and rotated after they are added. The entire editor can be panned as well.

The app that we built to demonstrate what the consumer would experience is built in react native. This gave us the flexibility to compile to both iOS and Android, along with having similar code to the admin web portal.

Challenges we ran into

One of the biggest challenges we ran into was running our continuous integration pipeline. We had it set such that if any one member creates a push to the repository, the server would automatically build this application. One of the largest challenges we had was that during the continuous building, we had an issue with one of the libraries we were using. It was our password hashing library and we could not avoid it. It turned out that we needed to install the C++ make files on our docker container to allow it to compile. This took way longer than we expected, but we learned a lot in the process.

Accomplishments that we're proud of

The biggest accomplishment of our application is the draggable editor that we used for the store layout. This took a while for us to perfect, and we are happy with how it came out. It allows users to move their store components into any location and rotation they want, along with choosing which items are in each component.

What we learned

We learned how to work together on one single GitHub repository. This was rocky at the start, but we quickly learned to split the work by files or concerns so that none of our changes conflicted with each other's. 

What's next for Store Savr

A few of the features we want to implement is to add more layout options, along with a fully feature-complete ordering experience. Finding a team member who has a design background would greatly help the app's overall look and feel, as developers can only go so far. We are excited to see the potential this app could bring to the market.
",,https://storesavr.com,,"kubernetes, docker, node.js, react, react-native, redux, javascript, express.js, domain.com, postgresql, rancher",801M-5,Ohio University,,Domain.com,nathanstead,Nathan,Steadman,nathanstead@gmail.com,Ohio University - Main Campus,2,BlenderDude,Daniel,Abdelsamed,legonxtphd@gmail.com,DominicBen,DominicBen,,bdominic00@gmail.com,,,,,,,,
Best Aviation Hack (GE Aviation),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
 Best IoT Hack using a Qualcomm Device (MLH),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Use of Google Cloud Platform (MLH),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Use of Azure (Microsoft),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Use of Snapkit (MLH),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Most Innovative Hack(TCS),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Hardware Hack,Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Use of Twilio,Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
 Best Domain Registered with Domain.com (MLH),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Design,Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Useless Hack,Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Make the Customer's Life Easier (84.51),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),Polyglotté,https://revuc-viii.devpost.com/submissions/114834-polyglotte,Learning languages using real-time camera,3/3/2019 11:46,"Inspiration

Last year, our parents visited us from China during the summer break.
Do you dream of your son flipping between 4 different languages as you sip Latte overlooking an Italian sunset or dream of visiting Paris with a daughter who can negotiate like a local?

If that’s what your into, you should start encouraging them to start learning a foreign language. However, the kids learned in school is on book. 

The human brain is a wonderful thing. From the moment we are born, we learn by six main ways, by


 Sight
 Taste
 Smell
 Sound
 Touch
 Doing.


We have built a web based tool that can help people learn a language by connecting these ways. Imaging you hold a cup of hot coffee which smells really good, and now the computer tells you how to speak and display ""coffee"" in five different languages. You will learn this word very quick efficient.

What it does

The Polylatte web tool opens the camera on your laptop to obtain a image. Based on your choice, either to detect the object or text in the image, it translate the word into five different languages.

How we built it


 We use HTML and Javascript to build a scene inside the webpage and stream from real time webcam
 Ajax
 OpenCV


-  Machine learning

Challenges we ran into


 Communication between the image captured by webcam, backend computation, and display


Accomplishments that we're proud of


 This is a very useful tool that we built for kids to encourage them to learn more languages, which can opens another world for them
 This tool is also very helpful for people who is traveling around the world, without input the words by hands, a simple realtime camera can be your guide


What we learned


 Team work 
 Creative thinking
 There is more can be done to help the community


What's next for Polylatte


 Account 
 IOS app

",https://youtu.be/bkpgarincVw,https://github.com/siqi-chen/translator,,"python, opencv, css, machine-learning, ajax, html5, javascript, flask",801C-3,"University of Cincinnati, University of Dayton",,,dellvo,Siqi,Chen,sq.d.chen@gmail.com,,1,QQshigesha,Pengfei ,Guo,pf.d.guo@gmail.com,,,,,,,,,,,,
Best Use of Google Cloud Platform (MLH),Automation Logging,https://revuc-viii.devpost.com/submissions/114848-automation-logging,Our project idea would solve enterprise automation deployment using Docker and logging system problems using Kibana.,3/3/2019 11:52,"Inspiration

We have research about the most traditionally ineffective practices around Enterprises/Tech Companies. Traditionally, there is a sort of culture to have script inside code to automate the process of deploying the application onto the web server  using .drone.yml usually which is very ineffective because in this process, businesses have to buy a lot of servers to host their applications. We noticed this problem and brainstormed on this and come up with technologies to work with. For second part of the project 'logging system', we talked to people about server logs in UC. They are paying huge amount of to get logs for their systems so we wanted to find a better solutions, which is free and effective in collecting relative data. 

What it does

It improves the automation process by putting applications into docker container by making image of those applications. Then store that image onto google-cloud-platform and use it to tell Kubernetes which application to deploy on one main Kubernetes sites. In this way, web application can be host onto one Kubernetes sever and it will look something like this 'Kubernetes:service1', 'Kubernetes:service2'. Then the next part is our logging system by having setup a APM server to make connection between logging system and web applications. In this way multiple web applications can communicate to logging system and send hosting system and service logs. 

How we built it

We started with created sample javascript application from where we can track multiple logs and traces. Then we made script inside app.js to connect the application to Kibana logging system. We tested it throughout the process locally. Once we see that logging system is connected to app then we created dashboards and visualizations to get relevant data. Then we started working on deployment process. First we created a script to make image inside Dockerfile then we build image out of it which we then stored it into Google cloud platform. We were making changes to our applications to and making sure that was it updating the image or not. This is where versioning control part plays out. Then we created Kubernetes on command line where we would be hosting our applications. We ran through a lot of steps to set up. Then we created new app for our application along 3 pods and deployed our application onto it. Then we keep making changes to our application and it keeps updating the application.

Challenges we ran into


It was so difficult to figure out how to connect Mongodb database to application because we are using login page for the applications. 
Figuring out how to get virtual box on Mac for Kubernetes to work on. 
Minikube was going down so we had to figure out that as well to how to keep it running.
To setup everything inside multiple docker container so if one thing goes down, other will be up
To configure the logging system to get relevant data which would actually be meaningful to developers and system admin person and also clients
Use of bootstrap in our application gave us a hard time.


Accomplishments that we're proud of


We accomplished the way to host multiple services onto one server using automation docker deployment process
get the logging which traces 


What we learned


create automated logging system from scratch
Working around Docker and google cloud platforms 
Learned how to store docker images into google cloud platform and using it globally for deployment


What's next for Automation Logging


Enterprise companies can implement this automation deployment process and the logging system into their development and staging environment. 
To help business to monitor their systems and microservices 

",,https://github.uc.edu/sukhbirsekhon/automatedLog.git,,"docker, node.js, kubernetes, elk, css, html5, mongodb, bootstrap, minikube, kubectl, github, visual-studio, google-cloud",801G-3,University of Cincinnati,,Google Cloud Platform,sukhbirsekhon,sukhbirsekhon,,sekhonss@mail.uc.edu,University of Cincinnati,2,sandhups,Paramjyot,Sandhu,sandhups@mail.uc.edu,calebbotter1,Caleb,Botteri,calebbotter1@gmail.com,,,,,,,,
Best Undergrad Hack (Undergrad Research),Automation Logging,https://revuc-viii.devpost.com/submissions/114848-automation-logging,Our project idea would solve enterprise automation deployment using Docker and logging system problems using Kibana.,3/3/2019 11:52,"Inspiration

We have research about the most traditionally ineffective practices around Enterprises/Tech Companies. Traditionally, there is a sort of culture to have script inside code to automate the process of deploying the application onto the web server  using .drone.yml usually which is very ineffective because in this process, businesses have to buy a lot of servers to host their applications. We noticed this problem and brainstormed on this and come up with technologies to work with. For second part of the project 'logging system', we talked to people about server logs in UC. They are paying huge amount of to get logs for their systems so we wanted to find a better solutions, which is free and effective in collecting relative data. 

What it does

It improves the automation process by putting applications into docker container by making image of those applications. Then store that image onto google-cloud-platform and use it to tell Kubernetes which application to deploy on one main Kubernetes sites. In this way, web application can be host onto one Kubernetes sever and it will look something like this 'Kubernetes:service1', 'Kubernetes:service2'. Then the next part is our logging system by having setup a APM server to make connection between logging system and web applications. In this way multiple web applications can communicate to logging system and send hosting system and service logs. 

How we built it

We started with created sample javascript application from where we can track multiple logs and traces. Then we made script inside app.js to connect the application to Kibana logging system. We tested it throughout the process locally. Once we see that logging system is connected to app then we created dashboards and visualizations to get relevant data. Then we started working on deployment process. First we created a script to make image inside Dockerfile then we build image out of it which we then stored it into Google cloud platform. We were making changes to our applications to and making sure that was it updating the image or not. This is where versioning control part plays out. Then we created Kubernetes on command line where we would be hosting our applications. We ran through a lot of steps to set up. Then we created new app for our application along 3 pods and deployed our application onto it. Then we keep making changes to our application and it keeps updating the application.

Challenges we ran into


It was so difficult to figure out how to connect Mongodb database to application because we are using login page for the applications. 
Figuring out how to get virtual box on Mac for Kubernetes to work on. 
Minikube was going down so we had to figure out that as well to how to keep it running.
To setup everything inside multiple docker container so if one thing goes down, other will be up
To configure the logging system to get relevant data which would actually be meaningful to developers and system admin person and also clients
Use of bootstrap in our application gave us a hard time.


Accomplishments that we're proud of


We accomplished the way to host multiple services onto one server using automation docker deployment process
get the logging which traces 


What we learned


create automated logging system from scratch
Working around Docker and google cloud platforms 
Learned how to store docker images into google cloud platform and using it globally for deployment


What's next for Automation Logging


Enterprise companies can implement this automation deployment process and the logging system into their development and staging environment. 
To help business to monitor their systems and microservices 

",,https://github.uc.edu/sukhbirsekhon/automatedLog.git,,"docker, node.js, kubernetes, elk, css, html5, mongodb, bootstrap, minikube, kubectl, github, visual-studio, google-cloud",801G-3,University of Cincinnati,,Google Cloud Platform,sukhbirsekhon,sukhbirsekhon,,sekhonss@mail.uc.edu,University of Cincinnati,2,sandhups,Paramjyot,Sandhu,sandhups@mail.uc.edu,calebbotter1,Caleb,Botteri,calebbotter1@gmail.com,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,Automation Logging,https://revuc-viii.devpost.com/submissions/114848-automation-logging,Our project idea would solve enterprise automation deployment using Docker and logging system problems using Kibana.,3/3/2019 11:52,"Inspiration

We have research about the most traditionally ineffective practices around Enterprises/Tech Companies. Traditionally, there is a sort of culture to have script inside code to automate the process of deploying the application onto the web server  using .drone.yml usually which is very ineffective because in this process, businesses have to buy a lot of servers to host their applications. We noticed this problem and brainstormed on this and come up with technologies to work with. For second part of the project 'logging system', we talked to people about server logs in UC. They are paying huge amount of to get logs for their systems so we wanted to find a better solutions, which is free and effective in collecting relative data. 

What it does

It improves the automation process by putting applications into docker container by making image of those applications. Then store that image onto google-cloud-platform and use it to tell Kubernetes which application to deploy on one main Kubernetes sites. In this way, web application can be host onto one Kubernetes sever and it will look something like this 'Kubernetes:service1', 'Kubernetes:service2'. Then the next part is our logging system by having setup a APM server to make connection between logging system and web applications. In this way multiple web applications can communicate to logging system and send hosting system and service logs. 

How we built it

We started with created sample javascript application from where we can track multiple logs and traces. Then we made script inside app.js to connect the application to Kibana logging system. We tested it throughout the process locally. Once we see that logging system is connected to app then we created dashboards and visualizations to get relevant data. Then we started working on deployment process. First we created a script to make image inside Dockerfile then we build image out of it which we then stored it into Google cloud platform. We were making changes to our applications to and making sure that was it updating the image or not. This is where versioning control part plays out. Then we created Kubernetes on command line where we would be hosting our applications. We ran through a lot of steps to set up. Then we created new app for our application along 3 pods and deployed our application onto it. Then we keep making changes to our application and it keeps updating the application.

Challenges we ran into


It was so difficult to figure out how to connect Mongodb database to application because we are using login page for the applications. 
Figuring out how to get virtual box on Mac for Kubernetes to work on. 
Minikube was going down so we had to figure out that as well to how to keep it running.
To setup everything inside multiple docker container so if one thing goes down, other will be up
To configure the logging system to get relevant data which would actually be meaningful to developers and system admin person and also clients
Use of bootstrap in our application gave us a hard time.


Accomplishments that we're proud of


We accomplished the way to host multiple services onto one server using automation docker deployment process
get the logging which traces 


What we learned


create automated logging system from scratch
Working around Docker and google cloud platforms 
Learned how to store docker images into google cloud platform and using it globally for deployment


What's next for Automation Logging


Enterprise companies can implement this automation deployment process and the logging system into their development and staging environment. 
To help business to monitor their systems and microservices 

",,https://github.uc.edu/sukhbirsekhon/automatedLog.git,,"docker, node.js, kubernetes, elk, css, html5, mongodb, bootstrap, minikube, kubectl, github, visual-studio, google-cloud",801G-3,University of Cincinnati,,Google Cloud Platform,sukhbirsekhon,sukhbirsekhon,,sekhonss@mail.uc.edu,University of Cincinnati,2,sandhups,Paramjyot,Sandhu,sandhups@mail.uc.edu,calebbotter1,Caleb,Botteri,calebbotter1@gmail.com,,,,,,,,
Best Aviation Hack (GE Aviation),VR Planetarium,https://revuc-viii.devpost.com/submissions/114856-vr-planetarium,Explore our wonderful solar system in a to-scale VR environment,3/3/2019 11:55,"Inspiration

3 of our 4 group members had never used Oculus Rift or any VR headset before, so we were very interested in exploring virtual reality with the cool hardware provided. We bounced a couple ideas off of each other while we brainstormed and settled on creating an educational VR application to teach users more about the scale and mechanisms of our solar system.

What it does

VR Planetarium puts the user onboard a ship similar to Cosmos's Ship of The Imagination, in which physical laws such as the speed of light are transcended for the sake of intellectual exploration.

How we built it

Our tech stack was composed of Unity3D, .NET, C#, and Oculus Rift's API. We also used both Git and a Git-like collaborative tool that is built into Unity3D simply called ""collab"". We were all new to C# and had no experience with Unity3D, which made it very rewarding to end with a final product.

Challenges we ran into

We had some difficulties in finding a good workflow for debugging, as we came across many old tutorials or forms of documentation. To make matters worse, some iterations that worked fine in the local debugger didn't function in any way in the final Oculus Rift application. Our workflow naturally became more efficient but it was still difficult to guarantee that certain features would port to the final VR application before actually building and testing it.

Accomplishments that we're proud of

We're proud of building a functioning application as a result of rapidly learning how to work with design in Unity3D, as well as appending code to objects with C#. We were also able to simultaneously learn more about the solar system by researching the relative sizes and orbital radii. We were also able to accept input from a controller to navigate the camera around the VR Planetarium around 3 axes.

What we learned

Besides working with a tech stack that was entirely new to us, our team learned how to do software development as a group and established a good workflow by the end of the Hackathon. We also learned how much red bull our bodies could handle (>400mg of caffeine).

What's next for VR Planetarium

One recommendation that we've received from many people so far is improving the flow of the controls. Our current version simply allows the user to move along each of the three axes at right angles, without allowing for rotation of the spaceship. This would be the number one thing we would improve. We would also like to add information about each planet that could appear to the user as they approach the planet.
",,https://github.com/noahtren/unity_build,,"c#, unity, oculus, git",801-7,1,Oculus Rift,,omarsyd,Omar,Alsayed,omarsyd@ymail.com,University of Cincinnati,2,noahtren,Noah,Trenaman,noahtren@gmail.com,muncyce,Chloe,Muncy,muncyce@mail.uc.edu,,,,,,,,
Best Design,VR Planetarium,https://revuc-viii.devpost.com/submissions/114856-vr-planetarium,Explore our wonderful solar system in a to-scale VR environment,3/3/2019 11:55,"Inspiration

3 of our 4 group members had never used Oculus Rift or any VR headset before, so we were very interested in exploring virtual reality with the cool hardware provided. We bounced a couple ideas off of each other while we brainstormed and settled on creating an educational VR application to teach users more about the scale and mechanisms of our solar system.

What it does

VR Planetarium puts the user onboard a ship similar to Cosmos's Ship of The Imagination, in which physical laws such as the speed of light are transcended for the sake of intellectual exploration.

How we built it

Our tech stack was composed of Unity3D, .NET, C#, and Oculus Rift's API. We also used both Git and a Git-like collaborative tool that is built into Unity3D simply called ""collab"". We were all new to C# and had no experience with Unity3D, which made it very rewarding to end with a final product.

Challenges we ran into

We had some difficulties in finding a good workflow for debugging, as we came across many old tutorials or forms of documentation. To make matters worse, some iterations that worked fine in the local debugger didn't function in any way in the final Oculus Rift application. Our workflow naturally became more efficient but it was still difficult to guarantee that certain features would port to the final VR application before actually building and testing it.

Accomplishments that we're proud of

We're proud of building a functioning application as a result of rapidly learning how to work with design in Unity3D, as well as appending code to objects with C#. We were also able to simultaneously learn more about the solar system by researching the relative sizes and orbital radii. We were also able to accept input from a controller to navigate the camera around the VR Planetarium around 3 axes.

What we learned

Besides working with a tech stack that was entirely new to us, our team learned how to do software development as a group and established a good workflow by the end of the Hackathon. We also learned how much red bull our bodies could handle (>400mg of caffeine).

What's next for VR Planetarium

One recommendation that we've received from many people so far is improving the flow of the controls. Our current version simply allows the user to move along each of the three axes at right angles, without allowing for rotation of the spaceship. This would be the number one thing we would improve. We would also like to add information about each planet that could appear to the user as they approach the planet.
",,https://github.com/noahtren/unity_build,,"c#, unity, oculus, git",801-7,1,Oculus Rift,,omarsyd,Omar,Alsayed,omarsyd@ymail.com,University of Cincinnati,2,noahtren,Noah,Trenaman,noahtren@gmail.com,muncyce,Chloe,Muncy,muncyce@mail.uc.edu,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),VR Planetarium,https://revuc-viii.devpost.com/submissions/114856-vr-planetarium,Explore our wonderful solar system in a to-scale VR environment,3/3/2019 11:55,"Inspiration

3 of our 4 group members had never used Oculus Rift or any VR headset before, so we were very interested in exploring virtual reality with the cool hardware provided. We bounced a couple ideas off of each other while we brainstormed and settled on creating an educational VR application to teach users more about the scale and mechanisms of our solar system.

What it does

VR Planetarium puts the user onboard a ship similar to Cosmos's Ship of The Imagination, in which physical laws such as the speed of light are transcended for the sake of intellectual exploration.

How we built it

Our tech stack was composed of Unity3D, .NET, C#, and Oculus Rift's API. We also used both Git and a Git-like collaborative tool that is built into Unity3D simply called ""collab"". We were all new to C# and had no experience with Unity3D, which made it very rewarding to end with a final product.

Challenges we ran into

We had some difficulties in finding a good workflow for debugging, as we came across many old tutorials or forms of documentation. To make matters worse, some iterations that worked fine in the local debugger didn't function in any way in the final Oculus Rift application. Our workflow naturally became more efficient but it was still difficult to guarantee that certain features would port to the final VR application before actually building and testing it.

Accomplishments that we're proud of

We're proud of building a functioning application as a result of rapidly learning how to work with design in Unity3D, as well as appending code to objects with C#. We were also able to simultaneously learn more about the solar system by researching the relative sizes and orbital radii. We were also able to accept input from a controller to navigate the camera around the VR Planetarium around 3 axes.

What we learned

Besides working with a tech stack that was entirely new to us, our team learned how to do software development as a group and established a good workflow by the end of the Hackathon. We also learned how much red bull our bodies could handle (>400mg of caffeine).

What's next for VR Planetarium

One recommendation that we've received from many people so far is improving the flow of the controls. Our current version simply allows the user to move along each of the three axes at right angles, without allowing for rotation of the spaceship. This would be the number one thing we would improve. We would also like to add information about each planet that could appear to the user as they approach the planet.
",,https://github.com/noahtren/unity_build,,"c#, unity, oculus, git",801-7,1,Oculus Rift,,omarsyd,Omar,Alsayed,omarsyd@ymail.com,University of Cincinnati,2,noahtren,Noah,Trenaman,noahtren@gmail.com,muncyce,Chloe,Muncy,muncyce@mail.uc.edu,,,,,,,,
Best Useless Hack,USELESS,https://revuc-viii.devpost.com/submissions/114859-useless,Useless is Funny,3/3/2019 11:55,"Inspiration

While I was being useless to the team I was inspired to make this project

What it does

Gives you useless post with useless notice

How I built it

using html

Challenges I ran into

I was so tired and useless

Accomplishments that I'm proud of

I got his useless project done

What I learned

Useless can be funny

What's next for USELESS

more useless project in upcoming hackathon
",,,https://s3.amazonaws.com/challengepost/zip_files/production/41736/zip_files/useless.zip,html,801B-4,Northern Kentucky University,,,budhathokg1,Ganesh,Budhathoki,budhathokg1@nku.edu,Northern Kentucky University,0,,,,,,,,,,,,,,,,
Most Innovative Hack(TCS),soldAR,https://revuc-viii.devpost.com/submissions/114870-soldar,Live data/built-in training course to assist with soldering. Viewed from an Augmented Reality headset. ,3/3/2019 12:00,"Inspiration

Cam had the opportunity to try out Virtual Reality welding at the Detroit Maker fair. As cool as he though this was, he wanted to see an augmented reality implementation of something similar. We were lucky enough to borrow a Magic Leap, a new AR headset, and wanted to try to make something cool with it!

What it does

soldAR offers two different modes. The first mode is monitoring of a live soldering session that shows you information about your current soldering job such as your current temperature in comparison to your target temperature, and the time that you've spent on the current piece that you're soldering. Our second mode is a tutorial about soldering, including videos of Cam walking the user through each step of the soldering process in AR. 

How we built it

We used an open source soldering iron that could provide a live temperature reading, power reading, and accelerometer data, and streamed the live data to an Adafruit Trinket M0. We wrote Arduino code to stream the live data via serial connection to a PC running Golang code. From here, an HTTP request posts the data to the Magic Leap headset, where C# code interprets the data and shows it to you. 

Challenges we ran into


Magic leap had very limited documentation
TCP connections weren't allowed so we had to buy our own router to open ports
Soldering iron had different hardware than what we expected
Tapping into the I2C line on the Soldering iron was difficult


Accomplishments that we're proud of


Successfully hacked on to the I2C bus line, directly to the processor
Created custom unity components for the first time
Created a soldering tutorial and displayed the video in AR


What we learned


First time using MagicLeap, so we learned the basics of that
First time having to deal with limited space on a microcontroller (4kb of free space!)
Covering the entire stack from very low level code to very high level code was a larger task than anticipated


What's next for soldAR

Video from the demo will be used on New Territory's social media (@NewTerritoryAR on Twitter!!)
",,,,"unity, c#, c++, golang, arduino",801-14,"The University of Akron, The Ohio State University",,,RodneyMorgan97,Rodney,Morgan,rtm36@zips.uakron.edu,"University of Akron, Ohio State University",3,csinko,Cameron,Sinko,csinko@gmail.com,kjv13,Kyle,Vasulka,kjv13@zips.uakron.edu,BrianGlen,Brian,Glen,br.glen@yahoo.com,,,,
Best Hardware Hack,soldAR,https://revuc-viii.devpost.com/submissions/114870-soldar,Live data/built-in training course to assist with soldering. Viewed from an Augmented Reality headset. ,3/3/2019 12:00,"Inspiration

Cam had the opportunity to try out Virtual Reality welding at the Detroit Maker fair. As cool as he though this was, he wanted to see an augmented reality implementation of something similar. We were lucky enough to borrow a Magic Leap, a new AR headset, and wanted to try to make something cool with it!

What it does

soldAR offers two different modes. The first mode is monitoring of a live soldering session that shows you information about your current soldering job such as your current temperature in comparison to your target temperature, and the time that you've spent on the current piece that you're soldering. Our second mode is a tutorial about soldering, including videos of Cam walking the user through each step of the soldering process in AR. 

How we built it

We used an open source soldering iron that could provide a live temperature reading, power reading, and accelerometer data, and streamed the live data to an Adafruit Trinket M0. We wrote Arduino code to stream the live data via serial connection to a PC running Golang code. From here, an HTTP request posts the data to the Magic Leap headset, where C# code interprets the data and shows it to you. 

Challenges we ran into


Magic leap had very limited documentation
TCP connections weren't allowed so we had to buy our own router to open ports
Soldering iron had different hardware than what we expected
Tapping into the I2C line on the Soldering iron was difficult


Accomplishments that we're proud of


Successfully hacked on to the I2C bus line, directly to the processor
Created custom unity components for the first time
Created a soldering tutorial and displayed the video in AR


What we learned


First time using MagicLeap, so we learned the basics of that
First time having to deal with limited space on a microcontroller (4kb of free space!)
Covering the entire stack from very low level code to very high level code was a larger task than anticipated


What's next for soldAR

Video from the demo will be used on New Territory's social media (@NewTerritoryAR on Twitter!!)
",,,,"unity, c#, c++, golang, arduino",801-14,"The University of Akron, The Ohio State University",,,RodneyMorgan97,Rodney,Morgan,rtm36@zips.uakron.edu,"University of Akron, Ohio State University",3,csinko,Cameron,Sinko,csinko@gmail.com,kjv13,Kyle,Vasulka,kjv13@zips.uakron.edu,BrianGlen,Brian,Glen,br.glen@yahoo.com,,,,
Best Design,soldAR,https://revuc-viii.devpost.com/submissions/114870-soldar,Live data/built-in training course to assist with soldering. Viewed from an Augmented Reality headset. ,3/3/2019 12:00,"Inspiration

Cam had the opportunity to try out Virtual Reality welding at the Detroit Maker fair. As cool as he though this was, he wanted to see an augmented reality implementation of something similar. We were lucky enough to borrow a Magic Leap, a new AR headset, and wanted to try to make something cool with it!

What it does

soldAR offers two different modes. The first mode is monitoring of a live soldering session that shows you information about your current soldering job such as your current temperature in comparison to your target temperature, and the time that you've spent on the current piece that you're soldering. Our second mode is a tutorial about soldering, including videos of Cam walking the user through each step of the soldering process in AR. 

How we built it

We used an open source soldering iron that could provide a live temperature reading, power reading, and accelerometer data, and streamed the live data to an Adafruit Trinket M0. We wrote Arduino code to stream the live data via serial connection to a PC running Golang code. From here, an HTTP request posts the data to the Magic Leap headset, where C# code interprets the data and shows it to you. 

Challenges we ran into


Magic leap had very limited documentation
TCP connections weren't allowed so we had to buy our own router to open ports
Soldering iron had different hardware than what we expected
Tapping into the I2C line on the Soldering iron was difficult


Accomplishments that we're proud of


Successfully hacked on to the I2C bus line, directly to the processor
Created custom unity components for the first time
Created a soldering tutorial and displayed the video in AR


What we learned


First time using MagicLeap, so we learned the basics of that
First time having to deal with limited space on a microcontroller (4kb of free space!)
Covering the entire stack from very low level code to very high level code was a larger task than anticipated


What's next for soldAR

Video from the demo will be used on New Territory's social media (@NewTerritoryAR on Twitter!!)
",,,,"unity, c#, c++, golang, arduino",801-14,"The University of Akron, The Ohio State University",,,RodneyMorgan97,Rodney,Morgan,rtm36@zips.uakron.edu,"University of Akron, Ohio State University",3,csinko,Cameron,Sinko,csinko@gmail.com,kjv13,Kyle,Vasulka,kjv13@zips.uakron.edu,BrianGlen,Brian,Glen,br.glen@yahoo.com,,,,
Make the Customer's Life Easier (84.51),soldAR,https://revuc-viii.devpost.com/submissions/114870-soldar,Live data/built-in training course to assist with soldering. Viewed from an Augmented Reality headset. ,3/3/2019 12:00,"Inspiration

Cam had the opportunity to try out Virtual Reality welding at the Detroit Maker fair. As cool as he though this was, he wanted to see an augmented reality implementation of something similar. We were lucky enough to borrow a Magic Leap, a new AR headset, and wanted to try to make something cool with it!

What it does

soldAR offers two different modes. The first mode is monitoring of a live soldering session that shows you information about your current soldering job such as your current temperature in comparison to your target temperature, and the time that you've spent on the current piece that you're soldering. Our second mode is a tutorial about soldering, including videos of Cam walking the user through each step of the soldering process in AR. 

How we built it

We used an open source soldering iron that could provide a live temperature reading, power reading, and accelerometer data, and streamed the live data to an Adafruit Trinket M0. We wrote Arduino code to stream the live data via serial connection to a PC running Golang code. From here, an HTTP request posts the data to the Magic Leap headset, where C# code interprets the data and shows it to you. 

Challenges we ran into


Magic leap had very limited documentation
TCP connections weren't allowed so we had to buy our own router to open ports
Soldering iron had different hardware than what we expected
Tapping into the I2C line on the Soldering iron was difficult


Accomplishments that we're proud of


Successfully hacked on to the I2C bus line, directly to the processor
Created custom unity components for the first time
Created a soldering tutorial and displayed the video in AR


What we learned


First time using MagicLeap, so we learned the basics of that
First time having to deal with limited space on a microcontroller (4kb of free space!)
Covering the entire stack from very low level code to very high level code was a larger task than anticipated


What's next for soldAR

Video from the demo will be used on New Territory's social media (@NewTerritoryAR on Twitter!!)
",,,,"unity, c#, c++, golang, arduino",801-14,"The University of Akron, The Ohio State University",,,RodneyMorgan97,Rodney,Morgan,rtm36@zips.uakron.edu,"University of Akron, Ohio State University",3,csinko,Cameron,Sinko,csinko@gmail.com,kjv13,Kyle,Vasulka,kjv13@zips.uakron.edu,BrianGlen,Brian,Glen,br.glen@yahoo.com,,,,
Best Design,shttr,https://revuc-viii.devpost.com/submissions/114871-shttr,You spend 92 days of your life in a bathroom. Why not choose the best?,3/3/2019 12:00,"Shttr

Shttr is a webapp that allows users to view and critique nearby restrooms. It is the Yelp equivalent for only bathrooms.

Inspiration

Hello! My name is Clair and I was inspired to create this application because of my personal experiences as a transwoman and the experiences of other members of the trans community. Finding the best, safest place to relieve yourself is something everyone has a right to.

Both Braxton and Jash contributed their own gusto to the team and were essential in providing more ideas and feedback.

What It Does

Primarily, shttr acts as a basic social rating system for bathrooms, as well as recording information such as type (all gender, family, men's, women's), presence of changing rooms, and times open/closed.

How We Built It

Shttr was built by separately building a JSON-based backend and connecting it via Flask to a frontend MVC utilizing a combination of Angular and Leaflet.

Challenges

The three of us have very different coding backgrounds and experiences which led to a lot of learning!

I had personally never used Flask or Leaflet before and integrating those into a cohesive backend/frontend relationship was quite the task! Both Braxton and Jash came into the project as first-year computer science students and learned Python, JSON parsing, database functionalities, and much, much more in an incredibly short amount of time.

Accomplishments

The aesthetic! I think the frontend looks pretty polished for such a short development time and add/modify/delete functions were completed too! We made great strides with login/logout functionality as well.

Learning

As mentioned above, different backgrounds required different types of learning! In general, quite a bit was new for everyone involved (Braxton and Jash came in and learned everything, which was amazing to watch).

Getting started

Prerequisites


Python 3
Flask
Javascript-enabled browser


Configuration

Run python server.py (contained within the app folder). Next, open index.html in any major browser (primary testing done with Google Chrome).

Usage

The first page loaded will ask for the user's location, required to show services closest to you! From there, bathrooms may be added by navigating andf clicking around the map.

Information about bathrooms can be seen when clicking on the toilet icon. Editing/deleting functions are available toward the buttom of the info drawer.

Help and about features are available in the top navigation bar. Finally, basic user functionality (registering/logging in/logging out) is available in version 0.1a.

Happy shitting!

Primary Components


AngularJS - Model View Control system
JQuery - Simple animations
Flask - Connect the server to the client
Python - Back-end development
Leaflet - Front-end map data


What's Next

New developments could include users' favorite lists of bathrooms, comments, user interaction, microbiome-connection, and much, much more! We're excited to see what the future holds for this little guy.

Contributing


Clair Kronk
Braxton Laster
Jash Gada


History


2 March 2019: First push.
3 March 2019: Push for project presentation, alpha version 0.1.


Acknowledgements

We would just like to thank the volunteers at RevolutionUC 2019 for providing the rations we needed to develop this web-app.  They provided us food, shelter, advice, and a stable wifi connection that allowed us to reach the point we're at.

License

Copyright (c) 2019-2020 Clair Kronk, Braxton Laster, and Jash Gada. All rights reserved.
",,https://github.com/Superraptor/shttr,,"javascript, css, html, python",801B-3,"University of Indianapolis, University of Cincinnati",,,braxtonhdlaster,Braxton,Laster,braxton.hd.laster@gmail.com,"University of Indianapolis, University of Pittsburgh - Main Campus, University of Cincinnati",2,superraptor,Clair,Kronk,charles.kronk@gmail.com,jashgada93,Jash,Gada,jashgada93@gmail.com,,,,,,,,
Best Useless Hack,shttr,https://revuc-viii.devpost.com/submissions/114871-shttr,You spend 92 days of your life in a bathroom. Why not choose the best?,3/3/2019 12:00,"Shttr

Shttr is a webapp that allows users to view and critique nearby restrooms. It is the Yelp equivalent for only bathrooms.

Inspiration

Hello! My name is Clair and I was inspired to create this application because of my personal experiences as a transwoman and the experiences of other members of the trans community. Finding the best, safest place to relieve yourself is something everyone has a right to.

Both Braxton and Jash contributed their own gusto to the team and were essential in providing more ideas and feedback.

What It Does

Primarily, shttr acts as a basic social rating system for bathrooms, as well as recording information such as type (all gender, family, men's, women's), presence of changing rooms, and times open/closed.

How We Built It

Shttr was built by separately building a JSON-based backend and connecting it via Flask to a frontend MVC utilizing a combination of Angular and Leaflet.

Challenges

The three of us have very different coding backgrounds and experiences which led to a lot of learning!

I had personally never used Flask or Leaflet before and integrating those into a cohesive backend/frontend relationship was quite the task! Both Braxton and Jash came into the project as first-year computer science students and learned Python, JSON parsing, database functionalities, and much, much more in an incredibly short amount of time.

Accomplishments

The aesthetic! I think the frontend looks pretty polished for such a short development time and add/modify/delete functions were completed too! We made great strides with login/logout functionality as well.

Learning

As mentioned above, different backgrounds required different types of learning! In general, quite a bit was new for everyone involved (Braxton and Jash came in and learned everything, which was amazing to watch).

Getting started

Prerequisites


Python 3
Flask
Javascript-enabled browser


Configuration

Run python server.py (contained within the app folder). Next, open index.html in any major browser (primary testing done with Google Chrome).

Usage

The first page loaded will ask for the user's location, required to show services closest to you! From there, bathrooms may be added by navigating andf clicking around the map.

Information about bathrooms can be seen when clicking on the toilet icon. Editing/deleting functions are available toward the buttom of the info drawer.

Help and about features are available in the top navigation bar. Finally, basic user functionality (registering/logging in/logging out) is available in version 0.1a.

Happy shitting!

Primary Components


AngularJS - Model View Control system
JQuery - Simple animations
Flask - Connect the server to the client
Python - Back-end development
Leaflet - Front-end map data


What's Next

New developments could include users' favorite lists of bathrooms, comments, user interaction, microbiome-connection, and much, much more! We're excited to see what the future holds for this little guy.

Contributing


Clair Kronk
Braxton Laster
Jash Gada


History


2 March 2019: First push.
3 March 2019: Push for project presentation, alpha version 0.1.


Acknowledgements

We would just like to thank the volunteers at RevolutionUC 2019 for providing the rations we needed to develop this web-app.  They provided us food, shelter, advice, and a stable wifi connection that allowed us to reach the point we're at.

License

Copyright (c) 2019-2020 Clair Kronk, Braxton Laster, and Jash Gada. All rights reserved.
",,https://github.com/Superraptor/shttr,,"javascript, css, html, python",801B-3,"University of Indianapolis, University of Cincinnati",,,braxtonhdlaster,Braxton,Laster,braxton.hd.laster@gmail.com,"University of Indianapolis, University of Pittsburgh - Main Campus, University of Cincinnati",2,superraptor,Clair,Kronk,charles.kronk@gmail.com,jashgada93,Jash,Gada,jashgada93@gmail.com,,,,,,,,
Make the Customer's Life Easier (84.51),shttr,https://revuc-viii.devpost.com/submissions/114871-shttr,You spend 92 days of your life in a bathroom. Why not choose the best?,3/3/2019 12:00,"Shttr

Shttr is a webapp that allows users to view and critique nearby restrooms. It is the Yelp equivalent for only bathrooms.

Inspiration

Hello! My name is Clair and I was inspired to create this application because of my personal experiences as a transwoman and the experiences of other members of the trans community. Finding the best, safest place to relieve yourself is something everyone has a right to.

Both Braxton and Jash contributed their own gusto to the team and were essential in providing more ideas and feedback.

What It Does

Primarily, shttr acts as a basic social rating system for bathrooms, as well as recording information such as type (all gender, family, men's, women's), presence of changing rooms, and times open/closed.

How We Built It

Shttr was built by separately building a JSON-based backend and connecting it via Flask to a frontend MVC utilizing a combination of Angular and Leaflet.

Challenges

The three of us have very different coding backgrounds and experiences which led to a lot of learning!

I had personally never used Flask or Leaflet before and integrating those into a cohesive backend/frontend relationship was quite the task! Both Braxton and Jash came into the project as first-year computer science students and learned Python, JSON parsing, database functionalities, and much, much more in an incredibly short amount of time.

Accomplishments

The aesthetic! I think the frontend looks pretty polished for such a short development time and add/modify/delete functions were completed too! We made great strides with login/logout functionality as well.

Learning

As mentioned above, different backgrounds required different types of learning! In general, quite a bit was new for everyone involved (Braxton and Jash came in and learned everything, which was amazing to watch).

Getting started

Prerequisites


Python 3
Flask
Javascript-enabled browser


Configuration

Run python server.py (contained within the app folder). Next, open index.html in any major browser (primary testing done with Google Chrome).

Usage

The first page loaded will ask for the user's location, required to show services closest to you! From there, bathrooms may be added by navigating andf clicking around the map.

Information about bathrooms can be seen when clicking on the toilet icon. Editing/deleting functions are available toward the buttom of the info drawer.

Help and about features are available in the top navigation bar. Finally, basic user functionality (registering/logging in/logging out) is available in version 0.1a.

Happy shitting!

Primary Components


AngularJS - Model View Control system
JQuery - Simple animations
Flask - Connect the server to the client
Python - Back-end development
Leaflet - Front-end map data


What's Next

New developments could include users' favorite lists of bathrooms, comments, user interaction, microbiome-connection, and much, much more! We're excited to see what the future holds for this little guy.

Contributing


Clair Kronk
Braxton Laster
Jash Gada


History


2 March 2019: First push.
3 March 2019: Push for project presentation, alpha version 0.1.


Acknowledgements

We would just like to thank the volunteers at RevolutionUC 2019 for providing the rations we needed to develop this web-app.  They provided us food, shelter, advice, and a stable wifi connection that allowed us to reach the point we're at.

License

Copyright (c) 2019-2020 Clair Kronk, Braxton Laster, and Jash Gada. All rights reserved.
",,https://github.com/Superraptor/shttr,,"javascript, css, html, python",801B-3,"University of Indianapolis, University of Cincinnati",,,braxtonhdlaster,Braxton,Laster,braxton.hd.laster@gmail.com,"University of Indianapolis, University of Pittsburgh - Main Campus, University of Cincinnati",2,superraptor,Clair,Kronk,charles.kronk@gmail.com,jashgada93,Jash,Gada,jashgada93@gmail.com,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,shttr,https://revuc-viii.devpost.com/submissions/114871-shttr,You spend 92 days of your life in a bathroom. Why not choose the best?,3/3/2019 12:00,"Shttr

Shttr is a webapp that allows users to view and critique nearby restrooms. It is the Yelp equivalent for only bathrooms.

Inspiration

Hello! My name is Clair and I was inspired to create this application because of my personal experiences as a transwoman and the experiences of other members of the trans community. Finding the best, safest place to relieve yourself is something everyone has a right to.

Both Braxton and Jash contributed their own gusto to the team and were essential in providing more ideas and feedback.

What It Does

Primarily, shttr acts as a basic social rating system for bathrooms, as well as recording information such as type (all gender, family, men's, women's), presence of changing rooms, and times open/closed.

How We Built It

Shttr was built by separately building a JSON-based backend and connecting it via Flask to a frontend MVC utilizing a combination of Angular and Leaflet.

Challenges

The three of us have very different coding backgrounds and experiences which led to a lot of learning!

I had personally never used Flask or Leaflet before and integrating those into a cohesive backend/frontend relationship was quite the task! Both Braxton and Jash came into the project as first-year computer science students and learned Python, JSON parsing, database functionalities, and much, much more in an incredibly short amount of time.

Accomplishments

The aesthetic! I think the frontend looks pretty polished for such a short development time and add/modify/delete functions were completed too! We made great strides with login/logout functionality as well.

Learning

As mentioned above, different backgrounds required different types of learning! In general, quite a bit was new for everyone involved (Braxton and Jash came in and learned everything, which was amazing to watch).

Getting started

Prerequisites


Python 3
Flask
Javascript-enabled browser


Configuration

Run python server.py (contained within the app folder). Next, open index.html in any major browser (primary testing done with Google Chrome).

Usage

The first page loaded will ask for the user's location, required to show services closest to you! From there, bathrooms may be added by navigating andf clicking around the map.

Information about bathrooms can be seen when clicking on the toilet icon. Editing/deleting functions are available toward the buttom of the info drawer.

Help and about features are available in the top navigation bar. Finally, basic user functionality (registering/logging in/logging out) is available in version 0.1a.

Happy shitting!

Primary Components


AngularJS - Model View Control system
JQuery - Simple animations
Flask - Connect the server to the client
Python - Back-end development
Leaflet - Front-end map data


What's Next

New developments could include users' favorite lists of bathrooms, comments, user interaction, microbiome-connection, and much, much more! We're excited to see what the future holds for this little guy.

Contributing


Clair Kronk
Braxton Laster
Jash Gada


History


2 March 2019: First push.
3 March 2019: Push for project presentation, alpha version 0.1.


Acknowledgements

We would just like to thank the volunteers at RevolutionUC 2019 for providing the rations we needed to develop this web-app.  They provided us food, shelter, advice, and a stable wifi connection that allowed us to reach the point we're at.

License

Copyright (c) 2019-2020 Clair Kronk, Braxton Laster, and Jash Gada. All rights reserved.
",,https://github.com/Superraptor/shttr,,"javascript, css, html, python",801B-3,"University of Indianapolis, University of Cincinnati",,,braxtonhdlaster,Braxton,Laster,braxton.hd.laster@gmail.com,"University of Indianapolis, University of Pittsburgh - Main Campus, University of Cincinnati",2,superraptor,Clair,Kronk,charles.kronk@gmail.com,jashgada93,Jash,Gada,jashgada93@gmail.com,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),shttr,https://revuc-viii.devpost.com/submissions/114871-shttr,You spend 92 days of your life in a bathroom. Why not choose the best?,3/3/2019 12:00,"Shttr

Shttr is a webapp that allows users to view and critique nearby restrooms. It is the Yelp equivalent for only bathrooms.

Inspiration

Hello! My name is Clair and I was inspired to create this application because of my personal experiences as a transwoman and the experiences of other members of the trans community. Finding the best, safest place to relieve yourself is something everyone has a right to.

Both Braxton and Jash contributed their own gusto to the team and were essential in providing more ideas and feedback.

What It Does

Primarily, shttr acts as a basic social rating system for bathrooms, as well as recording information such as type (all gender, family, men's, women's), presence of changing rooms, and times open/closed.

How We Built It

Shttr was built by separately building a JSON-based backend and connecting it via Flask to a frontend MVC utilizing a combination of Angular and Leaflet.

Challenges

The three of us have very different coding backgrounds and experiences which led to a lot of learning!

I had personally never used Flask or Leaflet before and integrating those into a cohesive backend/frontend relationship was quite the task! Both Braxton and Jash came into the project as first-year computer science students and learned Python, JSON parsing, database functionalities, and much, much more in an incredibly short amount of time.

Accomplishments

The aesthetic! I think the frontend looks pretty polished for such a short development time and add/modify/delete functions were completed too! We made great strides with login/logout functionality as well.

Learning

As mentioned above, different backgrounds required different types of learning! In general, quite a bit was new for everyone involved (Braxton and Jash came in and learned everything, which was amazing to watch).

Getting started

Prerequisites


Python 3
Flask
Javascript-enabled browser


Configuration

Run python server.py (contained within the app folder). Next, open index.html in any major browser (primary testing done with Google Chrome).

Usage

The first page loaded will ask for the user's location, required to show services closest to you! From there, bathrooms may be added by navigating andf clicking around the map.

Information about bathrooms can be seen when clicking on the toilet icon. Editing/deleting functions are available toward the buttom of the info drawer.

Help and about features are available in the top navigation bar. Finally, basic user functionality (registering/logging in/logging out) is available in version 0.1a.

Happy shitting!

Primary Components


AngularJS - Model View Control system
JQuery - Simple animations
Flask - Connect the server to the client
Python - Back-end development
Leaflet - Front-end map data


What's Next

New developments could include users' favorite lists of bathrooms, comments, user interaction, microbiome-connection, and much, much more! We're excited to see what the future holds for this little guy.

Contributing


Clair Kronk
Braxton Laster
Jash Gada


History


2 March 2019: First push.
3 March 2019: Push for project presentation, alpha version 0.1.


Acknowledgements

We would just like to thank the volunteers at RevolutionUC 2019 for providing the rations we needed to develop this web-app.  They provided us food, shelter, advice, and a stable wifi connection that allowed us to reach the point we're at.

License

Copyright (c) 2019-2020 Clair Kronk, Braxton Laster, and Jash Gada. All rights reserved.
",,https://github.com/Superraptor/shttr,,"javascript, css, html, python",801B-3,"University of Indianapolis, University of Cincinnati",,,braxtonhdlaster,Braxton,Laster,braxton.hd.laster@gmail.com,"University of Indianapolis, University of Pittsburgh - Main Campus, University of Cincinnati",2,superraptor,Clair,Kronk,charles.kronk@gmail.com,jashgada93,Jash,Gada,jashgada93@gmail.com,,,,,,,,
Most Innovative Hack(TCS),Ninja Cat Adventure,https://revuc-viii.devpost.com/submissions/114875-ninja-cat-adventure,"Ninja Cat Adventure is a 2D, side-scrolling action game with tight controls and fun gameplay!",3/3/2019 12:02,"Inspiration

We came to the RevolutionUC Hackathon with the intention of building a game, and Ninja Cat Adventure is our magnum opus!

What it does

In Ninja Cat Adventure, you play as The Ninja Cat, on a quest to become a ninja Master! Your objective is to defeat the malicious ninja critters who stand in your path, and become the ultimate Ninja Cat!

How we built it

We use Unity for our coding environment, and collaborated using Github. Missy hand-made all of the games' art in Photoshop!

Challenges we ran into

The RevolutionUC hackathon is a (fun, yet) exhausting event. Most of the group members had to leave the hack space in order to sleep. 
Additionally, Nick and Dom have both never used Unity before, and so we spent a lot of time introducing them to the tool.

Accomplishments that we're proud of

We've created an interesting game which we can proud of! We plan on sharing our project after hacking ends, even though we may not fit into any specific categories.

What we learned

Dom and Nick learned a lot about Unity! I (Sam) learned more about using Inheritance with Unity, since this is my first attempt to use a complex class structure like this one. Missy got more experience with game art, which is a profession which she'd love to have in the future.

What's next for Ninja Cat Adventure

First the Hackathon. Within several months, we'll have Ninja Cat Adventure in the hands of top-rated Youtubers who will promote the game. Before long, Ninja Cat Adventure will be the Top E-Sports Title in the World!
",,https://github.com/swiimii/ninja-cat-jam,,"unity, c#, photoshop",860D-2,University of Cincinnati,,,swiiimii,,,swiimii962@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Design,Ninja Cat Adventure,https://revuc-viii.devpost.com/submissions/114875-ninja-cat-adventure,"Ninja Cat Adventure is a 2D, side-scrolling action game with tight controls and fun gameplay!",3/3/2019 12:02,"Inspiration

We came to the RevolutionUC Hackathon with the intention of building a game, and Ninja Cat Adventure is our magnum opus!

What it does

In Ninja Cat Adventure, you play as The Ninja Cat, on a quest to become a ninja Master! Your objective is to defeat the malicious ninja critters who stand in your path, and become the ultimate Ninja Cat!

How we built it

We use Unity for our coding environment, and collaborated using Github. Missy hand-made all of the games' art in Photoshop!

Challenges we ran into

The RevolutionUC hackathon is a (fun, yet) exhausting event. Most of the group members had to leave the hack space in order to sleep. 
Additionally, Nick and Dom have both never used Unity before, and so we spent a lot of time introducing them to the tool.

Accomplishments that we're proud of

We've created an interesting game which we can proud of! We plan on sharing our project after hacking ends, even though we may not fit into any specific categories.

What we learned

Dom and Nick learned a lot about Unity! I (Sam) learned more about using Inheritance with Unity, since this is my first attempt to use a complex class structure like this one. Missy got more experience with game art, which is a profession which she'd love to have in the future.

What's next for Ninja Cat Adventure

First the Hackathon. Within several months, we'll have Ninja Cat Adventure in the hands of top-rated Youtubers who will promote the game. Before long, Ninja Cat Adventure will be the Top E-Sports Title in the World!
",,https://github.com/swiimii/ninja-cat-jam,,"unity, c#, photoshop",860D-2,University of Cincinnati,,,swiiimii,,,swiimii962@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Useless Hack,Ninja Cat Adventure,https://revuc-viii.devpost.com/submissions/114875-ninja-cat-adventure,"Ninja Cat Adventure is a 2D, side-scrolling action game with tight controls and fun gameplay!",3/3/2019 12:02,"Inspiration

We came to the RevolutionUC Hackathon with the intention of building a game, and Ninja Cat Adventure is our magnum opus!

What it does

In Ninja Cat Adventure, you play as The Ninja Cat, on a quest to become a ninja Master! Your objective is to defeat the malicious ninja critters who stand in your path, and become the ultimate Ninja Cat!

How we built it

We use Unity for our coding environment, and collaborated using Github. Missy hand-made all of the games' art in Photoshop!

Challenges we ran into

The RevolutionUC hackathon is a (fun, yet) exhausting event. Most of the group members had to leave the hack space in order to sleep. 
Additionally, Nick and Dom have both never used Unity before, and so we spent a lot of time introducing them to the tool.

Accomplishments that we're proud of

We've created an interesting game which we can proud of! We plan on sharing our project after hacking ends, even though we may not fit into any specific categories.

What we learned

Dom and Nick learned a lot about Unity! I (Sam) learned more about using Inheritance with Unity, since this is my first attempt to use a complex class structure like this one. Missy got more experience with game art, which is a profession which she'd love to have in the future.

What's next for Ninja Cat Adventure

First the Hackathon. Within several months, we'll have Ninja Cat Adventure in the hands of top-rated Youtubers who will promote the game. Before long, Ninja Cat Adventure will be the Top E-Sports Title in the World!
",,https://github.com/swiimii/ninja-cat-jam,,"unity, c#, photoshop",860D-2,University of Cincinnati,,,swiiimii,,,swiimii962@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),Ninja Cat Adventure,https://revuc-viii.devpost.com/submissions/114875-ninja-cat-adventure,"Ninja Cat Adventure is a 2D, side-scrolling action game with tight controls and fun gameplay!",3/3/2019 12:02,"Inspiration

We came to the RevolutionUC Hackathon with the intention of building a game, and Ninja Cat Adventure is our magnum opus!

What it does

In Ninja Cat Adventure, you play as The Ninja Cat, on a quest to become a ninja Master! Your objective is to defeat the malicious ninja critters who stand in your path, and become the ultimate Ninja Cat!

How we built it

We use Unity for our coding environment, and collaborated using Github. Missy hand-made all of the games' art in Photoshop!

Challenges we ran into

The RevolutionUC hackathon is a (fun, yet) exhausting event. Most of the group members had to leave the hack space in order to sleep. 
Additionally, Nick and Dom have both never used Unity before, and so we spent a lot of time introducing them to the tool.

Accomplishments that we're proud of

We've created an interesting game which we can proud of! We plan on sharing our project after hacking ends, even though we may not fit into any specific categories.

What we learned

Dom and Nick learned a lot about Unity! I (Sam) learned more about using Inheritance with Unity, since this is my first attempt to use a complex class structure like this one. Missy got more experience with game art, which is a profession which she'd love to have in the future.

What's next for Ninja Cat Adventure

First the Hackathon. Within several months, we'll have Ninja Cat Adventure in the hands of top-rated Youtubers who will promote the game. Before long, Ninja Cat Adventure will be the Top E-Sports Title in the World!
",,https://github.com/swiimii/ninja-cat-jam,,"unity, c#, photoshop",860D-2,University of Cincinnati,,,swiiimii,,,swiimii962@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Hardware Hack,Sight Necklace,https://revuc-viii.devpost.com/submissions/114877-sight-necklace,"A mobile,inexpensive alternative to walking canes and other forms of sight assistance for the blind in a necklace.",3/3/2019 12:04,"Inspiration

There is nothing on the market of sight assistance that is relatively accessible and affordable, so we decided to create the Sight Necklace.

What it does

The Sight Necklace utilizes several ultrasonic sensors to detect nearby objects and record their distance from the user. The sensors then inform the user via different sounds that relay direction and relative proximity.

How we built it

We took a raspberry pi b+ and attached a portable battery, ultrasonic sensors via gpio cables, and a breadboard. the code was all programmed within Raspbian terminal using the python language.

Challenges we ran into

Particular coding issue such as interaction between the terminal and python and calculating distance using only the speed of sound. organization of wires and measurements of voltages and resistances were also sources of challenges.

Accomplishments that we're proud of

We finished what we originally planned to accomplish.

What we learned

We learned how to use a raspberry pi. We learned to use python (something neither of us have used before) and the Raspbian terminal. We also learned basic physics concepts such as electrical conversions and sound waves
. 

What's next for Sight Necklace

We hope to elaborate on it with a larger number of sensors for a more accurate and wider range of measurement. As well as extra sensors to determine user position, user speed, surrounding speed, and distinguishing between living and non living things.
",,,,"python, raspberry-pi, ultrasonic-sensors",860D-5,St. Xavier High School,,,Akamarus,John (Jack),Burke,jackburke222@yahoo.com,,1,froggynardo,Vincent,Thiemann,froggynardo@gmail.com,,,,,,,,,,,,
Best High School Hack,Sight Necklace,https://revuc-viii.devpost.com/submissions/114877-sight-necklace,"A mobile,inexpensive alternative to walking canes and other forms of sight assistance for the blind in a necklace.",3/3/2019 12:04,"Inspiration

There is nothing on the market of sight assistance that is relatively accessible and affordable, so we decided to create the Sight Necklace.

What it does

The Sight Necklace utilizes several ultrasonic sensors to detect nearby objects and record their distance from the user. The sensors then inform the user via different sounds that relay direction and relative proximity.

How we built it

We took a raspberry pi b+ and attached a portable battery, ultrasonic sensors via gpio cables, and a breadboard. the code was all programmed within Raspbian terminal using the python language.

Challenges we ran into

Particular coding issue such as interaction between the terminal and python and calculating distance using only the speed of sound. organization of wires and measurements of voltages and resistances were also sources of challenges.

Accomplishments that we're proud of

We finished what we originally planned to accomplish.

What we learned

We learned how to use a raspberry pi. We learned to use python (something neither of us have used before) and the Raspbian terminal. We also learned basic physics concepts such as electrical conversions and sound waves
. 

What's next for Sight Necklace

We hope to elaborate on it with a larger number of sensors for a more accurate and wider range of measurement. As well as extra sensors to determine user position, user speed, surrounding speed, and distinguishing between living and non living things.
",,,,"python, raspberry-pi, ultrasonic-sensors",860D-5,St. Xavier High School,,,Akamarus,John (Jack),Burke,jackburke222@yahoo.com,,1,froggynardo,Vincent,Thiemann,froggynardo@gmail.com,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),Sight Necklace,https://revuc-viii.devpost.com/submissions/114877-sight-necklace,"A mobile,inexpensive alternative to walking canes and other forms of sight assistance for the blind in a necklace.",3/3/2019 12:04,"Inspiration

There is nothing on the market of sight assistance that is relatively accessible and affordable, so we decided to create the Sight Necklace.

What it does

The Sight Necklace utilizes several ultrasonic sensors to detect nearby objects and record their distance from the user. The sensors then inform the user via different sounds that relay direction and relative proximity.

How we built it

We took a raspberry pi b+ and attached a portable battery, ultrasonic sensors via gpio cables, and a breadboard. the code was all programmed within Raspbian terminal using the python language.

Challenges we ran into

Particular coding issue such as interaction between the terminal and python and calculating distance using only the speed of sound. organization of wires and measurements of voltages and resistances were also sources of challenges.

Accomplishments that we're proud of

We finished what we originally planned to accomplish.

What we learned

We learned how to use a raspberry pi. We learned to use python (something neither of us have used before) and the Raspbian terminal. We also learned basic physics concepts such as electrical conversions and sound waves
. 

What's next for Sight Necklace

We hope to elaborate on it with a larger number of sensors for a more accurate and wider range of measurement. As well as extra sensors to determine user position, user speed, surrounding speed, and distinguishing between living and non living things.
",,,,"python, raspberry-pi, ultrasonic-sensors",860D-5,St. Xavier High School,,,Akamarus,John (Jack),Burke,jackburke222@yahoo.com,,1,froggynardo,Vincent,Thiemann,froggynardo@gmail.com,,,,,,,,,,,,
,Fun 2 Fin,https://revuc-viii.devpost.com/submissions/114878-fun-2-fin,"Our Financials are not Rocket Science, but they are equally important. Here is a fun way to learn and improve your FQ",3/3/2019 12:06,"Inspiration: A conversation with a friend of ours on a ride to Dayton.

Chat with us to know the complete story behind our inspiration...

What it does: It provides a fun way to learn and motivate yourself to be aware of your financials.

How we built it: We started from scratch from designing the modules to hosting on Amazon-EC2 services.

Challenges we ran into: We are beginners in Web Development and first-time users of Cloud platform. Hence, many animations we imagined gave us really hard time during building and implementation

Accomplishments that we're proud of: Honestly everything that we built, but mainly the use case that we came up that made sense and was feasible to complete with a quick learning curve.

What we learned: Coding (Java-Script, Flask,HTML5), How fun it is to Build something from scratch, We have learnt that we need to brush up our financial knowledge as well!

What's next for FQ: Building more games that focus on particular aspects like loans, mortgages etc.
",,http://ec2-18-217-78-48.us-east-2.compute.amazonaws.com/home,,"flask, python, javascript, html5, amazon-ec2, css",801A-1,University of Cincinnati,,,pallapsu,Sai Sindhu,Pallapuneedi,pallapsu@mail.uc.edu,University of Cincinnati,3,vuyyurra,Rajeswari Likhitha,Vuyyuru,vuyyurra@mail.uc.edu,lakshmibhargavi9,Lakshmi Bhargavi,Anusuri,lakshmibhargavi9@gmail.com,yandraai,Aruna Harini,Yandrapally,yandraai@mail.uc.edu,,,,
Best Hardware Hack,Campfire,https://revuc-viii.devpost.com/submissions/114881-campfire,An intrusion detection system (IDS) that sends a text message (via Twilio) to a system administrator.,3/3/2019 12:08,"Inspiration

We have a group member with experience in network security, and some that like Python.
(Name credit goes to the guy from 84.51)

What it does

Campfire uses Suricata to constantly listen on the network for malicious traffic. If any of the traffic matches Suricata's traffic signatures, it makes note of it by writing the incident to a log file. Any time a change is written to the log file (a new incident is recorded) our python script communicates with the Twilio API and send us a text notification detailing the incident.

How we built it

We flashed a Raspbian image to an SD card to use in the Raspberry Pi. From there we installed and setup SSH network configurations of the Pi, then wrote the python script. Then, we used a Linux program to make the OS recognize our python script as a service, then set up the Raspberry Pi to start up both Suricata and our new Twilio SMS notification service when the Pi boots.

Challenges we ran into

We tried using a brand new Raspberry Pi 3B+ for the faster ethernet speeds and built in wi-fi, but there was an issue with the SD card reader of the Pi so we used a Raspberry Pi 2 with a USB wi-fi dongle.
We were having issues for a while running the python script on startup. It wasn't until we created a new service for the python script that we got it working on startup.

Accomplishments that we're proud of

Getting the whole thing to work feels pretty rewarding,  especially since we came in with no knowledge of what Twilio even was. Through the project, everyone was able to learn new, valuable, transferable skills.

What we learned

Members of our group learned about intrusion detection software and a base level of networking and network security. Members also learned about python, Twilio, and how to integrate the two to work together.

What's next for Campfire

Next is configuring a firewall to work on the Raspberry Pi as well, to make it a sort of all in one security device.
",,,,"raspberry-pi, raspbian, suricata, twilio, python",860D-2,"University of Cincinnati, Miami University",,,derrekmayse,Derrek,Mayse,derrekmayse@gmail.com,"University of Cincinnati, Miami University",3,car-keys,Nicholas,Engle,enick11@gmail.com,everetkg,Katherine,Everett,everetkg@mail.uc.edu,yodapon,yodapon,,mitchey1996@gmail.com,,,,
Best Use of Twilio,Campfire,https://revuc-viii.devpost.com/submissions/114881-campfire,An intrusion detection system (IDS) that sends a text message (via Twilio) to a system administrator.,3/3/2019 12:08,"Inspiration

We have a group member with experience in network security, and some that like Python.
(Name credit goes to the guy from 84.51)

What it does

Campfire uses Suricata to constantly listen on the network for malicious traffic. If any of the traffic matches Suricata's traffic signatures, it makes note of it by writing the incident to a log file. Any time a change is written to the log file (a new incident is recorded) our python script communicates with the Twilio API and send us a text notification detailing the incident.

How we built it

We flashed a Raspbian image to an SD card to use in the Raspberry Pi. From there we installed and setup SSH network configurations of the Pi, then wrote the python script. Then, we used a Linux program to make the OS recognize our python script as a service, then set up the Raspberry Pi to start up both Suricata and our new Twilio SMS notification service when the Pi boots.

Challenges we ran into

We tried using a brand new Raspberry Pi 3B+ for the faster ethernet speeds and built in wi-fi, but there was an issue with the SD card reader of the Pi so we used a Raspberry Pi 2 with a USB wi-fi dongle.
We were having issues for a while running the python script on startup. It wasn't until we created a new service for the python script that we got it working on startup.

Accomplishments that we're proud of

Getting the whole thing to work feels pretty rewarding,  especially since we came in with no knowledge of what Twilio even was. Through the project, everyone was able to learn new, valuable, transferable skills.

What we learned

Members of our group learned about intrusion detection software and a base level of networking and network security. Members also learned about python, Twilio, and how to integrate the two to work together.

What's next for Campfire

Next is configuring a firewall to work on the Raspberry Pi as well, to make it a sort of all in one security device.
",,,,"raspberry-pi, raspbian, suricata, twilio, python",860D-2,"University of Cincinnati, Miami University",,,derrekmayse,Derrek,Mayse,derrekmayse@gmail.com,"University of Cincinnati, Miami University",3,car-keys,Nicholas,Engle,enick11@gmail.com,everetkg,Katherine,Everett,everetkg@mail.uc.edu,yodapon,yodapon,,mitchey1996@gmail.com,,,,
Best Undergrad Hack (Undergrad Research),Campfire,https://revuc-viii.devpost.com/submissions/114881-campfire,An intrusion detection system (IDS) that sends a text message (via Twilio) to a system administrator.,3/3/2019 12:08,"Inspiration

We have a group member with experience in network security, and some that like Python.
(Name credit goes to the guy from 84.51)

What it does

Campfire uses Suricata to constantly listen on the network for malicious traffic. If any of the traffic matches Suricata's traffic signatures, it makes note of it by writing the incident to a log file. Any time a change is written to the log file (a new incident is recorded) our python script communicates with the Twilio API and send us a text notification detailing the incident.

How we built it

We flashed a Raspbian image to an SD card to use in the Raspberry Pi. From there we installed and setup SSH network configurations of the Pi, then wrote the python script. Then, we used a Linux program to make the OS recognize our python script as a service, then set up the Raspberry Pi to start up both Suricata and our new Twilio SMS notification service when the Pi boots.

Challenges we ran into

We tried using a brand new Raspberry Pi 3B+ for the faster ethernet speeds and built in wi-fi, but there was an issue with the SD card reader of the Pi so we used a Raspberry Pi 2 with a USB wi-fi dongle.
We were having issues for a while running the python script on startup. It wasn't until we created a new service for the python script that we got it working on startup.

Accomplishments that we're proud of

Getting the whole thing to work feels pretty rewarding,  especially since we came in with no knowledge of what Twilio even was. Through the project, everyone was able to learn new, valuable, transferable skills.

What we learned

Members of our group learned about intrusion detection software and a base level of networking and network security. Members also learned about python, Twilio, and how to integrate the two to work together.

What's next for Campfire

Next is configuring a firewall to work on the Raspberry Pi as well, to make it a sort of all in one security device.
",,,,"raspberry-pi, raspbian, suricata, twilio, python",860D-2,"University of Cincinnati, Miami University",,,derrekmayse,Derrek,Mayse,derrekmayse@gmail.com,"University of Cincinnati, Miami University",3,car-keys,Nicholas,Engle,enick11@gmail.com,everetkg,Katherine,Everett,everetkg@mail.uc.edu,yodapon,yodapon,,mitchey1996@gmail.com,,,,
 Best IoT Hack using a Qualcomm Device (MLH),Parental Display,https://revuc-viii.devpost.com/submissions/114883-parental-display,"""Parental Display"" helps single parents keep their kids at home updated.",3/3/2019 12:10,"Inspiration

We wanted to use the Dragonboard 410c to create an IoT device for a single parent household.  Single parents who are living on one income have a hard time keeping in touch with kids.  On a single income, it gets hard to pay for 2 phone bills. ""Parental Display"" offers a solution.

What it does

""Parental Display"" would be placed in a home on a kitchen counter or somewhere that the kids can see when they come home from school.  The parent will download ""Parental Display"" app from the store and connect to the Display.  Once connected, the parent can send a message to the display from anywhere.  For example, if the parent is working late and the kids come home before them, the parent can send a message like ""I will be home later.  Please clean your room before I get home.""  Once the kids come home, they can see the display.

How I built it

We used Android Studio to create an app for the mobile device.  This device is connected to an Amazon Web Service (AWS) IoT Core.  The Android device publishes the message to the IoT Core while the Dragonboard is subscribed to AWS.  Once the message is published, the Dragonboard displays the message on the screen.

Challenges I ran into

We ran into problems with the connection of AWS on both ends.  Pub/Sub is an unfamiliar concept to us, so this project brought this concept to a real-life application.  We also had problems with the user interface on the Android end.

Accomplishments that I'm proud of

We are proud of this IoT project because we were able to connect multiple devices from different programming languages to communicate together. 

What I learned

We learned how to use AWS IoT Core to connect devices to an MQTT server and write python scripts to subscribe to that server. 

What's next for Parental Display

We hope to create a better user-friendly UI on the Dragonboard side.
",,,,"amazon-web-services, dragonboard, iot, android, android-studio, linux, python",860D-4,Lawrence Technological University,,,nfraylick,Neil,Fraylick,29neiljf@gmail.com,Lawrence Technological University,3,kyletomczik,kyletomczik,Tomczik,ktomczik@ltu.edu,mfox123,Mike,Fox,mfox@ltu.edu,hdavies,Hunter,Davies,hdavies@ltu.edu,,,,
Best Hardware Hack,Parental Display,https://revuc-viii.devpost.com/submissions/114883-parental-display,"""Parental Display"" helps single parents keep their kids at home updated.",3/3/2019 12:10,"Inspiration

We wanted to use the Dragonboard 410c to create an IoT device for a single parent household.  Single parents who are living on one income have a hard time keeping in touch with kids.  On a single income, it gets hard to pay for 2 phone bills. ""Parental Display"" offers a solution.

What it does

""Parental Display"" would be placed in a home on a kitchen counter or somewhere that the kids can see when they come home from school.  The parent will download ""Parental Display"" app from the store and connect to the Display.  Once connected, the parent can send a message to the display from anywhere.  For example, if the parent is working late and the kids come home before them, the parent can send a message like ""I will be home later.  Please clean your room before I get home.""  Once the kids come home, they can see the display.

How I built it

We used Android Studio to create an app for the mobile device.  This device is connected to an Amazon Web Service (AWS) IoT Core.  The Android device publishes the message to the IoT Core while the Dragonboard is subscribed to AWS.  Once the message is published, the Dragonboard displays the message on the screen.

Challenges I ran into

We ran into problems with the connection of AWS on both ends.  Pub/Sub is an unfamiliar concept to us, so this project brought this concept to a real-life application.  We also had problems with the user interface on the Android end.

Accomplishments that I'm proud of

We are proud of this IoT project because we were able to connect multiple devices from different programming languages to communicate together. 

What I learned

We learned how to use AWS IoT Core to connect devices to an MQTT server and write python scripts to subscribe to that server. 

What's next for Parental Display

We hope to create a better user-friendly UI on the Dragonboard side.
",,,,"amazon-web-services, dragonboard, iot, android, android-studio, linux, python",860D-4,Lawrence Technological University,,,nfraylick,Neil,Fraylick,29neiljf@gmail.com,Lawrence Technological University,3,kyletomczik,kyletomczik,Tomczik,ktomczik@ltu.edu,mfox123,Mike,Fox,mfox@ltu.edu,hdavies,Hunter,Davies,hdavies@ltu.edu,,,,
Best Design,Parental Display,https://revuc-viii.devpost.com/submissions/114883-parental-display,"""Parental Display"" helps single parents keep their kids at home updated.",3/3/2019 12:10,"Inspiration

We wanted to use the Dragonboard 410c to create an IoT device for a single parent household.  Single parents who are living on one income have a hard time keeping in touch with kids.  On a single income, it gets hard to pay for 2 phone bills. ""Parental Display"" offers a solution.

What it does

""Parental Display"" would be placed in a home on a kitchen counter or somewhere that the kids can see when they come home from school.  The parent will download ""Parental Display"" app from the store and connect to the Display.  Once connected, the parent can send a message to the display from anywhere.  For example, if the parent is working late and the kids come home before them, the parent can send a message like ""I will be home later.  Please clean your room before I get home.""  Once the kids come home, they can see the display.

How I built it

We used Android Studio to create an app for the mobile device.  This device is connected to an Amazon Web Service (AWS) IoT Core.  The Android device publishes the message to the IoT Core while the Dragonboard is subscribed to AWS.  Once the message is published, the Dragonboard displays the message on the screen.

Challenges I ran into

We ran into problems with the connection of AWS on both ends.  Pub/Sub is an unfamiliar concept to us, so this project brought this concept to a real-life application.  We also had problems with the user interface on the Android end.

Accomplishments that I'm proud of

We are proud of this IoT project because we were able to connect multiple devices from different programming languages to communicate together. 

What I learned

We learned how to use AWS IoT Core to connect devices to an MQTT server and write python scripts to subscribe to that server. 

What's next for Parental Display

We hope to create a better user-friendly UI on the Dragonboard side.
",,,,"amazon-web-services, dragonboard, iot, android, android-studio, linux, python",860D-4,Lawrence Technological University,,,nfraylick,Neil,Fraylick,29neiljf@gmail.com,Lawrence Technological University,3,kyletomczik,kyletomczik,Tomczik,ktomczik@ltu.edu,mfox123,Mike,Fox,mfox@ltu.edu,hdavies,Hunter,Davies,hdavies@ltu.edu,,,,
Best Hack for Social Good (JP Morgan Chase & Co),Parental Display,https://revuc-viii.devpost.com/submissions/114883-parental-display,"""Parental Display"" helps single parents keep their kids at home updated.",3/3/2019 12:10,"Inspiration

We wanted to use the Dragonboard 410c to create an IoT device for a single parent household.  Single parents who are living on one income have a hard time keeping in touch with kids.  On a single income, it gets hard to pay for 2 phone bills. ""Parental Display"" offers a solution.

What it does

""Parental Display"" would be placed in a home on a kitchen counter or somewhere that the kids can see when they come home from school.  The parent will download ""Parental Display"" app from the store and connect to the Display.  Once connected, the parent can send a message to the display from anywhere.  For example, if the parent is working late and the kids come home before them, the parent can send a message like ""I will be home later.  Please clean your room before I get home.""  Once the kids come home, they can see the display.

How I built it

We used Android Studio to create an app for the mobile device.  This device is connected to an Amazon Web Service (AWS) IoT Core.  The Android device publishes the message to the IoT Core while the Dragonboard is subscribed to AWS.  Once the message is published, the Dragonboard displays the message on the screen.

Challenges I ran into

We ran into problems with the connection of AWS on both ends.  Pub/Sub is an unfamiliar concept to us, so this project brought this concept to a real-life application.  We also had problems with the user interface on the Android end.

Accomplishments that I'm proud of

We are proud of this IoT project because we were able to connect multiple devices from different programming languages to communicate together. 

What I learned

We learned how to use AWS IoT Core to connect devices to an MQTT server and write python scripts to subscribe to that server. 

What's next for Parental Display

We hope to create a better user-friendly UI on the Dragonboard side.
",,,,"amazon-web-services, dragonboard, iot, android, android-studio, linux, python",860D-4,Lawrence Technological University,,,nfraylick,Neil,Fraylick,29neiljf@gmail.com,Lawrence Technological University,3,kyletomczik,kyletomczik,Tomczik,ktomczik@ltu.edu,mfox123,Mike,Fox,mfox@ltu.edu,hdavies,Hunter,Davies,hdavies@ltu.edu,,,,
 Best Domain Registered with Domain.com (MLH),CookWithKroger,https://revuc-viii.devpost.com/submissions/114884-cookwithkroger,"Users can filter recipes by price, category, time to cook, and number or servings; and add products to their cart. ",3/3/2019 12:12,"Inspiration

The inspiration behind cook with Kroger was to try to make an interactive and dynamic webpage that can help simplify the shopping experience for any Kroger customer. 

What it does

CookWithKroger was made with convenience in mind. Customers will be able to search recipes within their budget from CookWithKroger.com while filtering recipes by price, category, and time to cook, and even number or servings, scaling the recipe to fit your needs. Once a recipe is selected, CookWithKroger will list all the ingredients needed ready to be added to the cart with one click. It will also provide resources to help with the preparation, including step by step instructions and even videos.

How we built it

We created the database using PostgreSQL, modeled after 84.51's data provided. The back-end was written in java and front-end was HTML, CSS, and Bootstrap.

Challenges we ran into

We struggled with CSS formatting and database design.

Accomplishments that we're proud of

We are proud of the product we were able to pump out in our first hackathon with only 7 weeks of coding knowledge. Our idea was ambitious given our skills, but we were able to complete everything we set out to do and present a workable MVP.

What we learned

We learned how to integrate a full-stack application from database to user. None of us had much experience using CSS, HTML or bootstrap.

What's next for CookWithKroger

In the future, we believe that CookWithKroger can effectively cut google out as the middle man between meal planning and shopping. This could be used online through ClickList or even in store; using the Kroger mobile application and showing aisle locations of the products needed. We will also be able to offer the ability to filter out any allergies or dietary restrictions. Using CookWithKroger regularly will allow the application to make smarter suggestions, based on your grocery buying pattern and what ingredients it believes you already have at home. Connecting your calendar app will also allow you to schedule selected recipes to your upcoming week, making life simpler and eliminating the daily ""What's for dinner?"" from the rest of the family.
",,https://github.com/kuttley/revolution2019,,"css, postgresql, java, html, bootstrap",8.01E+01,Tech Elevator,,,Quinn-Hebert,Quinn-Hebert,,hebert.42@osu.edu,,3,kuttley,Kali,Uttley,kaliuttley@gmail.com,bkma,bkma,,bkma1@hotmail.com,brettbauereis,brettbauereis,,brettbauereis@gmail.com,,,,
Best Design,CookWithKroger,https://revuc-viii.devpost.com/submissions/114884-cookwithkroger,"Users can filter recipes by price, category, time to cook, and number or servings; and add products to their cart. ",3/3/2019 12:12,"Inspiration

The inspiration behind cook with Kroger was to try to make an interactive and dynamic webpage that can help simplify the shopping experience for any Kroger customer. 

What it does

CookWithKroger was made with convenience in mind. Customers will be able to search recipes within their budget from CookWithKroger.com while filtering recipes by price, category, and time to cook, and even number or servings, scaling the recipe to fit your needs. Once a recipe is selected, CookWithKroger will list all the ingredients needed ready to be added to the cart with one click. It will also provide resources to help with the preparation, including step by step instructions and even videos.

How we built it

We created the database using PostgreSQL, modeled after 84.51's data provided. The back-end was written in java and front-end was HTML, CSS, and Bootstrap.

Challenges we ran into

We struggled with CSS formatting and database design.

Accomplishments that we're proud of

We are proud of the product we were able to pump out in our first hackathon with only 7 weeks of coding knowledge. Our idea was ambitious given our skills, but we were able to complete everything we set out to do and present a workable MVP.

What we learned

We learned how to integrate a full-stack application from database to user. None of us had much experience using CSS, HTML or bootstrap.

What's next for CookWithKroger

In the future, we believe that CookWithKroger can effectively cut google out as the middle man between meal planning and shopping. This could be used online through ClickList or even in store; using the Kroger mobile application and showing aisle locations of the products needed. We will also be able to offer the ability to filter out any allergies or dietary restrictions. Using CookWithKroger regularly will allow the application to make smarter suggestions, based on your grocery buying pattern and what ingredients it believes you already have at home. Connecting your calendar app will also allow you to schedule selected recipes to your upcoming week, making life simpler and eliminating the daily ""What's for dinner?"" from the rest of the family.
",,https://github.com/kuttley/revolution2019,,"css, postgresql, java, html, bootstrap",8.01E+01,Tech Elevator,,,Quinn-Hebert,Quinn-Hebert,,hebert.42@osu.edu,,3,kuttley,Kali,Uttley,kaliuttley@gmail.com,bkma,bkma,,bkma1@hotmail.com,brettbauereis,brettbauereis,,brettbauereis@gmail.com,,,,
Make the Customer's Life Easier (84.51),CookWithKroger,https://revuc-viii.devpost.com/submissions/114884-cookwithkroger,"Users can filter recipes by price, category, time to cook, and number or servings; and add products to their cart. ",3/3/2019 12:12,"Inspiration

The inspiration behind cook with Kroger was to try to make an interactive and dynamic webpage that can help simplify the shopping experience for any Kroger customer. 

What it does

CookWithKroger was made with convenience in mind. Customers will be able to search recipes within their budget from CookWithKroger.com while filtering recipes by price, category, and time to cook, and even number or servings, scaling the recipe to fit your needs. Once a recipe is selected, CookWithKroger will list all the ingredients needed ready to be added to the cart with one click. It will also provide resources to help with the preparation, including step by step instructions and even videos.

How we built it

We created the database using PostgreSQL, modeled after 84.51's data provided. The back-end was written in java and front-end was HTML, CSS, and Bootstrap.

Challenges we ran into

We struggled with CSS formatting and database design.

Accomplishments that we're proud of

We are proud of the product we were able to pump out in our first hackathon with only 7 weeks of coding knowledge. Our idea was ambitious given our skills, but we were able to complete everything we set out to do and present a workable MVP.

What we learned

We learned how to integrate a full-stack application from database to user. None of us had much experience using CSS, HTML or bootstrap.

What's next for CookWithKroger

In the future, we believe that CookWithKroger can effectively cut google out as the middle man between meal planning and shopping. This could be used online through ClickList or even in store; using the Kroger mobile application and showing aisle locations of the products needed. We will also be able to offer the ability to filter out any allergies or dietary restrictions. Using CookWithKroger regularly will allow the application to make smarter suggestions, based on your grocery buying pattern and what ingredients it believes you already have at home. Connecting your calendar app will also allow you to schedule selected recipes to your upcoming week, making life simpler and eliminating the daily ""What's for dinner?"" from the rest of the family.
",,https://github.com/kuttley/revolution2019,,"css, postgresql, java, html, bootstrap",8.01E+01,Tech Elevator,,,Quinn-Hebert,Quinn-Hebert,,hebert.42@osu.edu,,3,kuttley,Kali,Uttley,kaliuttley@gmail.com,bkma,bkma,,bkma1@hotmail.com,brettbauereis,brettbauereis,,brettbauereis@gmail.com,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,CookWithKroger,https://revuc-viii.devpost.com/submissions/114884-cookwithkroger,"Users can filter recipes by price, category, time to cook, and number or servings; and add products to their cart. ",3/3/2019 12:12,"Inspiration

The inspiration behind cook with Kroger was to try to make an interactive and dynamic webpage that can help simplify the shopping experience for any Kroger customer. 

What it does

CookWithKroger was made with convenience in mind. Customers will be able to search recipes within their budget from CookWithKroger.com while filtering recipes by price, category, and time to cook, and even number or servings, scaling the recipe to fit your needs. Once a recipe is selected, CookWithKroger will list all the ingredients needed ready to be added to the cart with one click. It will also provide resources to help with the preparation, including step by step instructions and even videos.

How we built it

We created the database using PostgreSQL, modeled after 84.51's data provided. The back-end was written in java and front-end was HTML, CSS, and Bootstrap.

Challenges we ran into

We struggled with CSS formatting and database design.

Accomplishments that we're proud of

We are proud of the product we were able to pump out in our first hackathon with only 7 weeks of coding knowledge. Our idea was ambitious given our skills, but we were able to complete everything we set out to do and present a workable MVP.

What we learned

We learned how to integrate a full-stack application from database to user. None of us had much experience using CSS, HTML or bootstrap.

What's next for CookWithKroger

In the future, we believe that CookWithKroger can effectively cut google out as the middle man between meal planning and shopping. This could be used online through ClickList or even in store; using the Kroger mobile application and showing aisle locations of the products needed. We will also be able to offer the ability to filter out any allergies or dietary restrictions. Using CookWithKroger regularly will allow the application to make smarter suggestions, based on your grocery buying pattern and what ingredients it believes you already have at home. Connecting your calendar app will also allow you to schedule selected recipes to your upcoming week, making life simpler and eliminating the daily ""What's for dinner?"" from the rest of the family.
",,https://github.com/kuttley/revolution2019,,"css, postgresql, java, html, bootstrap",8.01E+01,Tech Elevator,,,Quinn-Hebert,Quinn-Hebert,,hebert.42@osu.edu,,3,kuttley,Kali,Uttley,kaliuttley@gmail.com,bkma,bkma,,bkma1@hotmail.com,brettbauereis,brettbauereis,,brettbauereis@gmail.com,,,,
Best Useless Hack,Emoji Feel,https://revuc-viii.devpost.com/submissions/114892-emoji-feel,"It recognizes what emotion the emoji is conveying -positive,neutral, or negative",3/3/2019 12:18,"Inspiration

Saw in a documentary about how a person got detained at the US airport because of a joke tweet that got screened by the system as an actual threat to the US. The man had implied he is going to party hard which would ""wreck america"" followed by a series of wink emojis. If AI systems could recognize what kind of emojis are being used, it could save the authorities from wrongfully detaining someone and would allow people to use more sarcastic language without fear.

What it does

It takes as an input an image of an emoji and then classifies into 3 groups: positive, negative, neutral. 

How I built it

We found a youtube video of someone explaining computer vision, who had a link to his github. We cloned his repositories and made some changes to the data sets and weights on the training models to output, with reasonable accuracy, what emotion is the emoji trying to convey.

Challenges I ran into

As beginners, our biggest challenge was actually setting everything up. Since, none of us had any experience with tensorflow or keras, and the fact that the repository was written a year ago, we ran into some compatibility issues which we had to figure out and change accordingly.
Also, finding out the weights so that our model is the right combination of quick and accurate was a bit challenging. 

Accomplishments that I'm proud of

Finishing the project!! And training a model to accurately identify emotions was nice.

What I learned

We learned a great deal about tensorflow and keras. We also learned about various python IDEs and pip and how to work in a team using git. 

What's next for Emoji Feel

The model can further be expanded to recognize what emotions are displayed by human faces, which could help make better care-taking robots for the elderly and young.
",,https://github.com/krillian11/emojiFeel,,"keras, tensorflow, github, python",801-2,"Illinois Institute of Technology, Wright State University",,,krillian11,krillian11,,asw7731@gmail.com,"Wright State University, Illinois Institute of Technology",1,MohitSJha,MohitSJha,,mohitroddick@gmail.com,,,,,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,Emoji Feel,https://revuc-viii.devpost.com/submissions/114892-emoji-feel,"It recognizes what emotion the emoji is conveying -positive,neutral, or negative",3/3/2019 12:18,"Inspiration

Saw in a documentary about how a person got detained at the US airport because of a joke tweet that got screened by the system as an actual threat to the US. The man had implied he is going to party hard which would ""wreck america"" followed by a series of wink emojis. If AI systems could recognize what kind of emojis are being used, it could save the authorities from wrongfully detaining someone and would allow people to use more sarcastic language without fear.

What it does

It takes as an input an image of an emoji and then classifies into 3 groups: positive, negative, neutral. 

How I built it

We found a youtube video of someone explaining computer vision, who had a link to his github. We cloned his repositories and made some changes to the data sets and weights on the training models to output, with reasonable accuracy, what emotion is the emoji trying to convey.

Challenges I ran into

As beginners, our biggest challenge was actually setting everything up. Since, none of us had any experience with tensorflow or keras, and the fact that the repository was written a year ago, we ran into some compatibility issues which we had to figure out and change accordingly.
Also, finding out the weights so that our model is the right combination of quick and accurate was a bit challenging. 

Accomplishments that I'm proud of

Finishing the project!! And training a model to accurately identify emotions was nice.

What I learned

We learned a great deal about tensorflow and keras. We also learned about various python IDEs and pip and how to work in a team using git. 

What's next for Emoji Feel

The model can further be expanded to recognize what emotions are displayed by human faces, which could help make better care-taking robots for the elderly and young.
",,https://github.com/krillian11/emojiFeel,,"keras, tensorflow, github, python",801-2,"Illinois Institute of Technology, Wright State University",,,krillian11,krillian11,,asw7731@gmail.com,"Wright State University, Illinois Institute of Technology",1,MohitSJha,MohitSJha,,mohitroddick@gmail.com,,,,,,,,,,,,
Best Use of Google Cloud Platform (MLH),Ohio University League of Legends Website,https://revuc-viii.devpost.com/submissions/114908-ohio-university-league-of-legends-website,Official website for the Ohio University League of Legends Website,3/3/2019 12:24,"oulolwebsite

Official website for the Ohio University League of Legends Club
Our goal is to facilitate an open and supportive community filled with those who love the game League of Legends where people can play with friends or meet new people who play. We host open, game-related activities such as tournaments, along with fun events that people who don't play the game could enjoy. 
We consistently hold events for our members that include:
-Host Scrimmages and Tournaments in a fun and competitive environment to encourage players to become better at League
-Provide opportunities for players to be matched with a higher skilled player to help them improve
-Host Viewing Parties for professional events such as NA LCS, Worlds, and more
-Provide students, both experts and novice alike, with a space to meet others who play and love League of Legends
",,https://github.com/Micah-Tobon/oulolwebsite,,"html, css, javascript, jquery, snapchat, google-spreadsheets",801M-5,Ohio University,,Google Cloud Platform|-|Snap,Micah-Tobon,Micah,Tobon,mt405516@ohio.edu,,1,jacobeicher,jacobeicher,,jacob@ourthreeringcircus.com,,,,,,,,,,,,
Best Use of Snapkit (MLH),Ohio University League of Legends Website,https://revuc-viii.devpost.com/submissions/114908-ohio-university-league-of-legends-website,Official website for the Ohio University League of Legends Website,3/3/2019 12:24,"oulolwebsite

Official website for the Ohio University League of Legends Club
Our goal is to facilitate an open and supportive community filled with those who love the game League of Legends where people can play with friends or meet new people who play. We host open, game-related activities such as tournaments, along with fun events that people who don't play the game could enjoy. 
We consistently hold events for our members that include:
-Host Scrimmages and Tournaments in a fun and competitive environment to encourage players to become better at League
-Provide opportunities for players to be matched with a higher skilled player to help them improve
-Host Viewing Parties for professional events such as NA LCS, Worlds, and more
-Provide students, both experts and novice alike, with a space to meet others who play and love League of Legends
",,https://github.com/Micah-Tobon/oulolwebsite,,"html, css, javascript, jquery, snapchat, google-spreadsheets",801M-5,Ohio University,,Google Cloud Platform|-|Snap,Micah-Tobon,Micah,Tobon,mt405516@ohio.edu,,1,jacobeicher,jacobeicher,,jacob@ourthreeringcircus.com,,,,,,,,,,,,
Most Innovative Hack(TCS),Ohio University League of Legends Website,https://revuc-viii.devpost.com/submissions/114908-ohio-university-league-of-legends-website,Official website for the Ohio University League of Legends Website,3/3/2019 12:24,"oulolwebsite

Official website for the Ohio University League of Legends Club
Our goal is to facilitate an open and supportive community filled with those who love the game League of Legends where people can play with friends or meet new people who play. We host open, game-related activities such as tournaments, along with fun events that people who don't play the game could enjoy. 
We consistently hold events for our members that include:
-Host Scrimmages and Tournaments in a fun and competitive environment to encourage players to become better at League
-Provide opportunities for players to be matched with a higher skilled player to help them improve
-Host Viewing Parties for professional events such as NA LCS, Worlds, and more
-Provide students, both experts and novice alike, with a space to meet others who play and love League of Legends
",,https://github.com/Micah-Tobon/oulolwebsite,,"html, css, javascript, jquery, snapchat, google-spreadsheets",801M-5,Ohio University,,Google Cloud Platform|-|Snap,Micah-Tobon,Micah,Tobon,mt405516@ohio.edu,,1,jacobeicher,jacobeicher,,jacob@ourthreeringcircus.com,,,,,,,,,,,,
Best Design,Ohio University League of Legends Website,https://revuc-viii.devpost.com/submissions/114908-ohio-university-league-of-legends-website,Official website for the Ohio University League of Legends Website,3/3/2019 12:24,"oulolwebsite

Official website for the Ohio University League of Legends Club
Our goal is to facilitate an open and supportive community filled with those who love the game League of Legends where people can play with friends or meet new people who play. We host open, game-related activities such as tournaments, along with fun events that people who don't play the game could enjoy. 
We consistently hold events for our members that include:
-Host Scrimmages and Tournaments in a fun and competitive environment to encourage players to become better at League
-Provide opportunities for players to be matched with a higher skilled player to help them improve
-Host Viewing Parties for professional events such as NA LCS, Worlds, and more
-Provide students, both experts and novice alike, with a space to meet others who play and love League of Legends
",,https://github.com/Micah-Tobon/oulolwebsite,,"html, css, javascript, jquery, snapchat, google-spreadsheets",801M-5,Ohio University,,Google Cloud Platform|-|Snap,Micah-Tobon,Micah,Tobon,mt405516@ohio.edu,,1,jacobeicher,jacobeicher,,jacob@ourthreeringcircus.com,,,,,,,,,,,,
Best Use of Azure (Microsoft),GifBot,https://revuc-viii.devpost.com/submissions/114921-gifbot,Take a picture of your face and get a gif that reacts!,3/3/2019 12:28,"Inspiration

What it does

GifBot uses a webcam to capture a live frame of the user's facial expression to determine their emotion, then it returns a viewable gif that reflects that emotion.

How we built it

GifBot uses a combination of Python scripts, Microsoft Azure's Face API, and a Microsoft Azure hosted Linux virtual machine to take a photo, send the photo to Microsoft Azure's Face API to analyze the characteristics of the photo, then by using Giphy's API, it searches Giphy's database using keywords based on the data returned from Microsoft's Face API. 

Challenges we ran into

Networking: Microsoft's Face API uses an image's URL to locate the image, but the picture of the user is taken locally. Running a simple Apache server could alleviate the issue, but the University's firewall blocked this functionality. The workaround was to set up a Linux virtual machine on Azure, then use SCP to copy the local image onto the virtual machine.

Accomplishments that we're proud of

It works!!! We learned a lot about APIs in general and using multiple APIs to accomplish a task. We didn't settle; we finished what we started and we fulfilled our goals of the event.

What we learned

We learned a lot by struggling through using Microsoft Azure.

What's next for GifBot

Pushing it to mobile platforms; now that we have its basic functionality, we would like to try using React Native for allowing both Android and iOS development to bring it to the public.
",,https://github.com/cmoney1034/GifBot,,"python, microsoft-azure-face-api, giphy-api",801-16,University of Akron,,,cgm47,Corey,Miller,cgm47@zips.uakron.edu,University of Akron,1,LeeVico,Lee,Paolucci,lvp6@zips.uakron.edu,,,,,,,,,,,,
,Ladybug,https://revuc-viii.devpost.com/submissions/114922-ladybug,I teach my mom to program with a simple ladybug game,3/3/2019 12:28,"So my friends bailed on me for this Hackathon. So I brought my mom instead to show her what a Hackathon is all about.

It's a small game. You control a ladybug and avoid cacti and a wasp while collecting flowers. Use the arrow keys to move. The wasp freezes for three turns at the start and each time you collect a flower. Try to earn the highest score you can.

I coded and explained what I was doing while my mom told me what features she wanted. It's written in C# using Windows Forms as a GUI.

I'm proud that my mom now knows a little bit of basic coding in C#.
",https://youtu.be/nN85SXo2nYM,,,c#,801-13,"Carthage College, Harper College",,,lprotasova,Lesya,Protasova,lprotasova@carthage.edu,Carthage College,0,,,,,,,,,,,,,,,,
,FaceRekExtension,https://revuc-viii.devpost.com/submissions/114934-facerekextension,FaceRek aims to leverage security on your browser using bleeding-edge face recognition technology,3/3/2019 12:32,"Inspiration

With the life-changing power of AI and Computer Vision, we can now easily use features like Face Recognition to leverage our own security in everyday tasks. We have yet to see any applications for browser utilize this feature, so we thought to ourselves why not?

What it does

It acts as an overlay on top of your browser to filter out the pages you don't want other people to access using facial recognition. Imagine some websites that have saved your login credentials, but you don't want your evil friends to see when they borrow your laptop. FaceRek provides a simple yet complete solution such a problem. 

How we built it

The utilized the powerful AWS Rekognition API to handle facial recognition and the Google Chrome Extension developer kit to build our app.

Challenges we ran into

Many: setting up AWS to work flawlessly within the Chrome extension; handling the complex flow of authorization; workaround to enable the camera on Chrome extension as it's not natively supported by them. 

Accomplishments that we're proud of

The extension works perfectly under our tests. It even blocks everything from Maps to Drive when we specify ""google"" as the blocking keyword.

What we learned

Building with AWS and Chrome extension. Teamwork matters. You can sleep 1 hour a day.

What's next for FaceRekExtension

We will release this extension in near future on Chrome Web Store. It may allow multiple users on the same machine; different levels of authorization; recovery password, etc.
",,https://github.com/andre-le/FaceRekExtension,,"javascript, html, chrome, amazon-web-services, cv",801C-5,Miami University,,,letm,Tuan,Le,letm@miamioh.edu,Miami University,1,leduyanh1011998,Le,Anh,leduyanh1011998@yahoo.com.vn,,,,,,,,,,,,
Best Use of Snapkit (MLH),SongSnap,https://revuc-viii.devpost.com/submissions/114942-songsnap,This web application can take your currently playing Spotify song ,3/3/2019 12:46,"Inspiration

I have wanted this functionality for a long time.

What it does

It takes your currently playing Spotify song or other data and lets you use it as a Sticker in Snapchat

How I built it

I used Xcode and the Swift programming language to build it for iOS. For the web version I used NodeJS and React.

Challenges I ran into

Utilizing Spotify and Snapchat APIs and correlating the data. I was not able to post as a Sticker from the website.

Accomplishments that I'm proud of

Learning the Spotify API.

What I learned

I learned how to code in Swift.

What's next for SongSnap

I plan on finishing the iOS version since the web version could not function the way I wanted.
",,,,"swift, api, oauth, xcode, node.js",801B-5,University of Cincinnati,,Domain.com|-|Snap,jordarn96,Ryan,Jordan,jordarn96@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Most Innovative Hack(TCS),What do I wear?,https://revuc-viii.devpost.com/submissions/114944-what-do-i-wear,"Why dress in a turtle neck everyday?Every morning the question is ""what do I wear today?"" Here is the solution!",3/3/2019 12:47,"What do I wear today?

This project helps you choose and pair the different clothes in your wardrobe to make you look your best.

We built this using a deep learning model implemented in Tensorflow along with some machine learning in Python.

Collecting the data was a big challenges we ran into and this took up a lot of time.

We are proud to have completed such a ambitious project in the limited time of the hackathon.

We learned to run a complete machine learning pipeline from data collection to final test results.

We would like to improve on this project by adding accessories for both men and women. We would also like to suggest new clothes you can add to your wardrobe in your budget.
",,,,"python, tensorflow",801-13,University of Cincinnati,,Domain.com|-|Google Cloud Platform,VineetaSingh,Vineeta,Singh,vin.singh.93@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Make the Customer's Life Easier (84.51),What do I wear?,https://revuc-viii.devpost.com/submissions/114944-what-do-i-wear,"Why dress in a turtle neck everyday?Every morning the question is ""what do I wear today?"" Here is the solution!",3/3/2019 12:47,"What do I wear today?

This project helps you choose and pair the different clothes in your wardrobe to make you look your best.

We built this using a deep learning model implemented in Tensorflow along with some machine learning in Python.

Collecting the data was a big challenges we ran into and this took up a lot of time.

We are proud to have completed such a ambitious project in the limited time of the hackathon.

We learned to run a complete machine learning pipeline from data collection to final test results.

We would like to improve on this project by adding accessories for both men and women. We would also like to suggest new clothes you can add to your wardrobe in your budget.
",,,,"python, tensorflow",801-13,University of Cincinnati,,Domain.com|-|Google Cloud Platform,VineetaSingh,Vineeta,Singh,vin.singh.93@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,What do I wear?,https://revuc-viii.devpost.com/submissions/114944-what-do-i-wear,"Why dress in a turtle neck everyday?Every morning the question is ""what do I wear today?"" Here is the solution!",3/3/2019 12:47,"What do I wear today?

This project helps you choose and pair the different clothes in your wardrobe to make you look your best.

We built this using a deep learning model implemented in Tensorflow along with some machine learning in Python.

Collecting the data was a big challenges we ran into and this took up a lot of time.

We are proud to have completed such a ambitious project in the limited time of the hackathon.

We learned to run a complete machine learning pipeline from data collection to final test results.

We would like to improve on this project by adding accessories for both men and women. We would also like to suggest new clothes you can add to your wardrobe in your budget.
",,,,"python, tensorflow",801-13,University of Cincinnati,,Domain.com|-|Google Cloud Platform,VineetaSingh,Vineeta,Singh,vin.singh.93@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),What do I wear?,https://revuc-viii.devpost.com/submissions/114944-what-do-i-wear,"Why dress in a turtle neck everyday?Every morning the question is ""what do I wear today?"" Here is the solution!",3/3/2019 12:47,"What do I wear today?

This project helps you choose and pair the different clothes in your wardrobe to make you look your best.

We built this using a deep learning model implemented in Tensorflow along with some machine learning in Python.

Collecting the data was a big challenges we ran into and this took up a lot of time.

We are proud to have completed such a ambitious project in the limited time of the hackathon.

We learned to run a complete machine learning pipeline from data collection to final test results.

We would like to improve on this project by adding accessories for both men and women. We would also like to suggest new clothes you can add to your wardrobe in your budget.
",,,,"python, tensorflow",801-13,University of Cincinnati,,Domain.com|-|Google Cloud Platform,VineetaSingh,Vineeta,Singh,vin.singh.93@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Design,Tap,https://revuc-viii.devpost.com/submissions/114945-tap,Tap game is a very useless app you should try.,3/3/2019 12:47,"Inspiration: We wanted to learn how to develop an Android app to learn new thing.

What it does: It is pretty useless app that does nothing but shows numbers when you tap a button.

How we built it: We learned how to use Unity to build the app in it.

Challenges we ran into: How to use Unity. We had to watch couple videos and ask couple friends.

Accomplishments that we're proud of: We were able to get the app to work as we intended.

What we learned: How to develop an Android app.

What's next for Tap: To add on database to keep track of the score online and for people to be able to share their score with other friends.
",,,,unity,860B-1,"University of Cincinnati, Sinclair Community College, Wright State University",,,abougamz,Moaz,Abougabal,abougamz@mail.uc.edu,"University of Cincinnati, Sinclair Community College, Wright State University",3,abougaed,emad,abougabak,abougaed@mail.uc.edu,Omar-Mohamed,,,omarabdo352@gmail.com,Hamzaabdelhamed,,,hamza.abdelhamed2010@yahoo.com,,,,
Best Useless Hack,Tap,https://revuc-viii.devpost.com/submissions/114945-tap,Tap game is a very useless app you should try.,3/3/2019 12:47,"Inspiration: We wanted to learn how to develop an Android app to learn new thing.

What it does: It is pretty useless app that does nothing but shows numbers when you tap a button.

How we built it: We learned how to use Unity to build the app in it.

Challenges we ran into: How to use Unity. We had to watch couple videos and ask couple friends.

Accomplishments that we're proud of: We were able to get the app to work as we intended.

What we learned: How to develop an Android app.

What's next for Tap: To add on database to keep track of the score online and for people to be able to share their score with other friends.
",,,,unity,860B-1,"University of Cincinnati, Sinclair Community College, Wright State University",,,abougamz,Moaz,Abougabal,abougamz@mail.uc.edu,"University of Cincinnati, Sinclair Community College, Wright State University",3,abougaed,emad,abougabak,abougaed@mail.uc.edu,Omar-Mohamed,,,omarabdo352@gmail.com,Hamzaabdelhamed,,,hamza.abdelhamed2010@yahoo.com,,,,
Best Design,Open Banking API creation challenge by 5/3th Bank,https://revuc-viii.devpost.com/submissions/114954-open-banking-api-creation-challenge-by-5-3th-bank,A project that shows the API creation methods that needs to be used for open banking concept,3/3/2019 12:59,"Inspiration

It is a challenge posted by fifth third bank. I found the concept interesting so started to work on it

What it does

Creates specific API with limited access for the 3rd party application

How I built it

Using Node.js Express.js for backend API creation. MongoDB is used to handle user data. Postman is used for testing the API's.

Challenges I ran into

No major challenges, Anyone who is expert in javascript can create and understand this project

Accomplishments that I'm proud of

Having 15 hours, I completed this full project

What I learned

A lot, especially about the open banking concept

What's next for Open Banking API creation challenge by 5/3th Bank

Need to create a frontend using Angular or React to extend this project further
",,https://github.com/vr025/Backend-API-creation-for-Open-Banking,,"node.js, postman, javascript, mongodb, express.js",860D-5,university of cincinnati,,,vr025,vr025,,vignesh.vr025@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Hardware Hack,Chainsmokers,https://revuc-viii.devpost.com/submissions/114958-chainsmokers,Microphone Based Hardware Music Visualizer,3/3/2019 13:03,"Revolution UC: Chainsmokers Project

Inspiration

I like music and wanted to learn more about how electronic equipment can take audio signals and analyze them.

What it does

Makes an LED strip dance to music.

How I built it

I attached a sound sensor and LED strip to an arduino. The sound sensor listens for music and produces an analog signal. This analog signal is sampled and processed by the arduino. Then it is converted into a height value corresponding to the intensity of the music and a peak value corresponding to the highest recent spike in intensity. I designed different animations based on these two vales. I then added a push button to toggle between the different modes.

Challenges I ran into


The first controller i used didnt support the led control library i wanted to use so i had to switch to a different board.
When the microphone and led strip were powered off of the same power supply, the extra power consumed by the LED strip would cause interference in the analog signal produced by the microphone
The analog signal produced by the microphone is very complicated to understand and I had to try multiple different strategies to find patterns in the data it produced
The microphone picks up a lot of noise in the environment other than the music. I had to find a way to smooth out that noise and focus on the music playing instead.
The microphone can be placed anywhere in a room relative to the speakers playing music. I had to find a way to make the code adjust to different volume levels and still produce a similar animation on the LED strip.


Accomplishments that I'm proud of


I was able to make an animation that accurately corresponds to music.
I was able to use a push button to toggle between
I made something really cool that I can show my friends


What I learned


How to use an analog reference signal to prevent interference from a power supply
How to use a push button sensor in three different modes of operation
How to understand and process analog signals
How to detect and smooth out noise from a microphone


What's next for Chainsmokers

I want to learn how to use Fast Fourier Transforms to further analyze audio signals and break them down into frequency bands to create more interesting animations. I also want to hook this project up to the internet to be able to toggle it on/off and between modes using the Internet of Things.
",,https://github.com/Rooknj/RevolutionUC-LED/tree/master,,"arduino, c++",8.01E+00,University of Cincinnati,Arduino 101,,Rooknj,Nick,Rook,rooknj@outlook.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Useless Hack,Chainsmokers,https://revuc-viii.devpost.com/submissions/114958-chainsmokers,Microphone Based Hardware Music Visualizer,3/3/2019 13:03,"Revolution UC: Chainsmokers Project

Inspiration

I like music and wanted to learn more about how electronic equipment can take audio signals and analyze them.

What it does

Makes an LED strip dance to music.

How I built it

I attached a sound sensor and LED strip to an arduino. The sound sensor listens for music and produces an analog signal. This analog signal is sampled and processed by the arduino. Then it is converted into a height value corresponding to the intensity of the music and a peak value corresponding to the highest recent spike in intensity. I designed different animations based on these two vales. I then added a push button to toggle between the different modes.

Challenges I ran into


The first controller i used didnt support the led control library i wanted to use so i had to switch to a different board.
When the microphone and led strip were powered off of the same power supply, the extra power consumed by the LED strip would cause interference in the analog signal produced by the microphone
The analog signal produced by the microphone is very complicated to understand and I had to try multiple different strategies to find patterns in the data it produced
The microphone picks up a lot of noise in the environment other than the music. I had to find a way to smooth out that noise and focus on the music playing instead.
The microphone can be placed anywhere in a room relative to the speakers playing music. I had to find a way to make the code adjust to different volume levels and still produce a similar animation on the LED strip.


Accomplishments that I'm proud of


I was able to make an animation that accurately corresponds to music.
I was able to use a push button to toggle between
I made something really cool that I can show my friends


What I learned


How to use an analog reference signal to prevent interference from a power supply
How to use a push button sensor in three different modes of operation
How to understand and process analog signals
How to detect and smooth out noise from a microphone


What's next for Chainsmokers

I want to learn how to use Fast Fourier Transforms to further analyze audio signals and break them down into frequency bands to create more interesting animations. I also want to hook this project up to the internet to be able to toggle it on/off and between modes using the Internet of Things.
",,https://github.com/Rooknj/RevolutionUC-LED/tree/master,,"arduino, c++",8.01E+00,University of Cincinnati,Arduino 101,,Rooknj,Nick,Rook,rooknj@outlook.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),Chainsmokers,https://revuc-viii.devpost.com/submissions/114958-chainsmokers,Microphone Based Hardware Music Visualizer,3/3/2019 13:03,"Revolution UC: Chainsmokers Project

Inspiration

I like music and wanted to learn more about how electronic equipment can take audio signals and analyze them.

What it does

Makes an LED strip dance to music.

How I built it

I attached a sound sensor and LED strip to an arduino. The sound sensor listens for music and produces an analog signal. This analog signal is sampled and processed by the arduino. Then it is converted into a height value corresponding to the intensity of the music and a peak value corresponding to the highest recent spike in intensity. I designed different animations based on these two vales. I then added a push button to toggle between the different modes.

Challenges I ran into


The first controller i used didnt support the led control library i wanted to use so i had to switch to a different board.
When the microphone and led strip were powered off of the same power supply, the extra power consumed by the LED strip would cause interference in the analog signal produced by the microphone
The analog signal produced by the microphone is very complicated to understand and I had to try multiple different strategies to find patterns in the data it produced
The microphone picks up a lot of noise in the environment other than the music. I had to find a way to smooth out that noise and focus on the music playing instead.
The microphone can be placed anywhere in a room relative to the speakers playing music. I had to find a way to make the code adjust to different volume levels and still produce a similar animation on the LED strip.


Accomplishments that I'm proud of


I was able to make an animation that accurately corresponds to music.
I was able to use a push button to toggle between
I made something really cool that I can show my friends


What I learned


How to use an analog reference signal to prevent interference from a power supply
How to use a push button sensor in three different modes of operation
How to understand and process analog signals
How to detect and smooth out noise from a microphone


What's next for Chainsmokers

I want to learn how to use Fast Fourier Transforms to further analyze audio signals and break them down into frequency bands to create more interesting animations. I also want to hook this project up to the internet to be able to toggle it on/off and between modes using the Internet of Things.
",,https://github.com/Rooknj/RevolutionUC-LED/tree/master,,"arduino, c++",8.01E+00,University of Cincinnati,Arduino 101,,Rooknj,Nick,Rook,rooknj@outlook.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),FileBuddy,https://revuc-viii.devpost.com/submissions/114959-filebuddy,Turn any phone with a web browser and a camera into a high tech scanner for scanning and organizing documents.,3/3/2019 13:03,"Inspiration

The main idea was my idea, that is Blake Mallory's idea.  I got the idea from being the Academic Chairman of my fraternity.  In that role, I am responsible for holding brothers who have under performed academically accountable, part of that involves them sending me signs, such as photos, of them taking steps to improve.  This often becomes hard to manage, and after seeing apps like CamScanner, and after learning about WebAssembly, I had the idea to make an app to solve this issue by making a webapp.

What it does

The app allows a user to either submit an existing photo, or take a new one with their device.  This image is then processed by OpenCv and transformed so that it can be easily read.  This file is then submitted to a server for storage and categorization. 

How we built it

The app was built around docker.  There are three containers, one for the web app, one for the rest server, and one for the database.  These containers all communicate to make the whole product.  The web app was made using Vue.js and OpenCv and built on a debian docker image.  The rest server was built using python, flask, and a debian docker image.  The database was a postgresql database image.

Challenges we ran into

The first major challenge we faced was getting OpenCV to work.  Since WebAssembly, the technology that makes running OpenCV in the web browser possible is relatively new, the resources online were almost non existent.  The next issue we had was CORs, as we had not had a lot of experience with it in the past and the error messages were sometimes unclear.  Lastly, we had an issue with posting the scanned canvas to the server and spent a long period on time on that issue.

Accomplishments that we're proud of

We created a unique, challenging, relatively cutting edge piece of technology that has potential for the future.  We also learned a great deal.

What we learned

We learned or improved on Vue.js, OpenCv, Python Flask APIs, and Docker.

What's next for FileBuddy

We enjoyed working on this project, and plan on cleaning up the rough edges and bringing FileBuddy to the full vision we had at the start.
",,http://104.248.228.126:2375/#/,,"vue, docker, webassembly, opencv, python, flask",801-8,University of Cincinnati,,,mallorbc,,,mallorbc@mail.uc.edu,University of Cincinnati,1,kligmasn,Steven,Kligman,kligmasn@mail.uc.edu,,,,,,,,,,,,
Make the Customer's Life Easier (84.51),FileBuddy,https://revuc-viii.devpost.com/submissions/114959-filebuddy,Turn any phone with a web browser and a camera into a high tech scanner for scanning and organizing documents.,3/3/2019 13:03,"Inspiration

The main idea was my idea, that is Blake Mallory's idea.  I got the idea from being the Academic Chairman of my fraternity.  In that role, I am responsible for holding brothers who have under performed academically accountable, part of that involves them sending me signs, such as photos, of them taking steps to improve.  This often becomes hard to manage, and after seeing apps like CamScanner, and after learning about WebAssembly, I had the idea to make an app to solve this issue by making a webapp.

What it does

The app allows a user to either submit an existing photo, or take a new one with their device.  This image is then processed by OpenCv and transformed so that it can be easily read.  This file is then submitted to a server for storage and categorization. 

How we built it

The app was built around docker.  There are three containers, one for the web app, one for the rest server, and one for the database.  These containers all communicate to make the whole product.  The web app was made using Vue.js and OpenCv and built on a debian docker image.  The rest server was built using python, flask, and a debian docker image.  The database was a postgresql database image.

Challenges we ran into

The first major challenge we faced was getting OpenCV to work.  Since WebAssembly, the technology that makes running OpenCV in the web browser possible is relatively new, the resources online were almost non existent.  The next issue we had was CORs, as we had not had a lot of experience with it in the past and the error messages were sometimes unclear.  Lastly, we had an issue with posting the scanned canvas to the server and spent a long period on time on that issue.

Accomplishments that we're proud of

We created a unique, challenging, relatively cutting edge piece of technology that has potential for the future.  We also learned a great deal.

What we learned

We learned or improved on Vue.js, OpenCv, Python Flask APIs, and Docker.

What's next for FileBuddy

We enjoyed working on this project, and plan on cleaning up the rough edges and bringing FileBuddy to the full vision we had at the start.
",,http://104.248.228.126:2375/#/,,"vue, docker, webassembly, opencv, python, flask",801-8,University of Cincinnati,,,mallorbc,,,mallorbc@mail.uc.edu,University of Cincinnati,1,kligmasn,Steven,Kligman,kligmasn@mail.uc.edu,,,,,,,,,,,,
 Best Domain Registered with Domain.com (MLH),Cool Math Maze,https://revuc-viii.devpost.com/submissions/114961-cool-math-maze,Fun math questions that bring you through a small maze of URLs,3/3/2019 13:04,"I was bored at midnight so I decided to make a small maze out of website URLs. I ran into a problem by only being able to create one free domain, so the correct answer brings you to my other domain from a previous hackathon.
",,,,domain,860d-4,Lawrence Technological University,,,kyletomczik,kyletomczik,Tomczik,ktomczik@ltu.edu,Lawrence Technological University,0,,,,,,,,,,,,,,,,
Best Useless Hack,Cool Math Maze,https://revuc-viii.devpost.com/submissions/114961-cool-math-maze,Fun math questions that bring you through a small maze of URLs,3/3/2019 13:04,"I was bored at midnight so I decided to make a small maze out of website URLs. I ran into a problem by only being able to create one free domain, so the correct answer brings you to my other domain from a previous hackathon.
",,,,domain,860d-4,Lawrence Technological University,,,kyletomczik,kyletomczik,Tomczik,ktomczik@ltu.edu,Lawrence Technological University,0,,,,,,,,,,,,,,,,
Make the Customer's Life Easier (84.51),UC_bearcats_lung_cancer_study,https://revuc-viii.devpost.com/submissions/114965-uc_bearcats_lung_cancer_study,Does lung cancer distribution have spatial patterns ?,3/3/2019 13:07,"Inspiration

We are motivated by exploring the spatial distribution patterns of rate of new lung cancers, rate of new cancer deaths at county level in Kentucky in 2015, and related socioeconomic contributing factors. 

The two main research questions are:

(1) Do a spatial distribution patterns of rate of new lung cancers and rate of new cancer deaths show a cluster distribution in Kentucky? 

(2) If the spatial distribution presents a cluster characteristic, where are the hot spots located? 

What it does

We proposed to analyse spatial pattern.

How I built it

We built based on ArcGIS 10.3 platform.

Challenges I ran into

How to interpret the spatial patterns in a proper way?

Accomplishments that I'm proud of

We show the spatial patterns of lung cancer distribution

What I learned

1) Socioeconomic factors can contribute the rate of new lung cancers, rate of new cancer deaths in Kentucky, such as smoking, age, race, education, income, employment.

What's next for UC_bearcats_lung_cancer_study

1) Based on the above observations,  we propose a spatial lag regression model for our future study .
",,,,esri,801A-4,University of Cincinnati,,,fanzh,Jonathan,Fan,fanzh@mail.uc.edu,University of Cincinnati,0,,,,,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),Social Media connector using MERN stack for JP Morgan,https://revuc-viii.devpost.com/submissions/114966-social-media-connector-using-mern-stack-for-jp-morgan,A developer connector platform website using MERN stack,3/3/2019 13:07,"Inspiration

A challenge from JP Morgan and chase

What it does

It is a social connector for developers who can interact with each other once created the profile in the website

How I built it

Using MERN stack, i.e. React, node.js, express.js, mongoDB

Challenges I ran into

Making Frontend was a challenging task I faced

Accomplishments that I'm proud of

Created within 24 hours

What I learned

MERN stack concepts

What's next for Social Media connector using MERN stack for JP Morgan

More features like online status, publish subscribe messaging concept can be implemented as a future task
",,https://github.com/vr025/Social-connecter-website-using-MERN-stack.git,,"react, redux, node.js, express.js, mongodb",860D-5,university of cincinnati,,,vr025,vr025,,vignesh.vr025@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
,Removing Barriers,https://revuc-viii.devpost.com/submissions/114971-removing-barriers,we need to visualize data better in order to remove barriers for those with health problems. ,3/3/2019 13:14,"Inspiration

What it does

How I built it

Challenges I ran into

Accomplishments that I'm proud of##iteration one not ready yet send iteration two better version soon

What I learned

What's next for Removing Barriers
",,,,,unsure,1,,,mezhu,M,Z,mezhu@wccnet.edu,University of Michigan - Dearborn,0,,,,,,,,,,,,,,,,
Best Hardware Hack,AutoMed,https://revuc-viii.devpost.com/submissions/114981-automed,A 3D printed wearable medical device that safely medicates over the counter drugs,3/3/2019 13:20,"Inspiration

In today’s fast-paced world, it can be difficult to remember to remember the small, but important things in life. For most people that entails forgetting when to take their medicine. We wanted to solve this problem. Also, most drugs today are designed to administer large portions at a time which is ok, but isn't the best for the body. There are little to no methods of slowly releasing medicine that exist today. We were inspired to have multiple dosages per day and that can be difficult to keep track of. We recognized this problem, and we realized that we needed to automate this often difficult and frustrating process. We wanted to solve this problem by creating a wearable that will alert you as soon your time to take your medicine has come. And this will automatically give you medicine in the correct calculated dosage with the added functionality of making it slow release for extra safety.

What it does

AutoMed is a 3D printed wearable controlled by a mobile device through a Bluetooth serial connection that access a Google Firebase database that we set up to get correct information to calculate dosage. The application uses software to customize the user experience for every patient and calculates a dosage of medicine based on the patients personal inputs (weight, age) and the type of drug they are taking. The patient logs in to the system by entering their name and phone number. They will then receive a text telling them that they have successfully entered into the system and will receive texts for their dosage periodically. We do this by utilizing Twilio software. Then, when they do get the texts, they can press a button on the wearable and it will automatically inject the necessary amount of drug into their bloodstream. Our application is very secure as it also access Google Firebase for secure authentication.

How we built it

AutoMed was built mainly by a 3D printer. The device itself was designed in Autodesk Inventor to ensure a compact and secure design optimized for the user experience. 3D printing allowed us to easily make adjustments to the design of AutoMed and guaranteed a low cost product. This makes AutoMed something that is accessible to everyone, including those who do not necessarily have the means to heavily invest in an insulin pen that serves the same purpose as AutoMed. We also developed a mobile app in Android Studio that connects to the wearable using a Bluetooth Serial communication. The app also calculates the correct dosages and the amount of times needing to be administered daily for the corresponding drug and then sends this data over to the device. The calculations and user authentication are done using Google Firebase, and reminders are sent out to the users' phones using Twilio.

Challenges we ran into

One of the biggest challenges we ran in to was the low quality 3D printed parts that were being made with our printer. Our 3D printer that we brought wasn't printing well and was also performing slowly. We intended to conceal most of the electronics with a 3D printed TPU flexible sleeve but our printer was unable to do so. Another big challenge we ran into was deciding on an idea that we all liked. It took us almost 10 hours to think of an idea that we stuck with. We pivoted 3 times before hand.  

Accomplishments that we're proud of

We are proud of the software we were able to create in the short amount of time. Although we weren't able to get the design on par with our vision, we spent a lot of time working on the software to make that exceed our standards. Our app communicates to the device using Bluetooth serial communication. It also connects to Google Firebase and utilizes databases that exist for dosages with respect to characteristics of a human. We also used Google Firebase to authenticate our users that sign into the app. And lastly, after being stunned by the Twilio demonstration during the opening ceremony, we decided to incorporate this in our app. Our app now alerts its users to take their dosage at the correct times of day by sending them a text message by utilizing Twilios software. Our software also calculates dosage and how often the drug needs to be taken by just entering weight, age, and selecting the drug of choice. Overall we are also proud of our 3D printed wearable that we built in only around 12 hours.

What we learned

When working on AutoMed, we learned a lot on both the software and hardware sides. Although we have used Android Studio and java in the past, making a mobile application with Android Studio while integrating bluetooth functionality was new. We ran into many problems and we constantly talked about how next time making a mobile application would be so much easier and how we could make apps on our own. Going to a hackathon is a totally unique experience where you are in a building for 24 hours and are forced to learn new things for that whole 24 hours.. We know as a group that we would not have learned as much as we did about Firebase, Bluetooth serial communication code, and other new software endeavors without coming to this hackathon. Relating to hardware, we learned how to utilize Arduino to control stepper motors which was a very tough task. Along with this, we familiarize ourselves with Arduino Nano and a Bluetooth Module and how we can use the two together as this is our first time working with both of those pieces of hardware.

What's next for AutoMed

Some big next steps we are already looking into are incorporating a system where the patient can directly message the doctor through the mobile app and vice versa. This connection will also allow doctors to readily access patient information stored in the database. On top of that, the doctor will be able to regulate the dosage of the medicine remotely. We created this application in Android studio because most of the world uses android to cell phones due to the lack of infrastructure for landline phones. This is why we specially targeted an Android app for this hackathon. In the future we plan on expanding to IOS and swift. This will allow Auto-Med to grow as a medical device to more people outside of our accessible community. Our medicine database as of now only consists of 6 medicines, but we hope to expand to hundreds of medicines which will allow for more universal access to the application and AutoMed.
",,https://github.com/adarshponaka/AutoMed,https://s3.amazonaws.com/challengepost/zip_files/production/41775/zip_files/AutoMed.zip,"android-studio, arduino, serial-communication, autodesk, 3d-printing, java, medicine, google-firebase, bluetooth",860 d3,William Mason High School,,,adarshponaka,Adarsh,Ponaka,adarshponaka@gmail.com,,2,AnirudhBali,Anirudh,Bali,balianirudh@gmail.com,shahav2016,Aakash,Shah,shahav2016@gmail.com,,,,,,,,
Best High School Hack,AutoMed,https://revuc-viii.devpost.com/submissions/114981-automed,A 3D printed wearable medical device that safely medicates over the counter drugs,3/3/2019 13:20,"Inspiration

In today’s fast-paced world, it can be difficult to remember to remember the small, but important things in life. For most people that entails forgetting when to take their medicine. We wanted to solve this problem. Also, most drugs today are designed to administer large portions at a time which is ok, but isn't the best for the body. There are little to no methods of slowly releasing medicine that exist today. We were inspired to have multiple dosages per day and that can be difficult to keep track of. We recognized this problem, and we realized that we needed to automate this often difficult and frustrating process. We wanted to solve this problem by creating a wearable that will alert you as soon your time to take your medicine has come. And this will automatically give you medicine in the correct calculated dosage with the added functionality of making it slow release for extra safety.

What it does

AutoMed is a 3D printed wearable controlled by a mobile device through a Bluetooth serial connection that access a Google Firebase database that we set up to get correct information to calculate dosage. The application uses software to customize the user experience for every patient and calculates a dosage of medicine based on the patients personal inputs (weight, age) and the type of drug they are taking. The patient logs in to the system by entering their name and phone number. They will then receive a text telling them that they have successfully entered into the system and will receive texts for their dosage periodically. We do this by utilizing Twilio software. Then, when they do get the texts, they can press a button on the wearable and it will automatically inject the necessary amount of drug into their bloodstream. Our application is very secure as it also access Google Firebase for secure authentication.

How we built it

AutoMed was built mainly by a 3D printer. The device itself was designed in Autodesk Inventor to ensure a compact and secure design optimized for the user experience. 3D printing allowed us to easily make adjustments to the design of AutoMed and guaranteed a low cost product. This makes AutoMed something that is accessible to everyone, including those who do not necessarily have the means to heavily invest in an insulin pen that serves the same purpose as AutoMed. We also developed a mobile app in Android Studio that connects to the wearable using a Bluetooth Serial communication. The app also calculates the correct dosages and the amount of times needing to be administered daily for the corresponding drug and then sends this data over to the device. The calculations and user authentication are done using Google Firebase, and reminders are sent out to the users' phones using Twilio.

Challenges we ran into

One of the biggest challenges we ran in to was the low quality 3D printed parts that were being made with our printer. Our 3D printer that we brought wasn't printing well and was also performing slowly. We intended to conceal most of the electronics with a 3D printed TPU flexible sleeve but our printer was unable to do so. Another big challenge we ran into was deciding on an idea that we all liked. It took us almost 10 hours to think of an idea that we stuck with. We pivoted 3 times before hand.  

Accomplishments that we're proud of

We are proud of the software we were able to create in the short amount of time. Although we weren't able to get the design on par with our vision, we spent a lot of time working on the software to make that exceed our standards. Our app communicates to the device using Bluetooth serial communication. It also connects to Google Firebase and utilizes databases that exist for dosages with respect to characteristics of a human. We also used Google Firebase to authenticate our users that sign into the app. And lastly, after being stunned by the Twilio demonstration during the opening ceremony, we decided to incorporate this in our app. Our app now alerts its users to take their dosage at the correct times of day by sending them a text message by utilizing Twilios software. Our software also calculates dosage and how often the drug needs to be taken by just entering weight, age, and selecting the drug of choice. Overall we are also proud of our 3D printed wearable that we built in only around 12 hours.

What we learned

When working on AutoMed, we learned a lot on both the software and hardware sides. Although we have used Android Studio and java in the past, making a mobile application with Android Studio while integrating bluetooth functionality was new. We ran into many problems and we constantly talked about how next time making a mobile application would be so much easier and how we could make apps on our own. Going to a hackathon is a totally unique experience where you are in a building for 24 hours and are forced to learn new things for that whole 24 hours.. We know as a group that we would not have learned as much as we did about Firebase, Bluetooth serial communication code, and other new software endeavors without coming to this hackathon. Relating to hardware, we learned how to utilize Arduino to control stepper motors which was a very tough task. Along with this, we familiarize ourselves with Arduino Nano and a Bluetooth Module and how we can use the two together as this is our first time working with both of those pieces of hardware.

What's next for AutoMed

Some big next steps we are already looking into are incorporating a system where the patient can directly message the doctor through the mobile app and vice versa. This connection will also allow doctors to readily access patient information stored in the database. On top of that, the doctor will be able to regulate the dosage of the medicine remotely. We created this application in Android studio because most of the world uses android to cell phones due to the lack of infrastructure for landline phones. This is why we specially targeted an Android app for this hackathon. In the future we plan on expanding to IOS and swift. This will allow Auto-Med to grow as a medical device to more people outside of our accessible community. Our medicine database as of now only consists of 6 medicines, but we hope to expand to hundreds of medicines which will allow for more universal access to the application and AutoMed.
",,https://github.com/adarshponaka/AutoMed,https://s3.amazonaws.com/challengepost/zip_files/production/41775/zip_files/AutoMed.zip,"android-studio, arduino, serial-communication, autodesk, 3d-printing, java, medicine, google-firebase, bluetooth",860 d3,William Mason High School,,,adarshponaka,Adarsh,Ponaka,adarshponaka@gmail.com,,2,AnirudhBali,Anirudh,Bali,balianirudh@gmail.com,shahav2016,Aakash,Shah,shahav2016@gmail.com,,,,,,,,
Best Use of Twilio,AutoMed,https://revuc-viii.devpost.com/submissions/114981-automed,A 3D printed wearable medical device that safely medicates over the counter drugs,3/3/2019 13:20,"Inspiration

In today’s fast-paced world, it can be difficult to remember to remember the small, but important things in life. For most people that entails forgetting when to take their medicine. We wanted to solve this problem. Also, most drugs today are designed to administer large portions at a time which is ok, but isn't the best for the body. There are little to no methods of slowly releasing medicine that exist today. We were inspired to have multiple dosages per day and that can be difficult to keep track of. We recognized this problem, and we realized that we needed to automate this often difficult and frustrating process. We wanted to solve this problem by creating a wearable that will alert you as soon your time to take your medicine has come. And this will automatically give you medicine in the correct calculated dosage with the added functionality of making it slow release for extra safety.

What it does

AutoMed is a 3D printed wearable controlled by a mobile device through a Bluetooth serial connection that access a Google Firebase database that we set up to get correct information to calculate dosage. The application uses software to customize the user experience for every patient and calculates a dosage of medicine based on the patients personal inputs (weight, age) and the type of drug they are taking. The patient logs in to the system by entering their name and phone number. They will then receive a text telling them that they have successfully entered into the system and will receive texts for their dosage periodically. We do this by utilizing Twilio software. Then, when they do get the texts, they can press a button on the wearable and it will automatically inject the necessary amount of drug into their bloodstream. Our application is very secure as it also access Google Firebase for secure authentication.

How we built it

AutoMed was built mainly by a 3D printer. The device itself was designed in Autodesk Inventor to ensure a compact and secure design optimized for the user experience. 3D printing allowed us to easily make adjustments to the design of AutoMed and guaranteed a low cost product. This makes AutoMed something that is accessible to everyone, including those who do not necessarily have the means to heavily invest in an insulin pen that serves the same purpose as AutoMed. We also developed a mobile app in Android Studio that connects to the wearable using a Bluetooth Serial communication. The app also calculates the correct dosages and the amount of times needing to be administered daily for the corresponding drug and then sends this data over to the device. The calculations and user authentication are done using Google Firebase, and reminders are sent out to the users' phones using Twilio.

Challenges we ran into

One of the biggest challenges we ran in to was the low quality 3D printed parts that were being made with our printer. Our 3D printer that we brought wasn't printing well and was also performing slowly. We intended to conceal most of the electronics with a 3D printed TPU flexible sleeve but our printer was unable to do so. Another big challenge we ran into was deciding on an idea that we all liked. It took us almost 10 hours to think of an idea that we stuck with. We pivoted 3 times before hand.  

Accomplishments that we're proud of

We are proud of the software we were able to create in the short amount of time. Although we weren't able to get the design on par with our vision, we spent a lot of time working on the software to make that exceed our standards. Our app communicates to the device using Bluetooth serial communication. It also connects to Google Firebase and utilizes databases that exist for dosages with respect to characteristics of a human. We also used Google Firebase to authenticate our users that sign into the app. And lastly, after being stunned by the Twilio demonstration during the opening ceremony, we decided to incorporate this in our app. Our app now alerts its users to take their dosage at the correct times of day by sending them a text message by utilizing Twilios software. Our software also calculates dosage and how often the drug needs to be taken by just entering weight, age, and selecting the drug of choice. Overall we are also proud of our 3D printed wearable that we built in only around 12 hours.

What we learned

When working on AutoMed, we learned a lot on both the software and hardware sides. Although we have used Android Studio and java in the past, making a mobile application with Android Studio while integrating bluetooth functionality was new. We ran into many problems and we constantly talked about how next time making a mobile application would be so much easier and how we could make apps on our own. Going to a hackathon is a totally unique experience where you are in a building for 24 hours and are forced to learn new things for that whole 24 hours.. We know as a group that we would not have learned as much as we did about Firebase, Bluetooth serial communication code, and other new software endeavors without coming to this hackathon. Relating to hardware, we learned how to utilize Arduino to control stepper motors which was a very tough task. Along with this, we familiarize ourselves with Arduino Nano and a Bluetooth Module and how we can use the two together as this is our first time working with both of those pieces of hardware.

What's next for AutoMed

Some big next steps we are already looking into are incorporating a system where the patient can directly message the doctor through the mobile app and vice versa. This connection will also allow doctors to readily access patient information stored in the database. On top of that, the doctor will be able to regulate the dosage of the medicine remotely. We created this application in Android studio because most of the world uses android to cell phones due to the lack of infrastructure for landline phones. This is why we specially targeted an Android app for this hackathon. In the future we plan on expanding to IOS and swift. This will allow Auto-Med to grow as a medical device to more people outside of our accessible community. Our medicine database as of now only consists of 6 medicines, but we hope to expand to hundreds of medicines which will allow for more universal access to the application and AutoMed.
",,https://github.com/adarshponaka/AutoMed,https://s3.amazonaws.com/challengepost/zip_files/production/41775/zip_files/AutoMed.zip,"android-studio, arduino, serial-communication, autodesk, 3d-printing, java, medicine, google-firebase, bluetooth",860 d3,William Mason High School,,,adarshponaka,Adarsh,Ponaka,adarshponaka@gmail.com,,2,AnirudhBali,Anirudh,Bali,balianirudh@gmail.com,shahav2016,Aakash,Shah,shahav2016@gmail.com,,,,,,,,
Best Design,AutoMed,https://revuc-viii.devpost.com/submissions/114981-automed,A 3D printed wearable medical device that safely medicates over the counter drugs,3/3/2019 13:20,"Inspiration

In today’s fast-paced world, it can be difficult to remember to remember the small, but important things in life. For most people that entails forgetting when to take their medicine. We wanted to solve this problem. Also, most drugs today are designed to administer large portions at a time which is ok, but isn't the best for the body. There are little to no methods of slowly releasing medicine that exist today. We were inspired to have multiple dosages per day and that can be difficult to keep track of. We recognized this problem, and we realized that we needed to automate this often difficult and frustrating process. We wanted to solve this problem by creating a wearable that will alert you as soon your time to take your medicine has come. And this will automatically give you medicine in the correct calculated dosage with the added functionality of making it slow release for extra safety.

What it does

AutoMed is a 3D printed wearable controlled by a mobile device through a Bluetooth serial connection that access a Google Firebase database that we set up to get correct information to calculate dosage. The application uses software to customize the user experience for every patient and calculates a dosage of medicine based on the patients personal inputs (weight, age) and the type of drug they are taking. The patient logs in to the system by entering their name and phone number. They will then receive a text telling them that they have successfully entered into the system and will receive texts for their dosage periodically. We do this by utilizing Twilio software. Then, when they do get the texts, they can press a button on the wearable and it will automatically inject the necessary amount of drug into their bloodstream. Our application is very secure as it also access Google Firebase for secure authentication.

How we built it

AutoMed was built mainly by a 3D printer. The device itself was designed in Autodesk Inventor to ensure a compact and secure design optimized for the user experience. 3D printing allowed us to easily make adjustments to the design of AutoMed and guaranteed a low cost product. This makes AutoMed something that is accessible to everyone, including those who do not necessarily have the means to heavily invest in an insulin pen that serves the same purpose as AutoMed. We also developed a mobile app in Android Studio that connects to the wearable using a Bluetooth Serial communication. The app also calculates the correct dosages and the amount of times needing to be administered daily for the corresponding drug and then sends this data over to the device. The calculations and user authentication are done using Google Firebase, and reminders are sent out to the users' phones using Twilio.

Challenges we ran into

One of the biggest challenges we ran in to was the low quality 3D printed parts that were being made with our printer. Our 3D printer that we brought wasn't printing well and was also performing slowly. We intended to conceal most of the electronics with a 3D printed TPU flexible sleeve but our printer was unable to do so. Another big challenge we ran into was deciding on an idea that we all liked. It took us almost 10 hours to think of an idea that we stuck with. We pivoted 3 times before hand.  

Accomplishments that we're proud of

We are proud of the software we were able to create in the short amount of time. Although we weren't able to get the design on par with our vision, we spent a lot of time working on the software to make that exceed our standards. Our app communicates to the device using Bluetooth serial communication. It also connects to Google Firebase and utilizes databases that exist for dosages with respect to characteristics of a human. We also used Google Firebase to authenticate our users that sign into the app. And lastly, after being stunned by the Twilio demonstration during the opening ceremony, we decided to incorporate this in our app. Our app now alerts its users to take their dosage at the correct times of day by sending them a text message by utilizing Twilios software. Our software also calculates dosage and how often the drug needs to be taken by just entering weight, age, and selecting the drug of choice. Overall we are also proud of our 3D printed wearable that we built in only around 12 hours.

What we learned

When working on AutoMed, we learned a lot on both the software and hardware sides. Although we have used Android Studio and java in the past, making a mobile application with Android Studio while integrating bluetooth functionality was new. We ran into many problems and we constantly talked about how next time making a mobile application would be so much easier and how we could make apps on our own. Going to a hackathon is a totally unique experience where you are in a building for 24 hours and are forced to learn new things for that whole 24 hours.. We know as a group that we would not have learned as much as we did about Firebase, Bluetooth serial communication code, and other new software endeavors without coming to this hackathon. Relating to hardware, we learned how to utilize Arduino to control stepper motors which was a very tough task. Along with this, we familiarize ourselves with Arduino Nano and a Bluetooth Module and how we can use the two together as this is our first time working with both of those pieces of hardware.

What's next for AutoMed

Some big next steps we are already looking into are incorporating a system where the patient can directly message the doctor through the mobile app and vice versa. This connection will also allow doctors to readily access patient information stored in the database. On top of that, the doctor will be able to regulate the dosage of the medicine remotely. We created this application in Android studio because most of the world uses android to cell phones due to the lack of infrastructure for landline phones. This is why we specially targeted an Android app for this hackathon. In the future we plan on expanding to IOS and swift. This will allow Auto-Med to grow as a medical device to more people outside of our accessible community. Our medicine database as of now only consists of 6 medicines, but we hope to expand to hundreds of medicines which will allow for more universal access to the application and AutoMed.
",,https://github.com/adarshponaka/AutoMed,https://s3.amazonaws.com/challengepost/zip_files/production/41775/zip_files/AutoMed.zip,"android-studio, arduino, serial-communication, autodesk, 3d-printing, java, medicine, google-firebase, bluetooth",860 d3,William Mason High School,,,adarshponaka,Adarsh,Ponaka,adarshponaka@gmail.com,,2,AnirudhBali,Anirudh,Bali,balianirudh@gmail.com,shahav2016,Aakash,Shah,shahav2016@gmail.com,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),AutoMed,https://revuc-viii.devpost.com/submissions/114981-automed,A 3D printed wearable medical device that safely medicates over the counter drugs,3/3/2019 13:20,"Inspiration

In today’s fast-paced world, it can be difficult to remember to remember the small, but important things in life. For most people that entails forgetting when to take their medicine. We wanted to solve this problem. Also, most drugs today are designed to administer large portions at a time which is ok, but isn't the best for the body. There are little to no methods of slowly releasing medicine that exist today. We were inspired to have multiple dosages per day and that can be difficult to keep track of. We recognized this problem, and we realized that we needed to automate this often difficult and frustrating process. We wanted to solve this problem by creating a wearable that will alert you as soon your time to take your medicine has come. And this will automatically give you medicine in the correct calculated dosage with the added functionality of making it slow release for extra safety.

What it does

AutoMed is a 3D printed wearable controlled by a mobile device through a Bluetooth serial connection that access a Google Firebase database that we set up to get correct information to calculate dosage. The application uses software to customize the user experience for every patient and calculates a dosage of medicine based on the patients personal inputs (weight, age) and the type of drug they are taking. The patient logs in to the system by entering their name and phone number. They will then receive a text telling them that they have successfully entered into the system and will receive texts for their dosage periodically. We do this by utilizing Twilio software. Then, when they do get the texts, they can press a button on the wearable and it will automatically inject the necessary amount of drug into their bloodstream. Our application is very secure as it also access Google Firebase for secure authentication.

How we built it

AutoMed was built mainly by a 3D printer. The device itself was designed in Autodesk Inventor to ensure a compact and secure design optimized for the user experience. 3D printing allowed us to easily make adjustments to the design of AutoMed and guaranteed a low cost product. This makes AutoMed something that is accessible to everyone, including those who do not necessarily have the means to heavily invest in an insulin pen that serves the same purpose as AutoMed. We also developed a mobile app in Android Studio that connects to the wearable using a Bluetooth Serial communication. The app also calculates the correct dosages and the amount of times needing to be administered daily for the corresponding drug and then sends this data over to the device. The calculations and user authentication are done using Google Firebase, and reminders are sent out to the users' phones using Twilio.

Challenges we ran into

One of the biggest challenges we ran in to was the low quality 3D printed parts that were being made with our printer. Our 3D printer that we brought wasn't printing well and was also performing slowly. We intended to conceal most of the electronics with a 3D printed TPU flexible sleeve but our printer was unable to do so. Another big challenge we ran into was deciding on an idea that we all liked. It took us almost 10 hours to think of an idea that we stuck with. We pivoted 3 times before hand.  

Accomplishments that we're proud of

We are proud of the software we were able to create in the short amount of time. Although we weren't able to get the design on par with our vision, we spent a lot of time working on the software to make that exceed our standards. Our app communicates to the device using Bluetooth serial communication. It also connects to Google Firebase and utilizes databases that exist for dosages with respect to characteristics of a human. We also used Google Firebase to authenticate our users that sign into the app. And lastly, after being stunned by the Twilio demonstration during the opening ceremony, we decided to incorporate this in our app. Our app now alerts its users to take their dosage at the correct times of day by sending them a text message by utilizing Twilios software. Our software also calculates dosage and how often the drug needs to be taken by just entering weight, age, and selecting the drug of choice. Overall we are also proud of our 3D printed wearable that we built in only around 12 hours.

What we learned

When working on AutoMed, we learned a lot on both the software and hardware sides. Although we have used Android Studio and java in the past, making a mobile application with Android Studio while integrating bluetooth functionality was new. We ran into many problems and we constantly talked about how next time making a mobile application would be so much easier and how we could make apps on our own. Going to a hackathon is a totally unique experience where you are in a building for 24 hours and are forced to learn new things for that whole 24 hours.. We know as a group that we would not have learned as much as we did about Firebase, Bluetooth serial communication code, and other new software endeavors without coming to this hackathon. Relating to hardware, we learned how to utilize Arduino to control stepper motors which was a very tough task. Along with this, we familiarize ourselves with Arduino Nano and a Bluetooth Module and how we can use the two together as this is our first time working with both of those pieces of hardware.

What's next for AutoMed

Some big next steps we are already looking into are incorporating a system where the patient can directly message the doctor through the mobile app and vice versa. This connection will also allow doctors to readily access patient information stored in the database. On top of that, the doctor will be able to regulate the dosage of the medicine remotely. We created this application in Android studio because most of the world uses android to cell phones due to the lack of infrastructure for landline phones. This is why we specially targeted an Android app for this hackathon. In the future we plan on expanding to IOS and swift. This will allow Auto-Med to grow as a medical device to more people outside of our accessible community. Our medicine database as of now only consists of 6 medicines, but we hope to expand to hundreds of medicines which will allow for more universal access to the application and AutoMed.
",,https://github.com/adarshponaka/AutoMed,https://s3.amazonaws.com/challengepost/zip_files/production/41775/zip_files/AutoMed.zip,"android-studio, arduino, serial-communication, autodesk, 3d-printing, java, medicine, google-firebase, bluetooth",860 d3,William Mason High School,,,adarshponaka,Adarsh,Ponaka,adarshponaka@gmail.com,,2,AnirudhBali,Anirudh,Bali,balianirudh@gmail.com,shahav2016,Aakash,Shah,shahav2016@gmail.com,,,,,,,,
 Best Domain Registered with Domain.com (MLH),FinTopia,https://revuc-viii.devpost.com/submissions/114982-fintopia,Using the Data visualization to improve the financial wellbeing,3/3/2019 13:21,"Inspiration

According to a study done by American Psychological Association, Money and Work are the top two sources of stress in an adult's life. In 2007, these two sources comprised of 65 percent of stress, and In 2015 they comprised of 67 percent of stress. We explored the data-set from the National Financial Well-Being survey to learn more about how a wide range of factors relate to consumers' financial well-being. 

What it does

We have a short survey for consumers in our application that comprises of 10 most important factors that affect the financial well-being of a person. Depending on the results of the survey, and where they stand relative to the data we gathered, the app offers an exclusive financial plan to the user based on their needs. 

How we built it

We collected the data-set from Kaggle, and cleaned it by using the Pandas and Numpy libraries in python. We then built our scatter plot using the libraries hosted by the plotly cdn and the Cloudflare cdn. Plotly is the part of D3.JS framework. We used plotly libraries for data visualization. We also used Google's font api ""Google fonts"" to load the railway font. We then stored the clean data in a data variable. After that we parsed through the whole data using the D3 Javascript library. Now we have a form that is using the JSON file to upload the data on a local server and looping through the array to get the average of all the values. Once it has the average, it's publishing the value to the ""y"" value data array we already created in. X values are auto incrementing from 0 to 5001. This whole process gives user a scatter plot in the end that represents the financial wellbeing of the user in comparison to all other people in the dataset.

Challenges we ran into

It was incredibly difficult to find a suitable dataset in such a short period of time, and that impacted our application greatly. We ran into various challenges. Since back-end development is new to us we had difficulty setting up a Cherrypy server. We were stuck at the configuration process of the server. We also had difficulty 

Accomplishments that we're proud of

In just 24 hours, we built an application using very big data. Our idea solves a serious real world problem. Both of us in the team did not have much experience with the technologies we worked with. We stayed up all night to polish our application!

What we learned

We learned to setup a CherryPy Server. We were new to learning D3.

What's next for FinTopia

We are planning on making a fully customizable financial planning application
",,,,"javascript, cherrypy, python, html, css, d3.js, kaggle, canvas, plotly",N/A,University of Toledo,,,ManishShiwlani,Manish,Shiwlani,manishshiwlani123@gmail.com,,0,,,,,,,,,,,,,,,,
Best Design,FinTopia,https://revuc-viii.devpost.com/submissions/114982-fintopia,Using the Data visualization to improve the financial wellbeing,3/3/2019 13:21,"Inspiration

According to a study done by American Psychological Association, Money and Work are the top two sources of stress in an adult's life. In 2007, these two sources comprised of 65 percent of stress, and In 2015 they comprised of 67 percent of stress. We explored the data-set from the National Financial Well-Being survey to learn more about how a wide range of factors relate to consumers' financial well-being. 

What it does

We have a short survey for consumers in our application that comprises of 10 most important factors that affect the financial well-being of a person. Depending on the results of the survey, and where they stand relative to the data we gathered, the app offers an exclusive financial plan to the user based on their needs. 

How we built it

We collected the data-set from Kaggle, and cleaned it by using the Pandas and Numpy libraries in python. We then built our scatter plot using the libraries hosted by the plotly cdn and the Cloudflare cdn. Plotly is the part of D3.JS framework. We used plotly libraries for data visualization. We also used Google's font api ""Google fonts"" to load the railway font. We then stored the clean data in a data variable. After that we parsed through the whole data using the D3 Javascript library. Now we have a form that is using the JSON file to upload the data on a local server and looping through the array to get the average of all the values. Once it has the average, it's publishing the value to the ""y"" value data array we already created in. X values are auto incrementing from 0 to 5001. This whole process gives user a scatter plot in the end that represents the financial wellbeing of the user in comparison to all other people in the dataset.

Challenges we ran into

It was incredibly difficult to find a suitable dataset in such a short period of time, and that impacted our application greatly. We ran into various challenges. Since back-end development is new to us we had difficulty setting up a Cherrypy server. We were stuck at the configuration process of the server. We also had difficulty 

Accomplishments that we're proud of

In just 24 hours, we built an application using very big data. Our idea solves a serious real world problem. Both of us in the team did not have much experience with the technologies we worked with. We stayed up all night to polish our application!

What we learned

We learned to setup a CherryPy Server. We were new to learning D3.

What's next for FinTopia

We are planning on making a fully customizable financial planning application
",,,,"javascript, cherrypy, python, html, css, d3.js, kaggle, canvas, plotly",N/A,University of Toledo,,,ManishShiwlani,Manish,Shiwlani,manishshiwlani123@gmail.com,,0,,,,,,,,,,,,,,,,
Best Useless Hack,FinTopia,https://revuc-viii.devpost.com/submissions/114982-fintopia,Using the Data visualization to improve the financial wellbeing,3/3/2019 13:21,"Inspiration

According to a study done by American Psychological Association, Money and Work are the top two sources of stress in an adult's life. In 2007, these two sources comprised of 65 percent of stress, and In 2015 they comprised of 67 percent of stress. We explored the data-set from the National Financial Well-Being survey to learn more about how a wide range of factors relate to consumers' financial well-being. 

What it does

We have a short survey for consumers in our application that comprises of 10 most important factors that affect the financial well-being of a person. Depending on the results of the survey, and where they stand relative to the data we gathered, the app offers an exclusive financial plan to the user based on their needs. 

How we built it

We collected the data-set from Kaggle, and cleaned it by using the Pandas and Numpy libraries in python. We then built our scatter plot using the libraries hosted by the plotly cdn and the Cloudflare cdn. Plotly is the part of D3.JS framework. We used plotly libraries for data visualization. We also used Google's font api ""Google fonts"" to load the railway font. We then stored the clean data in a data variable. After that we parsed through the whole data using the D3 Javascript library. Now we have a form that is using the JSON file to upload the data on a local server and looping through the array to get the average of all the values. Once it has the average, it's publishing the value to the ""y"" value data array we already created in. X values are auto incrementing from 0 to 5001. This whole process gives user a scatter plot in the end that represents the financial wellbeing of the user in comparison to all other people in the dataset.

Challenges we ran into

It was incredibly difficult to find a suitable dataset in such a short period of time, and that impacted our application greatly. We ran into various challenges. Since back-end development is new to us we had difficulty setting up a Cherrypy server. We were stuck at the configuration process of the server. We also had difficulty 

Accomplishments that we're proud of

In just 24 hours, we built an application using very big data. Our idea solves a serious real world problem. Both of us in the team did not have much experience with the technologies we worked with. We stayed up all night to polish our application!

What we learned

We learned to setup a CherryPy Server. We were new to learning D3.

What's next for FinTopia

We are planning on making a fully customizable financial planning application
",,,,"javascript, cherrypy, python, html, css, d3.js, kaggle, canvas, plotly",N/A,University of Toledo,,,ManishShiwlani,Manish,Shiwlani,manishshiwlani123@gmail.com,,0,,,,,,,,,,,,,,,,
Best Undergrad Hack (Undergrad Research),FinTopia,https://revuc-viii.devpost.com/submissions/114982-fintopia,Using the Data visualization to improve the financial wellbeing,3/3/2019 13:21,"Inspiration

According to a study done by American Psychological Association, Money and Work are the top two sources of stress in an adult's life. In 2007, these two sources comprised of 65 percent of stress, and In 2015 they comprised of 67 percent of stress. We explored the data-set from the National Financial Well-Being survey to learn more about how a wide range of factors relate to consumers' financial well-being. 

What it does

We have a short survey for consumers in our application that comprises of 10 most important factors that affect the financial well-being of a person. Depending on the results of the survey, and where they stand relative to the data we gathered, the app offers an exclusive financial plan to the user based on their needs. 

How we built it

We collected the data-set from Kaggle, and cleaned it by using the Pandas and Numpy libraries in python. We then built our scatter plot using the libraries hosted by the plotly cdn and the Cloudflare cdn. Plotly is the part of D3.JS framework. We used plotly libraries for data visualization. We also used Google's font api ""Google fonts"" to load the railway font. We then stored the clean data in a data variable. After that we parsed through the whole data using the D3 Javascript library. Now we have a form that is using the JSON file to upload the data on a local server and looping through the array to get the average of all the values. Once it has the average, it's publishing the value to the ""y"" value data array we already created in. X values are auto incrementing from 0 to 5001. This whole process gives user a scatter plot in the end that represents the financial wellbeing of the user in comparison to all other people in the dataset.

Challenges we ran into

It was incredibly difficult to find a suitable dataset in such a short period of time, and that impacted our application greatly. We ran into various challenges. Since back-end development is new to us we had difficulty setting up a Cherrypy server. We were stuck at the configuration process of the server. We also had difficulty 

Accomplishments that we're proud of

In just 24 hours, we built an application using very big data. Our idea solves a serious real world problem. Both of us in the team did not have much experience with the technologies we worked with. We stayed up all night to polish our application!

What we learned

We learned to setup a CherryPy Server. We were new to learning D3.

What's next for FinTopia

We are planning on making a fully customizable financial planning application
",,,,"javascript, cherrypy, python, html, css, d3.js, kaggle, canvas, plotly",N/A,University of Toledo,,,ManishShiwlani,Manish,Shiwlani,manishshiwlani123@gmail.com,,0,,,,,,,,,,,,,,,,
Make the Customer's Life Easier (84.51),FinTopia,https://revuc-viii.devpost.com/submissions/114982-fintopia,Using the Data visualization to improve the financial wellbeing,3/3/2019 13:21,"Inspiration

According to a study done by American Psychological Association, Money and Work are the top two sources of stress in an adult's life. In 2007, these two sources comprised of 65 percent of stress, and In 2015 they comprised of 67 percent of stress. We explored the data-set from the National Financial Well-Being survey to learn more about how a wide range of factors relate to consumers' financial well-being. 

What it does

We have a short survey for consumers in our application that comprises of 10 most important factors that affect the financial well-being of a person. Depending on the results of the survey, and where they stand relative to the data we gathered, the app offers an exclusive financial plan to the user based on their needs. 

How we built it

We collected the data-set from Kaggle, and cleaned it by using the Pandas and Numpy libraries in python. We then built our scatter plot using the libraries hosted by the plotly cdn and the Cloudflare cdn. Plotly is the part of D3.JS framework. We used plotly libraries for data visualization. We also used Google's font api ""Google fonts"" to load the railway font. We then stored the clean data in a data variable. After that we parsed through the whole data using the D3 Javascript library. Now we have a form that is using the JSON file to upload the data on a local server and looping through the array to get the average of all the values. Once it has the average, it's publishing the value to the ""y"" value data array we already created in. X values are auto incrementing from 0 to 5001. This whole process gives user a scatter plot in the end that represents the financial wellbeing of the user in comparison to all other people in the dataset.

Challenges we ran into

It was incredibly difficult to find a suitable dataset in such a short period of time, and that impacted our application greatly. We ran into various challenges. Since back-end development is new to us we had difficulty setting up a Cherrypy server. We were stuck at the configuration process of the server. We also had difficulty 

Accomplishments that we're proud of

In just 24 hours, we built an application using very big data. Our idea solves a serious real world problem. Both of us in the team did not have much experience with the technologies we worked with. We stayed up all night to polish our application!

What we learned

We learned to setup a CherryPy Server. We were new to learning D3.

What's next for FinTopia

We are planning on making a fully customizable financial planning application
",,,,"javascript, cherrypy, python, html, css, d3.js, kaggle, canvas, plotly",N/A,University of Toledo,,,ManishShiwlani,Manish,Shiwlani,manishshiwlani123@gmail.com,,0,,,,,,,,,,,,,,,,
Best Demonstration of the Use of Data to enable Better Customer Experiences,FinTopia,https://revuc-viii.devpost.com/submissions/114982-fintopia,Using the Data visualization to improve the financial wellbeing,3/3/2019 13:21,"Inspiration

According to a study done by American Psychological Association, Money and Work are the top two sources of stress in an adult's life. In 2007, these two sources comprised of 65 percent of stress, and In 2015 they comprised of 67 percent of stress. We explored the data-set from the National Financial Well-Being survey to learn more about how a wide range of factors relate to consumers' financial well-being. 

What it does

We have a short survey for consumers in our application that comprises of 10 most important factors that affect the financial well-being of a person. Depending on the results of the survey, and where they stand relative to the data we gathered, the app offers an exclusive financial plan to the user based on their needs. 

How we built it

We collected the data-set from Kaggle, and cleaned it by using the Pandas and Numpy libraries in python. We then built our scatter plot using the libraries hosted by the plotly cdn and the Cloudflare cdn. Plotly is the part of D3.JS framework. We used plotly libraries for data visualization. We also used Google's font api ""Google fonts"" to load the railway font. We then stored the clean data in a data variable. After that we parsed through the whole data using the D3 Javascript library. Now we have a form that is using the JSON file to upload the data on a local server and looping through the array to get the average of all the values. Once it has the average, it's publishing the value to the ""y"" value data array we already created in. X values are auto incrementing from 0 to 5001. This whole process gives user a scatter plot in the end that represents the financial wellbeing of the user in comparison to all other people in the dataset.

Challenges we ran into

It was incredibly difficult to find a suitable dataset in such a short period of time, and that impacted our application greatly. We ran into various challenges. Since back-end development is new to us we had difficulty setting up a Cherrypy server. We were stuck at the configuration process of the server. We also had difficulty 

Accomplishments that we're proud of

In just 24 hours, we built an application using very big data. Our idea solves a serious real world problem. Both of us in the team did not have much experience with the technologies we worked with. We stayed up all night to polish our application!

What we learned

We learned to setup a CherryPy Server. We were new to learning D3.

What's next for FinTopia

We are planning on making a fully customizable financial planning application
",,,,"javascript, cherrypy, python, html, css, d3.js, kaggle, canvas, plotly",N/A,University of Toledo,,,ManishShiwlani,Manish,Shiwlani,manishshiwlani123@gmail.com,,0,,,,,,,,,,,,,,,,
Best Hack for Social Good (JP Morgan Chase & Co),FinTopia,https://revuc-viii.devpost.com/submissions/114982-fintopia,Using the Data visualization to improve the financial wellbeing,3/3/2019 13:21,"Inspiration

According to a study done by American Psychological Association, Money and Work are the top two sources of stress in an adult's life. In 2007, these two sources comprised of 65 percent of stress, and In 2015 they comprised of 67 percent of stress. We explored the data-set from the National Financial Well-Being survey to learn more about how a wide range of factors relate to consumers' financial well-being. 

What it does

We have a short survey for consumers in our application that comprises of 10 most important factors that affect the financial well-being of a person. Depending on the results of the survey, and where they stand relative to the data we gathered, the app offers an exclusive financial plan to the user based on their needs. 

How we built it

We collected the data-set from Kaggle, and cleaned it by using the Pandas and Numpy libraries in python. We then built our scatter plot using the libraries hosted by the plotly cdn and the Cloudflare cdn. Plotly is the part of D3.JS framework. We used plotly libraries for data visualization. We also used Google's font api ""Google fonts"" to load the railway font. We then stored the clean data in a data variable. After that we parsed through the whole data using the D3 Javascript library. Now we have a form that is using the JSON file to upload the data on a local server and looping through the array to get the average of all the values. Once it has the average, it's publishing the value to the ""y"" value data array we already created in. X values are auto incrementing from 0 to 5001. This whole process gives user a scatter plot in the end that represents the financial wellbeing of the user in comparison to all other people in the dataset.

Challenges we ran into

It was incredibly difficult to find a suitable dataset in such a short period of time, and that impacted our application greatly. We ran into various challenges. Since back-end development is new to us we had difficulty setting up a Cherrypy server. We were stuck at the configuration process of the server. We also had difficulty 

Accomplishments that we're proud of

In just 24 hours, we built an application using very big data. Our idea solves a serious real world problem. Both of us in the team did not have much experience with the technologies we worked with. We stayed up all night to polish our application!

What we learned

We learned to setup a CherryPy Server. We were new to learning D3.

What's next for FinTopia

We are planning on making a fully customizable financial planning application
",,,,"javascript, cherrypy, python, html, css, d3.js, kaggle, canvas, plotly",N/A,University of Toledo,,,ManishShiwlani,Manish,Shiwlani,manishshiwlani123@gmail.com,,0,,,,,,,,,,,,,,,,
,Bread and Milk Alarm,https://revuc-viii.devpost.com/submissions/114986-bread-and-milk-alarm,this program sends you a text when its snowing to remind you to get bread and milk,3/3/2019 13:23,"Inspiration

it was snowing

What it does

annoys you

How I built it

with a computer

Challenges I ran into

making sure it was snowing

Accomplishments that I'm proud of

making it while it was snowing

What I learned

its snowing

What's next for Bread and Milk Alarm

continue to keep people alerted
",,,,"twilio, python",801B-5,1,,,noahbirrer,Noah,Birrer,noahbirrer@gmail.com,University of Cincinnati,0,,,,,,,,,,,,,,,,
